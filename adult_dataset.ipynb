{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d410884",
   "metadata": {},
   "source": [
    "# Dataset Context and Exploration\n",
    "\n",
    "**age**  \n",
    "- Demographic: Age  \n",
    "- Description: How old is this sample of people  \n",
    "- Data Type: Integer  \n",
    "- Missing Values: No  \n",
    "\n",
    "**workclass**  \n",
    "- Demographic: Income  \n",
    "- Description: Employment classification  \n",
    "- Possible values: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked  \n",
    "- Data Type: Categorical  \n",
    "- Missing Values: Yes  \n",
    "\n",
    "**fnlwgt**  \n",
    "- Demographic:  \n",
    "- Description: Final weight representing the number of people the census believes the entry represents  \n",
    "- Data Type: Integer  \n",
    "- Missing Values: No  \n",
    "\n",
    "**education**  \n",
    "- Demographic: Education Level  \n",
    "- Description: Highest level of education achieved  \n",
    "- Possible values: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool  \n",
    "- Data Type: Categorical  \n",
    "- Missing Values: No  \n",
    "\n",
    "**education-num**  \n",
    "- Demographic: Education Level  \n",
    "- Description: Numeric representation of education level  \n",
    "- Data Type: Integer  \n",
    "- Missing Values: No  \n",
    "\n",
    "**marital-status**  \n",
    "- Demographic: Other  \n",
    "- Description: Marital status of the individual  \n",
    "- Possible values: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse  \n",
    "- Data Type: Categorical  \n",
    "- Missing Values: No  \n",
    "\n",
    "**occupation**  \n",
    "- Demographic: Other  \n",
    "- Description: Type of job  \n",
    "- Possible values: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces  \n",
    "- Data Type: Categorical  \n",
    "- Missing Values: Yes  \n",
    "\n",
    "**relationship**  \n",
    "- Demographic: Other  \n",
    "- Description: Relationship within household  \n",
    "- Possible values: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried  \n",
    "- Data Type: Categorical  \n",
    "- Missing Values: No  \n",
    "\n",
    "**race**  \n",
    "- Demographic: Race  \n",
    "- Description: Race of the individual  \n",
    "- Possible values: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black  \n",
    "- Data Type: Categorical  \n",
    "- Missing Values: No  \n",
    "\n",
    "**sex**  \n",
    "- Demographic: Sex  \n",
    "- Description: Gender of the individual  \n",
    "- Possible values: Female, Male  \n",
    "- Data Type: Binary  \n",
    "- Missing Values: No  \n",
    "\n",
    "**capital-gain**  \n",
    "- Demographic:  \n",
    "- Description: Income from capital gains  \n",
    "- Data Type: Integer  \n",
    "- Missing Values: No  \n",
    "\n",
    "**capital-loss**  \n",
    "- Demographic:  \n",
    "- Description: Capital losses  \n",
    "- Data Type: Integer  \n",
    "- Missing Values: No  \n",
    "\n",
    "**hours-per-week**  \n",
    "- Demographic:  \n",
    "- Description: Number of hours worked per week  \n",
    "- Data Type: Integer  \n",
    "- Missing Values: No  \n",
    "\n",
    "**native-country**  \n",
    "- Demographic: Other  \n",
    "- Description: Country of origin  \n",
    "- Possible values: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands  \n",
    "- Data Type: Categorical  \n",
    "- Missing Values: Yes  \n",
    "\n",
    "**income**  \n",
    "- Demographic: Income  \n",
    "- Description: Income class  \n",
    "- Possible values: >50K, <=50K  \n",
    "- Data Type: Binary  \n",
    "- Missing Values: No  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb6049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9ed00",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f607c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                  0\n",
      "workclass         2799\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education-num        0\n",
      "marital-status       0\n",
      "occupation        2809\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital-gain         0\n",
      "capital-loss         0\n",
      "hours-per-week       0\n",
      "native-country     857\n",
      "income               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('base_data/adultdataset.csv', na_values='NaN', skipinitialspace=True)\n",
    "\n",
    "#Identify and count the number of missing values in each column, the missing values are repesented by \"NaN\"\n",
    "missing_values = data.isna().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca1cdf5",
   "metadata": {},
   "source": [
    "# Total fnlwgt\n",
    "\n",
    "The fnlwgt represent the wheight a certain row has over the whole dataset, this works like a percentage.\n",
    "From this point forward if we discribe something as wheighted it means that it wheighted to the total fnlwgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a987500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9263575662\n"
     ]
    }
   ],
   "source": [
    "total_fnlwgt = data['fnlwgt'].sum()\n",
    "print(total_fnlwgt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57702e4b",
   "metadata": {},
   "source": [
    "# Wheighted Age Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "376abf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'17-26': 0.23254280804728858, '27-36': 0.27141756733459493, '37-46': 0.23722836582580933, '47-56': 0.15117445207951713, '57-66': 0.07870687525021912, '67-76': 0.02373170685071477, '77-86': 0.004034587978086513, '87-99': 0.001163636633769635}\n"
     ]
    }
   ],
   "source": [
    "age_bins = [(17, 26), (27, 36), (37, 46), (47, 56), (57, 66), (67, 76), (77, 86), (87, 99)]\n",
    "\n",
    "age_distribution = (data.groupby('age')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "\n",
    "# Aggregate into custom age ranges\n",
    "age_ranges = {}\n",
    "for start, end in age_bins:\n",
    "    label = f'{start}-{end}'\n",
    "    age_ranges[label] = sum(age_distribution.get(age, 0) for age in range(start, end + 1))\n",
    "\n",
    "print(age_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf6cee",
   "metadata": {},
   "source": [
    "# Wheighted Education Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bfcbf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10th': 0.029468504815025498, '11th': 0.03816294386736559, '12th': 0.01400998833877717, '1st-4th': 0.0062664863027056044, '5th-6th': 0.012629909796056028, '7th-8th': 0.019338862285637366, '9th': 0.016240940376528228, 'Assoc-acdm': 0.03347668679083759, 'Assoc-voc': 0.0399183750953639, 'Bachelors': 0.163176883759985, 'Doctorate': 0.011804269538010278, 'HS-grad': 0.32139634430936437, 'Masters': 0.0520525309657691, 'Preschool': 0.0021408804465594703, 'Prof-school': 0.016798332164364632, 'Some-college': 0.22311806114765018}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "education_distribution = (data.groupby('education')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(education_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7d20fb",
   "metadata": {},
   "source": [
    "# Wheighted Race Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bed862e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Amer-Indian-Eskimo': 0.00609399275827926, 'Asian-Pac-Islander': 0.026202793700461278, 'Black': 0.11656649596219383, 'Other': 0.008577742860778288, 'White': 0.8425589747182873}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "race_distribution = (data.groupby('race')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(race_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bb02c1",
   "metadata": {},
   "source": [
    "# Wheighted Native Country Distribuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e324f64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cambodia': 0.0006054133095717787, 'Canada': 0.0035612337183499113, 'China': 0.002275493585750992, 'Columbia': 0.001998964619672796, 'Cuba': 0.003584282917470276, 'Dominican-Republic': 0.002264667852399304, 'Ecuador': 0.000867478746135166, 'El-Salvador': 0.004194289701695103, 'England': 0.0025167153430435273, 'France': 0.0007650541495625774, 'Germany': 0.004291807337752816, 'Greece': 0.000795958306925307, 'Guatemala': 0.0024352646130521775, 'Haiti': 0.0017626972128033124, 'Holand-Netherlands': 3.009852892374422e-06, 'Honduras': 0.0005169305217253592, 'Hong': 0.0006895137723332388, 'Hungary': 0.00040688543360871404, 'India': 0.0026994449996861265, 'Iran': 0.0012345983254516651, 'Ireland': 0.000583518308397231, 'Italy': 0.0020298072457196714, 'Jamaica': 0.002418630971181892, 'Japan': 0.0019346626674100781, 'Laos': 0.0005085181113512882, 'Mexico': 0.02920982867446892, 'Nicaragua': 0.0015055085108452585, 'Outlying-US(Guam-USVI-etc)': 0.00046019119997985937, 'Peru': 0.0013488914492551592, 'Philippines': 0.005207780964956726, 'Poland': 0.0017265999203321452, 'Portugal': 0.0010919792064197425, 'Puerto-Rico': 0.004064267230465031, 'Scotland': 0.0003546663966352996, 'South': 0.0020754486929779234, 'Taiwan': 0.0012956487254953454, 'Thailand': 0.0005933743298009886, 'Trinadad&Tobago': 0.0006071571286530288, 'United-States': 0.8854902228141374, 'Vietnam': 0.0015862030533496602, 'Yugoslavia': 0.0005276729179264515}\n"
     ]
    }
   ],
   "source": [
    "ncountry_distribution = (data.groupby('native-country')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(ncountry_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6b6cb8",
   "metadata": {},
   "source": [
    "# Wheighted Workclass Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5416f357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Federal-gov': 0.028380069488549937, 'Local-gov': 0.06437528452930555, 'Never-worked': 0.00023212775265828018, 'Private': 0.7051966278850047, 'Self-emp-inc': 0.03275067868712141, 'Self-emp-not-inc': 0.07319917748192728, 'State-gov': 0.03890616400732109, 'Without-pay': 0.00038062581109622506}\n"
     ]
    }
   ],
   "source": [
    "workclass_distribution = (data.groupby('workclass')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(workclass_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05717e4",
   "metadata": {},
   "source": [
    "# Wheighted Income Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc469a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<=50K': 0.7622240390354357, '>50K': 0.2377759609645643}\n"
     ]
    }
   ],
   "source": [
    "income_distribution = (data.groupby('income')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(income_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163346c7",
   "metadata": {},
   "source": [
    "# Wheighted Sex Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91d60d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Female': 0.32424719304894256, 'Male': 0.6757528069510574}\n"
     ]
    }
   ],
   "source": [
    "sex_distribution = (data.groupby('sex')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(sex_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be109aee",
   "metadata": {},
   "source": [
    "# Wheighted Relationship Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b0598e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Husband': 0.39841025891757864, 'Not-in-family': 0.25856131437726904, 'Other-relative': 0.03308744508422627, 'Own-child': 0.15858494253209673, 'Unmarried': 0.10587409719372355, 'Wife': 0.04548194189510577}\n"
     ]
    }
   ],
   "source": [
    "relationship_distribution = (data.groupby('relationship')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(relationship_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e18149",
   "metadata": {},
   "source": [
    "# Wheighted Average Hours per Weak Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3600a96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.0005355909187801483, 2: 0.001110879143807656, 3: 0.0011775734768106653, 4: 0.001502640719727734, 5: 0.001782997041601753, 6: 0.0017477536310751623, 7: 0.0008876964252294569, 8: 0.004306831773788993, 9: 0.0005425860578457053, 10: 0.00822093884464027, 11: 0.00029105478255659766, 12: 0.00464480234954009, 13: 0.0005934932903449739, 14: 0.001068289757765461, 15: 0.012683411491090814, 16: 0.005952873923857416, 17: 0.0009196336610004795, 18: 0.002499484415610746, 19: 0.00037384246929681955, 20: 0.03775265175785208, 21: 0.0009668757860683624, 22: 0.0012101099412383685, 23: 0.000869856013920686, 24: 0.007465276748769972, 25: 0.020016737139702544, 26: 0.0008324194977574308, 27: 0.0008371259957222337, 28: 0.0029465861775135357, 29: 0.0003484678182358651, 30: 0.035563565627408374, 31: 0.00024778768844258833, 32: 0.008798474473991942, 33: 0.0013127072572940571, 34: 0.0009296414596500113, 35: 0.039750254268501276, 36: 0.007376472162936601, 37: 0.004874414119077986, 38: 0.014070435839875153, 39: 0.0011599365506429218, 40: 0.4750028149551481, 41: 0.0010720054935953304, 42: 0.006574459498380249, 43: 0.004373176349838724, 44: 0.006600522652480711, 45: 0.05462403066190879, 46: 0.002475315778340539, 47: 0.0016496344994175534, 48: 0.0162560565697898, 49: 0.0007953133076056048, 50: 0.08643813266238533, 51: 0.0003386656637208994, 52: 0.0043745867123679135, 53: 0.0007236105413913981, 54: 0.0012943107971993806, 55: 0.020353896257732103, 56: 0.002779384110351319, 57: 0.00026824048193324943, 58: 0.0007148367154989401, 59: 0.00014840543761513242, 60: 0.043008709545530134, 61: 7.752902617788323e-05, 62: 0.0003895966451490943, 63: 0.0003774625617129223, 64: 0.00042595603943586594, 65: 0.007006211463920572, 66: 0.0004102484978440283, 67: 9.925357481254628e-05, 68: 0.00022206727456640274, 69: 2.1828180324523158e-05, 70: 0.008170033015486801, 72: 0.002030608340272225, 73: 6.930606748683779e-05, 74: 5.515926232416409e-05, 75: 0.002009212606353514, 76: 8.792296082182094e-05, 77: 0.00022777176729449377, 78: 0.00029280540246749486, 79: 4.941504411496002e-06, 80: 0.004183963127649575, 81: 6.459751847817315e-05, 82: 3.0540043102419042e-06, 84: 0.0011761069804494678, 85: 0.0002735752470178291, 86: 5.313391048546066e-05, 87: 9.336783457687702e-06, 88: 0.00012357172238531235, 89: 3.8341350355346186e-05, 90: 0.000844305944634708, 91: 4.110939597138037e-05, 92: 7.604730891223761e-05, 94: 3.0337097709776337e-05, 95: 3.228450988173081e-05, 96: 0.0002801515413368683, 97: 3.592813532740593e-05, 98: 0.0002679081048779585, 99: 0.0024500539346919837}\n",
      "{40: 0.4750028149551481, 50: 0.08643813266238533, 45: 0.05462403066190879, 60: 0.043008709545530134, 35: 0.039750254268501276, 20: 0.03775265175785208, 30: 0.035563565627408374, 55: 0.020353896257732103, 25: 0.020016737139702544, 48: 0.0162560565697898, 38: 0.014070435839875153, 15: 0.012683411491090814, 32: 0.008798474473991942, 10: 0.00822093884464027, 70: 0.008170033015486801, 24: 0.007465276748769972, 36: 0.007376472162936601, 65: 0.007006211463920572, 44: 0.006600522652480711, 42: 0.006574459498380249, 16: 0.005952873923857416, 37: 0.004874414119077986, 12: 0.00464480234954009, 52: 0.0043745867123679135, 43: 0.004373176349838724, 8: 0.004306831773788993, 80: 0.004183963127649575, 28: 0.0029465861775135357, 56: 0.002779384110351319, 18: 0.002499484415610746, 46: 0.002475315778340539, 99: 0.0024500539346919837, 72: 0.002030608340272225, 75: 0.002009212606353514, 5: 0.001782997041601753, 6: 0.0017477536310751623, 47: 0.0016496344994175534, 4: 0.001502640719727734, 33: 0.0013127072572940571, 54: 0.0012943107971993806, 22: 0.0012101099412383685, 3: 0.0011775734768106653, 84: 0.0011761069804494678, 39: 0.0011599365506429218, 2: 0.001110879143807656, 41: 0.0010720054935953304, 14: 0.001068289757765461, 21: 0.0009668757860683624, 34: 0.0009296414596500113, 17: 0.0009196336610004795, 7: 0.0008876964252294569, 23: 0.000869856013920686, 90: 0.000844305944634708, 27: 0.0008371259957222337, 26: 0.0008324194977574308, 49: 0.0007953133076056048, 53: 0.0007236105413913981, 58: 0.0007148367154989401, 13: 0.0005934932903449739, 9: 0.0005425860578457053, 1: 0.0005355909187801483, 64: 0.00042595603943586594, 66: 0.0004102484978440283, 62: 0.0003895966451490943, 63: 0.0003774625617129223, 19: 0.00037384246929681955, 29: 0.0003484678182358651, 51: 0.0003386656637208994, 78: 0.00029280540246749486, 11: 0.00029105478255659766, 96: 0.0002801515413368683, 85: 0.0002735752470178291, 57: 0.00026824048193324943, 98: 0.0002679081048779585, 31: 0.00024778768844258833, 77: 0.00022777176729449377, 68: 0.00022206727456640274, 59: 0.00014840543761513242, 88: 0.00012357172238531235, 67: 9.925357481254628e-05, 76: 8.792296082182094e-05, 61: 7.752902617788323e-05, 92: 7.604730891223761e-05, 73: 6.930606748683779e-05, 81: 6.459751847817315e-05, 74: 5.515926232416409e-05, 86: 5.313391048546066e-05, 91: 4.110939597138037e-05, 89: 3.8341350355346186e-05, 97: 3.592813532740593e-05, 95: 3.228450988173081e-05, 94: 3.0337097709776337e-05, 69: 2.1828180324523158e-05, 87: 9.336783457687702e-06, 79: 4.941504411496002e-06, 82: 3.0540043102419042e-06}\n",
      "{'<40': 0.2381721704989729, '40': 0.4750028149551481, '>40': 0.28682501454587894}\n",
      "Average Hours: 40.32911200806684\n"
     ]
    }
   ],
   "source": [
    "hours_per_week_distribution = (data.groupby('hours-per-week')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(hours_per_week_distribution)\n",
    "sorted_hours_per_week = dict(sorted(hours_per_week_distribution.items(), key=lambda item: item[1], reverse=True))\n",
    "print(sorted_hours_per_week)\n",
    "\n",
    "hours_per_week_distribution_grouped = {\"<40\":0, \"40\":0, \">40\":0}\n",
    "for key, value in hours_per_week_distribution.items():\n",
    "    if key < 40:\n",
    "        hours_per_week_distribution_grouped[\"<40\"] += value\n",
    "    elif key == 40:\n",
    "        hours_per_week_distribution_grouped[\"40\"] += value\n",
    "    else:\n",
    "        hours_per_week_distribution_grouped[\">40\"] += value\n",
    "print(hours_per_week_distribution_grouped)\n",
    "\n",
    "\n",
    "average_hours_per_week = 0\n",
    "for key, value in hours_per_week_distribution.items():\n",
    "    average_hours_per_week += key * value\n",
    "print(\"Average Hours:\" , average_hours_per_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6877f",
   "metadata": {},
   "source": [
    "# Class Balance of the Dataset\n",
    "\n",
    "Check the distribution of the target variable (the class you’re trying to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d395c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "<=50K    0.760718\n",
       ">50K     0.239282\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['income'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca8522a",
   "metadata": {},
   "source": [
    "## **Preprocessing the Dataset**\n",
    "\n",
    "In this section, we handle the preprocessing of the Adult Income dataset to prepare it for machine learning.\n",
    "\n",
    "### **Handling Missing Values**\n",
    "\n",
    "The dataset contains some missing values, represented as `\"NaN\"`, particularly in categorical features like `workclass`, `occupation`, and `native-country`. We will address them using two strategies:\n",
    "\n",
    "- **Removing rows with missing values** to eliminate uncertainty.\n",
    "- **Replacing missing values** with the most frequent value (mode) in the respective column.\n",
    "\n",
    "### **Encoding Categorical Features**\n",
    "\n",
    "Machine learning models typically require numerical input. Therefore, we will encode categorical features such as `education`, `marital-status`, and `occupation` using:\n",
    "\n",
    "- **One-hot encoding** for features with no ordinal relationship.\n",
    "- **Label encoding** for features with inherent order (if applicable).\n",
    "\n",
    "### **Transforming Numerical Features**\n",
    "\n",
    "Some continuous numerical features contain extreme or highly granular values that could introduce noise:\n",
    "\n",
    "- `hours-per-week` includes values as low as 1 and as high as 99 — we may **clip or bin these values** into broader categories (e.g., part-time, full-time, overtime).\n",
    "- `capital-gain` and `capital-loss` have **many rare and highly specific values**, most of which are zero — we may **bucketize or simplify** these into categories like \"none\", \"low\", and \"high\".\n",
    "- We will also consider removing these features completely to see what results we achieve.\n",
    "\n",
    "### **Splitting the Data**\n",
    "\n",
    "We will explore two approaches to splitting the dataset for training and testing:\n",
    "\n",
    "- Use the **original train/test split** provided with the dataset.\n",
    "- Perform **random train/test splits** (e.g., 80/20 or 70/30) using `train_test_split` for experimentation and validation.\n",
    "\n",
    "### **Optional: Addressing Class Imbalance**\n",
    "\n",
    "If we find that the dataset is imbalanced (e.g., far more samples with income ≤50K than >50K), we may apply techniques to balance the classes:\n",
    "\n",
    "- **Oversampling** the minority class.\n",
    "- **Undersampling** the majority class.\n",
    "- Using synthetic data generation methods like **SMOTE (Synthetic Minority Over-sampling Technique)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9224326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pronto aqui é para fazer o que diz em cima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1a763",
   "metadata": {},
   "source": [
    "## **Model Implementation**\n",
    "\n",
    "In this section, we will implement and evaluate various machine learning models to predict whether an individual's income exceeds $50K based on the features in the dataset. The objective is to confirm and apply machine learning theory learned in class, deepen our understanding of classification models, and identify the most effective approach for this problem.\n",
    "\n",
    "### **Implemented Models**\n",
    "\n",
    "We will start by implementing the following classification models:\n",
    "\n",
    "- **Logistic Regression**  \n",
    "  A simple and interpretable linear model; it's a good baseline for binary classification tasks.\n",
    "\n",
    "- **Random Forest Classifier**  \n",
    "  A robust ensemble method that reduces overfitting; chosen for its ability to handle non-linear relationships and mixed feature types.\n",
    "\n",
    "- **Gradient Boosting (XGBoost or LightGBM)**  \n",
    "  A highly accurate boosting algorithm; selected for its strong performance in structured/tabular data and ability to capture complex patterns.\n",
    "\n",
    "### **Optional Models (for Extended Work)**\n",
    "\n",
    "For further exploration and comparison, the following models may be implemented:\n",
    "\n",
    "- **Support Vector Machine (SVM)**  \n",
    "  Effective in high-dimensional spaces; useful for classification with clear margins of separation.\n",
    "\n",
    "- **K-Nearest Neighbors (KNN)**  \n",
    "  A simple, instance-based method that can perform well with normalized data and lower dimensions.\n",
    "\n",
    "- **Neural Network (MLPClassifier)**  \n",
    "  A basic feed-forward neural network; useful for modeling non-linear relationships in the data.\n",
    "\n",
    "- **Naive Bayes**  \n",
    "  Fast and efficient, especially on categorical data; good as a quick baseline for comparison.\n",
    "\n",
    "### **Hyperparameter Tuning and Model Selection (Optional)**\n",
    "\n",
    "To improve model performance, we may apply:\n",
    "\n",
    "- **Cross-validation**  \n",
    "  Using k-fold cross-validation to evaluate model reliability across different data splits.\n",
    "\n",
    "- **Grid Search or Randomized Search**  \n",
    "  For systematic tuning of hyperparameters, especially in Random Forest and Gradient Boosting models.\n",
    "\n",
    "### **Evaluation Metrics**\n",
    "\n",
    "All models will be evaluated using key classification metrics to gain a comprehensive view of performance:\n",
    "\n",
    "- **Accuracy**  \n",
    "  The proportion of total predictions that are correct. Good for balanced datasets.\n",
    "\n",
    "- **Precision**  \n",
    "  The proportion of positive predictions that were actually correct. Important when false positives are costly.\n",
    "\n",
    "- **Recall**  \n",
    "  The proportion of actual positives that were correctly predicted. Important when false negatives are costly.\n",
    "\n",
    "- **F1-Score**  \n",
    "  The harmonic mean of precision and recall. Useful when you need a balance between precision and recall.\n",
    "\n",
    "- **ROC AUC Score**  \n",
    "  Measures the ability of the model to distinguish between classes across different thresholds. A higher score indicates better overall classification performance.\n",
    "\n",
    "---\n",
    "\n",
    "Through this modeling process, we aim to validate theoretical concepts covered in class, enhance practical skills with real-world data, and gain insights into which algorithms are most suitable for income prediction tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda469e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer o que diz em cima"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
