{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d410884",
   "metadata": {},
   "source": [
    "# Dataset Context and Exploration\n",
    "\n",
    "**age**  \n",
    "- Demographic: Age  \n",
    "- Description: How old is this sample of people  \n",
    "- Data Type: Integer  \n",
    "- Missing Values: No  \n",
    "\n",
    "**workclass**  \n",
    "- Demographic: Income  \n",
    "- Description: Employment classification  \n",
    "- Possible values: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked  \n",
    "- Data Type: Categorical  \n",
    "- Missing Values: Yes  \n",
    "\n",
    "**fnlwgt**  \n",
    "- Demographic:  \n",
    "- Description: Final weight representing the number of people the census believes the entry represents  \n",
    "- Data Type: Integer  \n",
    "- Missing Values: No  \n",
    "\n",
    "**education**  \n",
    "- Demographic: Education Level  \n",
    "- Description: Highest level of education achieved  \n",
    "- Possible values: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool  \n",
    "- Data Type: Categorical  \n",
    "- Missing Values: No  \n",
    "\n",
    "**education-num**  \n",
    "- Demographic: Education Level  \n",
    "- Description: Numeric representation of education level  \n",
    "- Data Type: Integer  \n",
    "- Missing Values: No  \n",
    "\n",
    "**marital-status**  \n",
    "- Demographic: Other  \n",
    "- Description: Marital status of the individual  \n",
    "- Possible values: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse  \n",
    "- Data Type: Categorical  \n",
    "- Missing Values: No  \n",
    "\n",
    "**occupation**  \n",
    "- Demographic: Other  \n",
    "- Description: Type of job  \n",
    "- Possible values: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces  \n",
    "- Data Type: Categorical  \n",
    "- Missing Values: Yes  \n",
    "\n",
    "**relationship**  \n",
    "- Demographic: Other  \n",
    "- Description: Relationship within household  \n",
    "- Possible values: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried  \n",
    "- Data Type: Categorical  \n",
    "- Missing Values: No  \n",
    "\n",
    "**race**  \n",
    "- Demographic: Race  \n",
    "- Description: Race of the individual  \n",
    "- Possible values: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black  \n",
    "- Data Type: Categorical  \n",
    "- Missing Values: No  \n",
    "\n",
    "**sex**  \n",
    "- Demographic: Sex  \n",
    "- Description: Gender of the individual  \n",
    "- Possible values: Female, Male  \n",
    "- Data Type: Binary  \n",
    "- Missing Values: No  \n",
    "\n",
    "**capital-gain**  \n",
    "- Demographic:  \n",
    "- Description: Income from capital gains  \n",
    "- Data Type: Integer  \n",
    "- Missing Values: No  \n",
    "\n",
    "**capital-loss**  \n",
    "- Demographic:  \n",
    "- Description: Capital losses  \n",
    "- Data Type: Integer  \n",
    "- Missing Values: No  \n",
    "\n",
    "**hours-per-week**  \n",
    "- Demographic:  \n",
    "- Description: Number of hours worked per week  \n",
    "- Data Type: Integer  \n",
    "- Missing Values: No  \n",
    "\n",
    "**native-country**  \n",
    "- Demographic: Other  \n",
    "- Description: Country of origin  \n",
    "- Possible values: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands  \n",
    "- Data Type: Categorical  \n",
    "- Missing Values: Yes  \n",
    "\n",
    "**income**  \n",
    "- Demographic: Income  \n",
    "- Description: Income class  \n",
    "- Possible values: >50K, <=50K  \n",
    "- Data Type: Binary  \n",
    "- Missing Values: No  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb6049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9ed00",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f607c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                  0\n",
      "workclass         2799\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education-num        0\n",
      "marital-status       0\n",
      "occupation        2809\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital-gain         0\n",
      "capital-loss         0\n",
      "hours-per-week       0\n",
      "native-country     857\n",
      "income               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('base_data/adultdataset.csv', na_values='NaN', skipinitialspace=True)\n",
    "\n",
    "#Identify and count the number of missing values in each column, the missing values are repesented by \"NaN\"\n",
    "missing_values = df.isna().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca1cdf5",
   "metadata": {},
   "source": [
    "# Total fnlwgt\n",
    "\n",
    "The fnlwgt represent the wheight a certain row has over the whole dataset, this works like a percentage.\n",
    "From this point forward if we discribe something as wheighted it means that it wheighted to the total fnlwgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a987500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9263575662\n"
     ]
    }
   ],
   "source": [
    "total_fnlwgt = df['fnlwgt'].sum()\n",
    "print(total_fnlwgt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57702e4b",
   "metadata": {},
   "source": [
    "# Wheighted Age Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "376abf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'17-26': 0.23254280804728855, '27-36': 0.27141756733459493, '37-46': 0.23722836582580933, '47-56': 0.1511744520795171, '57-66': 0.07870687525021912, '67-76': 0.023731706850714768, '77-86': 0.004034587978086512, '87-99': 0.001163636633769635}\n"
     ]
    }
   ],
   "source": [
    "age_bins = [(17, 26), (27, 36), (37, 46), (47, 56), (57, 66), (67, 76), (77, 86), (87, 99)]\n",
    "\n",
    "age_distribution = (df.groupby('age')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "\n",
    "# Aggregate into custom age ranges\n",
    "age_ranges = {}\n",
    "for start, end in age_bins:\n",
    "    label = f'{start}-{end}'\n",
    "    age_ranges[label] = sum(age_distribution.get(age, 0) for age in range(start, end + 1))\n",
    "\n",
    "print(age_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf6cee",
   "metadata": {},
   "source": [
    "# Wheighted Education Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bfcbf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10th': 0.029468504815025498, '11th': 0.03816294386736559, '12th': 0.01400998833877717, '1st-4th': 0.0062664863027056044, '5th-6th': 0.012629909796056028, '7th-8th': 0.019338862285637366, '9th': 0.016240940376528228, 'Assoc-acdm': 0.03347668679083759, 'Assoc-voc': 0.0399183750953639, 'Bachelors': 0.163176883759985, 'Doctorate': 0.011804269538010278, 'HS-grad': 0.32139634430936437, 'Masters': 0.0520525309657691, 'Preschool': 0.0021408804465594703, 'Prof-school': 0.016798332164364632, 'Some-college': 0.22311806114765018}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "education_distribution = (df.groupby('education')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(education_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7d20fb",
   "metadata": {},
   "source": [
    "# Wheighted Race Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bed862e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Amer-Indian-Eskimo': 0.00609399275827926, 'Asian-Pac-Islander': 0.026202793700461278, 'Black': 0.11656649596219383, 'Other': 0.008577742860778288, 'White': 0.8425589747182873}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "race_distribution = (df.groupby('race')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(race_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bb02c1",
   "metadata": {},
   "source": [
    "# Wheighted Native Country Distribuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e324f64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cambodia': 0.0006054133095717787, 'Canada': 0.0035612337183499113, 'China': 0.002275493585750992, 'Columbia': 0.001998964619672796, 'Cuba': 0.003584282917470276, 'Dominican-Republic': 0.002264667852399304, 'Ecuador': 0.000867478746135166, 'El-Salvador': 0.004194289701695103, 'England': 0.0025167153430435273, 'France': 0.0007650541495625774, 'Germany': 0.004291807337752816, 'Greece': 0.000795958306925307, 'Guatemala': 0.0024352646130521775, 'Haiti': 0.0017626972128033124, 'Holand-Netherlands': 3.009852892374422e-06, 'Honduras': 0.0005169305217253592, 'Hong': 0.0006895137723332388, 'Hungary': 0.00040688543360871404, 'India': 0.0026994449996861265, 'Iran': 0.0012345983254516651, 'Ireland': 0.000583518308397231, 'Italy': 0.0020298072457196714, 'Jamaica': 0.002418630971181892, 'Japan': 0.0019346626674100781, 'Laos': 0.0005085181113512882, 'Mexico': 0.02920982867446892, 'Nicaragua': 0.0015055085108452585, 'Outlying-US(Guam-USVI-etc)': 0.00046019119997985937, 'Peru': 0.0013488914492551592, 'Philippines': 0.005207780964956726, 'Poland': 0.0017265999203321452, 'Portugal': 0.0010919792064197425, 'Puerto-Rico': 0.004064267230465031, 'Scotland': 0.0003546663966352996, 'South': 0.0020754486929779234, 'Taiwan': 0.0012956487254953454, 'Thailand': 0.0005933743298009886, 'Trinadad&Tobago': 0.0006071571286530288, 'United-States': 0.8854902228141374, 'Vietnam': 0.0015862030533496602, 'Yugoslavia': 0.0005276729179264515}\n"
     ]
    }
   ],
   "source": [
    "ncountry_distribution = (df.groupby('native-country')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(ncountry_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6b6cb8",
   "metadata": {},
   "source": [
    "# Wheighted Workclass Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5416f357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Federal-gov': 0.028380069488549937, 'Local-gov': 0.06437528452930555, 'Never-worked': 0.00023212775265828018, 'Private': 0.7051966278850047, 'Self-emp-inc': 0.03275067868712141, 'Self-emp-not-inc': 0.07319917748192728, 'State-gov': 0.03890616400732109, 'Without-pay': 0.00038062581109622506}\n"
     ]
    }
   ],
   "source": [
    "workclass_distribution = (df.groupby('workclass')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(workclass_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05717e4",
   "metadata": {},
   "source": [
    "# Wheighted Income Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc469a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<=50K': 0.7622240390354357, '>50K': 0.2377759609645643}\n"
     ]
    }
   ],
   "source": [
    "income_distribution = (df.groupby('income')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(income_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163346c7",
   "metadata": {},
   "source": [
    "# Wheighted Sex Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d60d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Female': 0.32424719304894256, 'Male': 0.6757528069510574}\n"
     ]
    }
   ],
   "source": [
    "sex_distribution = (df.groupby('sex')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(sex_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be109aee",
   "metadata": {},
   "source": [
    "# Wheighted Relationship Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b0598e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Husband': 0.39841025891757864, 'Not-in-family': 0.25856131437726904, 'Other-relative': 0.03308744508422627, 'Own-child': 0.15858494253209673, 'Unmarried': 0.10587409719372355, 'Wife': 0.04548194189510577}\n"
     ]
    }
   ],
   "source": [
    "relationship_distribution = (df.groupby('relationship')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(relationship_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e18149",
   "metadata": {},
   "source": [
    "# Wheighted Average Hours per Week Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3600a96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.0005355909187801483, 2: 0.001110879143807656, 3: 0.0011775734768106653, 4: 0.001502640719727734, 5: 0.001782997041601753, 6: 0.0017477536310751623, 7: 0.0008876964252294569, 8: 0.004306831773788993, 9: 0.0005425860578457053, 10: 0.00822093884464027, 11: 0.00029105478255659766, 12: 0.00464480234954009, 13: 0.0005934932903449739, 14: 0.001068289757765461, 15: 0.012683411491090814, 16: 0.005952873923857416, 17: 0.0009196336610004795, 18: 0.002499484415610746, 19: 0.00037384246929681955, 20: 0.03775265175785208, 21: 0.0009668757860683624, 22: 0.0012101099412383685, 23: 0.000869856013920686, 24: 0.007465276748769972, 25: 0.020016737139702544, 26: 0.0008324194977574308, 27: 0.0008371259957222337, 28: 0.0029465861775135357, 29: 0.0003484678182358651, 30: 0.035563565627408374, 31: 0.00024778768844258833, 32: 0.008798474473991942, 33: 0.0013127072572940571, 34: 0.0009296414596500113, 35: 0.039750254268501276, 36: 0.007376472162936601, 37: 0.004874414119077986, 38: 0.014070435839875153, 39: 0.0011599365506429218, 40: 0.4750028149551481, 41: 0.0010720054935953304, 42: 0.006574459498380249, 43: 0.004373176349838724, 44: 0.006600522652480711, 45: 0.05462403066190879, 46: 0.002475315778340539, 47: 0.0016496344994175534, 48: 0.0162560565697898, 49: 0.0007953133076056048, 50: 0.08643813266238533, 51: 0.0003386656637208994, 52: 0.0043745867123679135, 53: 0.0007236105413913981, 54: 0.0012943107971993806, 55: 0.020353896257732103, 56: 0.002779384110351319, 57: 0.00026824048193324943, 58: 0.0007148367154989401, 59: 0.00014840543761513242, 60: 0.043008709545530134, 61: 7.752902617788323e-05, 62: 0.0003895966451490943, 63: 0.0003774625617129223, 64: 0.00042595603943586594, 65: 0.007006211463920572, 66: 0.0004102484978440283, 67: 9.925357481254628e-05, 68: 0.00022206727456640274, 69: 2.1828180324523158e-05, 70: 0.008170033015486801, 72: 0.002030608340272225, 73: 6.930606748683779e-05, 74: 5.515926232416409e-05, 75: 0.002009212606353514, 76: 8.792296082182094e-05, 77: 0.00022777176729449377, 78: 0.00029280540246749486, 79: 4.941504411496002e-06, 80: 0.004183963127649575, 81: 6.459751847817315e-05, 82: 3.0540043102419042e-06, 84: 0.0011761069804494678, 85: 0.0002735752470178291, 86: 5.313391048546066e-05, 87: 9.336783457687702e-06, 88: 0.00012357172238531235, 89: 3.8341350355346186e-05, 90: 0.000844305944634708, 91: 4.110939597138037e-05, 92: 7.604730891223761e-05, 94: 3.0337097709776337e-05, 95: 3.228450988173081e-05, 96: 0.0002801515413368683, 97: 3.592813532740593e-05, 98: 0.0002679081048779585, 99: 0.0024500539346919837}\n",
      "{40: 0.4750028149551481, 50: 0.08643813266238533, 45: 0.05462403066190879, 60: 0.043008709545530134, 35: 0.039750254268501276, 20: 0.03775265175785208, 30: 0.035563565627408374, 55: 0.020353896257732103, 25: 0.020016737139702544, 48: 0.0162560565697898, 38: 0.014070435839875153, 15: 0.012683411491090814, 32: 0.008798474473991942, 10: 0.00822093884464027, 70: 0.008170033015486801, 24: 0.007465276748769972, 36: 0.007376472162936601, 65: 0.007006211463920572, 44: 0.006600522652480711, 42: 0.006574459498380249, 16: 0.005952873923857416, 37: 0.004874414119077986, 12: 0.00464480234954009, 52: 0.0043745867123679135, 43: 0.004373176349838724, 8: 0.004306831773788993, 80: 0.004183963127649575, 28: 0.0029465861775135357, 56: 0.002779384110351319, 18: 0.002499484415610746, 46: 0.002475315778340539, 99: 0.0024500539346919837, 72: 0.002030608340272225, 75: 0.002009212606353514, 5: 0.001782997041601753, 6: 0.0017477536310751623, 47: 0.0016496344994175534, 4: 0.001502640719727734, 33: 0.0013127072572940571, 54: 0.0012943107971993806, 22: 0.0012101099412383685, 3: 0.0011775734768106653, 84: 0.0011761069804494678, 39: 0.0011599365506429218, 2: 0.001110879143807656, 41: 0.0010720054935953304, 14: 0.001068289757765461, 21: 0.0009668757860683624, 34: 0.0009296414596500113, 17: 0.0009196336610004795, 7: 0.0008876964252294569, 23: 0.000869856013920686, 90: 0.000844305944634708, 27: 0.0008371259957222337, 26: 0.0008324194977574308, 49: 0.0007953133076056048, 53: 0.0007236105413913981, 58: 0.0007148367154989401, 13: 0.0005934932903449739, 9: 0.0005425860578457053, 1: 0.0005355909187801483, 64: 0.00042595603943586594, 66: 0.0004102484978440283, 62: 0.0003895966451490943, 63: 0.0003774625617129223, 19: 0.00037384246929681955, 29: 0.0003484678182358651, 51: 0.0003386656637208994, 78: 0.00029280540246749486, 11: 0.00029105478255659766, 96: 0.0002801515413368683, 85: 0.0002735752470178291, 57: 0.00026824048193324943, 98: 0.0002679081048779585, 31: 0.00024778768844258833, 77: 0.00022777176729449377, 68: 0.00022206727456640274, 59: 0.00014840543761513242, 88: 0.00012357172238531235, 67: 9.925357481254628e-05, 76: 8.792296082182094e-05, 61: 7.752902617788323e-05, 92: 7.604730891223761e-05, 73: 6.930606748683779e-05, 81: 6.459751847817315e-05, 74: 5.515926232416409e-05, 86: 5.313391048546066e-05, 91: 4.110939597138037e-05, 89: 3.8341350355346186e-05, 97: 3.592813532740593e-05, 95: 3.228450988173081e-05, 94: 3.0337097709776337e-05, 69: 2.1828180324523158e-05, 87: 9.336783457687702e-06, 79: 4.941504411496002e-06, 82: 3.0540043102419042e-06}\n",
      "{'<40': 0.2381721704989729, '40': 0.4750028149551481, '>40': 0.28682501454587894}\n",
      "Average Hours: 40.32911200806684\n"
     ]
    }
   ],
   "source": [
    "hours_per_week_distribution = (df.groupby('hours-per-week')['fnlwgt'].sum() / total_fnlwgt).to_dict()\n",
    "print(hours_per_week_distribution)\n",
    "sorted_hours_per_week = dict(sorted(hours_per_week_distribution.items(), key=lambda item: item[1], reverse=True))\n",
    "print(sorted_hours_per_week)\n",
    "\n",
    "hours_per_week_distribution_grouped = {\"<40\":0, \"40\":0, \">40\":0}\n",
    "for key, value in hours_per_week_distribution.items():\n",
    "    if key < 40:\n",
    "        hours_per_week_distribution_grouped[\"<40\"] += value\n",
    "    elif key == 40:\n",
    "        hours_per_week_distribution_grouped[\"40\"] += value\n",
    "    else:\n",
    "        hours_per_week_distribution_grouped[\">40\"] += value\n",
    "print(hours_per_week_distribution_grouped)\n",
    "\n",
    "\n",
    "average_hours_per_week = 0\n",
    "for key, value in hours_per_week_distribution.items():\n",
    "    average_hours_per_week += key * value\n",
    "print(\"Average Hours:\" , average_hours_per_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6877f",
   "metadata": {},
   "source": [
    "# Class Balance of the Dataset\n",
    "\n",
    "Check the distribution of the target variable (the class you’re trying to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d395c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "income",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "proportion",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "108ca402-2a13-4a7c-a315-e740e2afeb2a",
       "rows": [
        [
         "<=50K",
         "0.7607182343065395"
        ],
        [
         ">50K",
         "0.23928176569346055"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "income\n",
       "<=50K    0.760718\n",
       ">50K     0.239282\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['income'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca8522a",
   "metadata": {},
   "source": [
    "## **Preprocessing the Dataset**\n",
    "\n",
    "In this section, we handle the preprocessing of the Adult Income dataset to prepare it for machine learning.\n",
    "\n",
    "### **Handling Missing Values**\n",
    "\n",
    "The dataset contains some missing values, represented as `\"NaN\"`, particularly in categorical features like `workclass`, `occupation`, and `native-country`. We will address them using two strategies:\n",
    "\n",
    "- **Removing rows with missing values** to eliminate uncertainty.\n",
    "- **Replacing missing values** with the most frequent value (mode) in the respective column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85fced8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: workclass\n",
      "  Most common value: Private\n",
      "  Frequency: 33906 (73.64% of non-missing values)\n",
      "\n",
      "Column: occupation\n",
      "  Most common value: Prof-specialty\n",
      "  Frequency: 6172 (13.41% of non-missing values)\n",
      "\n",
      "Column: native-country\n",
      "  Most common value: United-States\n",
      "  Frequency: 43832 (91.35% of non-missing values)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['workclass', 'occupation', 'native-country']\n",
    "\n",
    "for col in columns:\n",
    "    mode_value = df[col].mode()[0]\n",
    "    mode_count = df[col].value_counts().loc[mode_value]\n",
    "    total_non_missing = df[col].notna().sum()\n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"  Most common value: {mode_value}\")\n",
    "    print(f\"  Frequency: {mode_count} ({mode_count / total_non_missing:.2%} of non-missing values)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ddad8",
   "metadata": {},
   "source": [
    "### **Missing Values Chosen Strategy** \n",
    "\n",
    "Missing values in the workclass, occupation, and native-country columns were imputed using the most frequent value (mode) in each column. This strategy retains more data while introducing minimal bias, as the mode values were dominant — especially in native-country (>91%) and workclass (>73%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7874876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of rows: 48842\n",
      "Remaining rows after dropping: 45222\n",
      "Rows dropped: 3620\n",
      "Percentage of data lost: 7.41%\n"
     ]
    }
   ],
   "source": [
    "original_rows = df.shape[0]\n",
    "\n",
    "# Drop rows with missing values in the selected columns\n",
    "df_dropped = df.dropna(subset=['workclass', 'occupation', 'native-country'])\n",
    "\n",
    "# Number of rows after dropping\n",
    "remaining_rows = df_dropped.shape[0]\n",
    "\n",
    "# Number of rows removed\n",
    "rows_dropped = original_rows - remaining_rows\n",
    "\n",
    "# Percentage of data lost\n",
    "percent_lost = (rows_dropped / original_rows) * 100\n",
    "\n",
    "print(f\"Original number of rows: {original_rows}\")\n",
    "print(f\"Remaining rows after dropping: {remaining_rows}\")\n",
    "print(f\"Rows dropped: {rows_dropped}\")\n",
    "print(f\"Percentage of data lost: {percent_lost:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a569cd",
   "metadata": {},
   "source": [
    "### **Dropping Rows with missing Values**\n",
    "\n",
    "The dataset contains missing values in the workclass, occupation, and native-country columns. Dropping rows with missing values would result in a loss of 7.41% of the data (3,620 rows). To preserve the dataset size and avoid potential bias introduced by data loss, we chose to impute missing values using the most frequent (mode) value for each column. The dominant presence of these mode values (e.g., native-country = \"United-States\" at 91%) supports this choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed2da4",
   "metadata": {},
   "source": [
    "### **Dataset After This Step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c93e305d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputation:\n",
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital-gain      0\n",
      "capital-loss      0\n",
      "hours-per-week    0\n",
      "native-country    0\n",
      "income            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "columns_to_impute = ['workclass', 'occupation', 'native-country']\n",
    "for col in columns_to_impute:\n",
    "    mode_val = df[col].mode()[0]\n",
    "    df[col] = df[col].fillna(mode_val)\n",
    "\n",
    "# Check if there are any missing values left\n",
    "missing_values_after = df.isna().sum()\n",
    "print(\"Missing values after imputation:\")\n",
    "print(missing_values_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ae8793",
   "metadata": {},
   "source": [
    "### **Encoding Categorical Features**\n",
    "\n",
    "Machine learning models typically require numerical input. Therefore, we will encode categorical features such as `education`, `marital-status`, and `occupation` using:\n",
    "\n",
    "- **One-hot encoding** for features with no ordinal relationship.\n",
    "- **Label encoding** for features with inherent order (if applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "173151e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48842, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "print(df.shape)\n",
    "# Label encode 'education' (ordinal)\n",
    "education_order = [\n",
    "    'Preschool', '1st-4th', '5th-6th', '7th-8th', '9th',\n",
    "    '10th', '11th', '12th', 'HS-grad',\n",
    "    'Some-college', 'Assoc-voc', 'Assoc-acdm',\n",
    "    'Bachelors', 'Masters', 'Doctorate'\n",
    "]\n",
    "\n",
    "df['education'] = pd.Categorical(df['education'], categories=education_order, ordered=True)\n",
    "df['education'] = df['education'].cat.codes\n",
    "\n",
    "# One-hot encode nominal categorical features\n",
    "one_hot_cols = [\n",
    "    'workclass', 'marital-status', 'occupation', 'relationship',\n",
    "    'race', 'sex', 'native-country'\n",
    "]\n",
    "\n",
    "df = pd.get_dummies(df, columns=one_hot_cols, drop_first=True)\n",
    "\n",
    "df['income'] = df['income'].map({'<=50K': 0, '>50K': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30080a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fnlwgt",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "education",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "education-num",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "capital-gain",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "capital-loss",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hours-per-week",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "income",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "workclass_Local-gov",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "workclass_Never-worked",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "workclass_Private",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "workclass_Self-emp-inc",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "workclass_Self-emp-not-inc",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "workclass_State-gov",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "workclass_Without-pay",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "marital-status_Married-AF-spouse",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "marital-status_Married-civ-spouse",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "marital-status_Married-spouse-absent",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "marital-status_Never-married",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "marital-status_Separated",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "marital-status_Widowed",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "occupation_Armed-Forces",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "occupation_Craft-repair",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "occupation_Exec-managerial",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "occupation_Farming-fishing",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "occupation_Handlers-cleaners",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "occupation_Machine-op-inspct",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "occupation_Other-service",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "occupation_Priv-house-serv",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "occupation_Prof-specialty",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "occupation_Protective-serv",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "occupation_Sales",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "occupation_Tech-support",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "occupation_Transport-moving",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "relationship_Not-in-family",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "relationship_Other-relative",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "relationship_Own-child",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "relationship_Unmarried",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "relationship_Wife",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "race_Asian-Pac-Islander",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "race_Black",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "race_Other",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "race_White",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "sex_Male",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Canada",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_China",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Columbia",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Cuba",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Dominican-Republic",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Ecuador",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_El-Salvador",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_England",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_France",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Germany",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Greece",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Guatemala",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Haiti",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Holand-Netherlands",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Honduras",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Hong",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Hungary",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_India",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Iran",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Ireland",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Italy",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Jamaica",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Japan",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Laos",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Mexico",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Nicaragua",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Outlying-US(Guam-USVI-etc)",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Peru",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Philippines",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Poland",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Portugal",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Puerto-Rico",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Scotland",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_South",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Taiwan",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Thailand",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Trinadad&Tobago",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_United-States",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Vietnam",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "native-country_Yugoslavia",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "acc8d0a9-0491-4b33-a6fe-7c93f50f4d0e",
       "rows": [
        [
         "0",
         "39",
         "77516",
         "12",
         "13",
         "2174",
         "0",
         "40",
         "0",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "1",
         "50",
         "83311",
         "12",
         "13",
         "0",
         "0",
         "13",
         "0",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "2",
         "38",
         "215646",
         "8",
         "9",
         "0",
         "0",
         "40",
         "0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "3",
         "53",
         "234721",
         "6",
         "7",
         "0",
         "0",
         "40",
         "0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "4",
         "28",
         "338409",
         "12",
         "13",
         "0",
         "0",
         "40",
         "0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ]
       ],
       "shape": {
        "columns": 84,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education  education-num  capital-gain  capital-loss  \\\n",
       "0   39   77516         12             13          2174             0   \n",
       "1   50   83311         12             13             0             0   \n",
       "2   38  215646          8              9             0             0   \n",
       "3   53  234721          6              7             0             0   \n",
       "4   28  338409         12             13             0             0   \n",
       "\n",
       "   hours-per-week  income  workclass_Local-gov  workclass_Never-worked  ...  \\\n",
       "0              40       0                False                   False  ...   \n",
       "1              13       0                False                   False  ...   \n",
       "2              40       0                False                   False  ...   \n",
       "3              40       0                False                   False  ...   \n",
       "4              40       0                False                   False  ...   \n",
       "\n",
       "   native-country_Portugal  native-country_Puerto-Rico  \\\n",
       "0                    False                       False   \n",
       "1                    False                       False   \n",
       "2                    False                       False   \n",
       "3                    False                       False   \n",
       "4                    False                       False   \n",
       "\n",
       "   native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "0                    False                 False                  False   \n",
       "1                    False                 False                  False   \n",
       "2                    False                 False                  False   \n",
       "3                    False                 False                  False   \n",
       "4                    False                 False                  False   \n",
       "\n",
       "   native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "0                    False                           False   \n",
       "1                    False                           False   \n",
       "2                    False                           False   \n",
       "3                    False                           False   \n",
       "4                    False                           False   \n",
       "\n",
       "   native-country_United-States  native-country_Vietnam  \\\n",
       "0                          True                   False   \n",
       "1                          True                   False   \n",
       "2                          True                   False   \n",
       "3                          True                   False   \n",
       "4                         False                   False   \n",
       "\n",
       "   native-country_Yugoslavia  \n",
       "0                      False  \n",
       "1                      False  \n",
       "2                      False  \n",
       "3                      False  \n",
       "4                      False  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows to check encoding results\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ff236",
   "metadata": {},
   "source": [
    "### **Enconding Reasoning and Results**\n",
    "\n",
    "We encoded the categorical features to convert them into a numeric format suitable for machine learning algorithms. Since the education feature has a clear order of attainment levels, we applied label encoding based on its natural hierarchy, preserving the ordinal relationship. For other categorical features without inherent order—such as workclass, marital-status, occupation, relationship, race, sex, and native-country—we applied one-hot encoding, which created new binary columns for each category. This expanded the feature space but allowed models to interpret categorical data effectively. Lastly, the target variable income was binarized to 0 and 1, facilitating binary classification. This preprocessing step transformed all relevant columns into numeric form, enabling downstream model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55bff2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48842, 84)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f24e945",
   "metadata": {},
   "source": [
    "### **Why Does The Data Change Shape**\n",
    "\n",
    "The dataset’s number of columns increases after encoding because one-hot encoding creates a new binary column for each category in the original categorical features. This expands the feature space to convert categorical data into a numeric format suitable for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1458a990",
   "metadata": {},
   "source": [
    "### **Transforming Numerical Features**\n",
    "\n",
    "Some continuous numerical features contain extreme or highly granular values that could introduce noise:\n",
    "\n",
    "- `hours-per-week` includes values as low as 1 and as high as 99 — we may **clip or bin these values** into broader categories (e.g., part-time, full-time, overtime).\n",
    "- `capital-gain` and `capital-loss` have **many rare and highly specific values**, most of which are zero — we may **bucketize or simplify** these into categories like \"none\", \"low\", and \"high\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fa0ba95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top capital-gain values:\n",
      "capital-gain\n",
      "0        44807\n",
      "15024      513\n",
      "7688       410\n",
      "7298       364\n",
      "99999      244\n",
      "3103       152\n",
      "5178       146\n",
      "5013       117\n",
      "4386       108\n",
      "8614        82\n",
      "3325        81\n",
      "2174        74\n",
      "10520       64\n",
      "4650        63\n",
      "27828       58\n",
      "4064        54\n",
      "594         52\n",
      "3137        51\n",
      "20051       49\n",
      "14084       49\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top capital-loss values:\n",
      "capital-loss\n",
      "0       46560\n",
      "1902      304\n",
      "1977      253\n",
      "1887      233\n",
      "2415       72\n",
      "1485       71\n",
      "1848       67\n",
      "1590       62\n",
      "1602       62\n",
      "1876       59\n",
      "1740       58\n",
      "1672       50\n",
      "1741       44\n",
      "1564       43\n",
      "2258       39\n",
      "1719       38\n",
      "1980       36\n",
      "2001       35\n",
      "1408       35\n",
      "1669       35\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot capital-gain distribution (log scale to handle skewness)\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['capital-gain'], bins=50, color='skyblue')\n",
    "plt.title('Capital Gain Distribution')\n",
    "plt.xlabel('Capital Gain')\n",
    "plt.ylabel('Frequency')\n",
    "plt.yscale('log')  # Log scale for better visibility of rare high values\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df['capital-loss'], bins=50, color='salmon')\n",
    "plt.title('Capital Loss Distribution')\n",
    "plt.xlabel('Capital Loss')\n",
    "plt.ylabel('Frequency')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Also, print value counts for the top values to see where to place threshold\n",
    "print(\"Top capital-gain values:\")\n",
    "print(df['capital-gain'].value_counts().head(20))\n",
    "\n",
    "print(\"\\nTop capital-loss values:\")\n",
    "print(df['capital-loss'].value_counts().head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7394c5f3",
   "metadata": {},
   "source": [
    "### **Binning Strategy**\n",
    "\n",
    "To simplify the numerical features and reduce noise from extreme values, we binned capital-gain and capital-loss into three categories: \"none\" for zero values, \"low\" for values up to a chosen threshold, and \"high\" for values above it. Based on data distribution analysis, we selected 7,000 as the threshold for capital-gain and 2,000 for capital-loss. Additionally, we transformed hours-per-week into categorical bins representing work intensity: \"part-time\" (≤30 hours), \"full-time\" (31–40 hours), and \"overtime\" (>40 hours). This binning strategy groups continuous values into meaningful categories, helping reduce noise and improving model interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ebd5ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48842, 90)\n",
      "   age  fnlwgt  education  education-num  income  workclass_Local-gov  \\\n",
      "0   39   77516         12             13       0                False   \n",
      "1   50   83311         12             13       0                False   \n",
      "2   38  215646          8              9       0                False   \n",
      "3   53  234721          6              7       0                False   \n",
      "4   28  338409         12             13       0                False   \n",
      "\n",
      "   workclass_Never-worked  workclass_Private  workclass_Self-emp-inc  \\\n",
      "0                   False              False                   False   \n",
      "1                   False              False                   False   \n",
      "2                   False               True                   False   \n",
      "3                   False               True                   False   \n",
      "4                   False               True                   False   \n",
      "\n",
      "   workclass_Self-emp-not-inc  ...  native-country_Yugoslavia  \\\n",
      "0                       False  ...                      False   \n",
      "1                        True  ...                      False   \n",
      "2                       False  ...                      False   \n",
      "3                       False  ...                      False   \n",
      "4                       False  ...                      False   \n",
      "\n",
      "   hours-per-week-binned_full-time  hours-per-week-binned_overtime  \\\n",
      "0                             True                           False   \n",
      "1                            False                           False   \n",
      "2                             True                           False   \n",
      "3                             True                           False   \n",
      "4                             True                           False   \n",
      "\n",
      "   hours-per-week-binned_part-time  capital-gain-binned_high  \\\n",
      "0                            False                     False   \n",
      "1                             True                     False   \n",
      "2                            False                     False   \n",
      "3                            False                     False   \n",
      "4                            False                     False   \n",
      "\n",
      "   capital-gain-binned_low  capital-gain-binned_none  \\\n",
      "0                     True                     False   \n",
      "1                    False                      True   \n",
      "2                    False                      True   \n",
      "3                    False                      True   \n",
      "4                    False                      True   \n",
      "\n",
      "   capital-loss-binned_high  capital-loss-binned_low  capital-loss-binned_none  \n",
      "0                     False                    False                      True  \n",
      "1                     False                    False                      True  \n",
      "2                     False                    False                      True  \n",
      "3                     False                    False                      True  \n",
      "4                     False                    False                      True  \n",
      "\n",
      "[5 rows x 90 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Copy original dataframe\n",
    "df_transformed = df.copy()\n",
    "\n",
    "# Binning hours-per-week\n",
    "def hours_bin(hours):\n",
    "    if hours <= 30:\n",
    "        return 'part-time'\n",
    "    elif hours <= 40:\n",
    "        return 'full-time'\n",
    "    else:\n",
    "        return 'overtime'\n",
    "\n",
    "df_transformed['hours-per-week-binned'] = df_transformed['hours-per-week'].apply(hours_bin)\n",
    "\n",
    "# Binning capital-gain\n",
    "def capital_gain_bin(gain):\n",
    "    if gain == 0:\n",
    "        return 'none'\n",
    "    elif gain <= 7000:\n",
    "        return 'low'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "df_transformed['capital-gain-binned'] = df_transformed['capital-gain'].apply(capital_gain_bin)\n",
    "\n",
    "# Binning capital-loss\n",
    "def capital_loss_bin(loss):\n",
    "    if loss == 0:\n",
    "        return 'none'\n",
    "    elif loss <= 2000:\n",
    "        return 'low'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "df_transformed['capital-loss-binned'] = df_transformed['capital-loss'].apply(capital_loss_bin)\n",
    "\n",
    "# Drop original continuous columns\n",
    "df_transformed = df_transformed.drop(columns=['hours-per-week', 'capital-gain', 'capital-loss'])\n",
    "\n",
    "# One-hot encode the new binned columns\n",
    "binned_cols = ['hours-per-week-binned', 'capital-gain-binned', 'capital-loss-binned']\n",
    "df_transformed = pd.get_dummies(df_transformed, columns=binned_cols)\n",
    "# Check results\n",
    "print(df_transformed.shape)\n",
    "print(df_transformed.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18171560",
   "metadata": {},
   "source": [
    "### **2 Versions Of Our Dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1beb2f",
   "metadata": {},
   "source": [
    "This step of transforming numerical features into binned categories was considered optional. To evaluate its impact on model performance, we decided to create and retain two versions of the dataset: one with the original continuous numerical features, and another with the binned and encoded versions. This approach allows for a direct comparison to determine which preprocessing strategy yields better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61f7232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df2 = df_transformed.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5036be56",
   "metadata": {},
   "source": [
    "### **Splitting the Data**\n",
    "\n",
    "We will explore one approaches to splitting the dataset for training and testing:\n",
    "\n",
    "- Perform **random train/test splits** (e.g., 80/20 or 70/30) using `train_test_split` for experimentation and validation.\n",
    "\n",
    "### **Optional: Addressing Class Imbalance**\n",
    "\n",
    "If we find that the dataset is imbalanced (e.g., far more samples with income ≤50K than >50K), we may apply techniques to balance the classes:\n",
    "\n",
    "- **Oversampling** the minority class.\n",
    "- **Undersampling** the majority class.\n",
    "- Using synthetic data generation methods like **SMOTE (Synthetic Minority Over-sampling Technique)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9224326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df1 and df2 include features + target 'income'\n",
    "X1, y1 = df1.drop(columns='income'), df1['income']\n",
    "X2, y2 = df2.drop(columns='income'), df2['income']\n",
    "\n",
    "def generate_splits(X, y, n_splits=10, test_size=0.2, random_state=42):\n",
    "    raw_splits = []\n",
    "    over_splits = []\n",
    "    under_splits = []\n",
    "    both_splits = []\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=random_state)\n",
    "    rus = RandomUnderSampler(random_state=random_state)\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        rs = random_state + i  # change seed for diversity\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, stratify=y, random_state=rs\n",
    "        )\n",
    "        \n",
    "        # Raw (no sampling)\n",
    "        raw_splits.append((X_train, X_test, y_train, y_test))\n",
    "        \n",
    "        # Oversampling only\n",
    "        X_over, y_over = ros.fit_resample(X_train, y_train)\n",
    "        over_splits.append((X_over, X_test, y_over, y_test))\n",
    "        \n",
    "        # Undersampling only\n",
    "        X_under, y_under = rus.fit_resample(X_train, y_train)\n",
    "        under_splits.append((X_under, X_test, y_under, y_test))\n",
    "        \n",
    "    \n",
    "    return raw_splits, over_splits, under_splits\n",
    "\n",
    "# Generate splits for df1\n",
    "df1_raw, df1_OverSampling, df1_UnderSampling = generate_splits(X1, y1)\n",
    "\n",
    "# Generate splits for df2\n",
    "df2_raw, df2_OverSampling, df2_UnderSampling = generate_splits(X2, y2)\n",
    "\n",
    "# Example of accessing a split:\n",
    "# X_train, X_test, y_train, y_test = df1_OverSampling[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee69b64",
   "metadata": {},
   "source": [
    "### **Splitting and sampling Strategy**\n",
    "\n",
    "\n",
    "We created multiple random 80/20 train-test splits for each dataset version to ensure robust evaluation across different data partitions. To address the class imbalance present in the income target variable, we generated splits under four conditions:\n",
    "\n",
    "Raw data with no sampling applied,\n",
    "\n",
    "Oversampling of the minority class,\n",
    "\n",
    "Undersampling of the majority class, and\n",
    "\n",
    "Combination of both oversampling and undersampling.\n",
    "\n",
    "Stratified splitting was used to maintain the original class distribution in each split, ensuring consistent representation of both income classes during training and testing. This approach allows us to compare the impact of different sampling techniques on model performance more reliably."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1a763",
   "metadata": {},
   "source": [
    "## **Model Implementation**\n",
    "\n",
    "In this section, we will implement and evaluate various machine learning models to predict whether an individual's income exceeds $50K based on the features in the dataset. The objective is to confirm and apply machine learning theory learned in class, deepen our understanding of classification models, and identify the most effective approach for this problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f160bd",
   "metadata": {},
   "source": [
    "### **Evaluation Metrics**\n",
    "\n",
    "All models will be evaluated using key classification metrics to gain a comprehensive view of performance:\n",
    "\n",
    "- **Accuracy**  \n",
    "  The proportion of total predictions that are correct. Good for balanced datasets.\n",
    "\n",
    "- **Precision**  \n",
    "  The proportion of positive predictions that were actually correct. Important when false positives are costly.\n",
    "\n",
    "- **Recall**  \n",
    "  The proportion of actual positives that were correctly predicted. Important when false negatives are costly.\n",
    "\n",
    "- **F1-Score**  \n",
    "  The harmonic mean of precision and recall. Useful when you need a balance between precision and recall.\n",
    "\n",
    "- **ROC AUC Score**  \n",
    "  Measures the ability of the model to distinguish between classes across different thresholds. A higher score indicates better overall classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5508e062",
   "metadata": {},
   "source": [
    "\n",
    "### **Implemented Models**\n",
    "\n",
    "We will start by implementing the following classification models:\n",
    "\n",
    "- **Logistic Regression**  \n",
    "  A simple and interpretable linear model; it's a good baseline for binary classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73e7e832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Running Logistic Regression for dataset: df1_raw\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8507523799774798, 'precision': 0.7298850574712644, 'recall': 0.5975192472198461, 'f1': 0.6571025399811853, 'roc_auc': np.float64(0.9034742672219435)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8481932644078206, 'precision': 0.7191184008200923, 'recall': 0.6000855431993156, 'f1': 0.6542317556539986, 'roc_auc': np.float64(0.9041750975239671)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8553587880028662, 'precision': 0.7375449409347714, 'recall': 0.6142001710863987, 'f1': 0.67024504084014, 'roc_auc': np.float64(0.9077742778472124)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8504452861091207, 'precision': 0.7333688131985099, 'recall': 0.5893926432848589, 'f1': 0.6535451742945222, 'roc_auc': np.float64(0.9038559941078683)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.847169618179957, 'precision': 0.7199375325351379, 'recall': 0.5915312232677502, 'f1': 0.6494482272833999, 'roc_auc': np.float64(0.8995210743516715)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8513665677141979, 'precision': 0.7346398305084746, 'recall': 0.5932420872540634, 'f1': 0.6564126833885471, 'roc_auc': np.float64(0.9024004876802714)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8485003582761798, 'precision': 0.7225103734439834, 'recall': 0.5958083832335329, 'f1': 0.6530707923112986, 'roc_auc': np.float64(0.9051602660070022)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8535162247927116, 'precision': 0.7423837520042758, 'recall': 0.5940975192472199, 'f1': 0.6600142551674982, 'roc_auc': np.float64(0.9055912628287458)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8439963148735797, 'precision': 0.7146624472573839, 'recall': 0.5795551753635586, 'f1': 0.6400566839867737, 'roc_auc': np.float64(0.8976402981567864)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8544375063977889, 'precision': 0.7449197860962566, 'recall': 0.5958083832335329, 'f1': 0.6620722433460076, 'roc_auc': np.float64(0.9066615025327396)}\n",
      "\n",
      "📦 Running Logistic Regression for dataset: df1_OverSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8056095813286928, 'precision': 0.5634943592710443, 'recall': 0.8331907613344739, 'f1': 0.6723037100949094, 'roc_auc': np.float64(0.902943636920173)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8048930289691882, 'precision': 0.5607424071991001, 'recall': 0.8528656971770744, 'f1': 0.6766202918221921, 'roc_auc': np.float64(0.903614939795707)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8070426860477019, 'precision': 0.5641098216812906, 'recall': 0.8524379811804962, 'f1': 0.6789303355476068, 'roc_auc': np.float64(0.9072974645898239)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8081686968983519, 'precision': 0.566935949221004, 'recall': 0.8404619332763046, 'f1': 0.677119228118539, 'roc_auc': np.float64(0.9031442852802959)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8016173610400246, 'precision': 0.556657223796034, 'recall': 0.8404619332763046, 'f1': 0.6697341513292433, 'roc_auc': np.float64(0.8995070876759659)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.7994677039615109, 'precision': 0.5527708159287107, 'recall': 0.84901625320787, 'f1': 0.6695901501096306, 'roc_auc': np.float64(0.9022208481128752)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8097041662401474, 'precision': 0.5679432624113475, 'recall': 0.8562874251497006, 'f1': 0.6829268292682927, 'roc_auc': np.float64(0.9054131773364281)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8087828846350701, 'precision': 0.5673352435530086, 'recall': 0.8468776732249786, 'f1': 0.6794783802333562, 'roc_auc': np.float64(0.9054052342860274)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.7996724332070836, 'precision': 0.5545064377682404, 'recall': 0.8289136013686912, 'f1': 0.6644951140065146, 'roc_auc': np.float64(0.8977081018768737)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8103183539768656, 'precision': 0.5691474194468207, 'recall': 0.853721129170231, 'f1': 0.6829769033361848, 'roc_auc': np.float64(0.9065921447375737)}\n",
      "\n",
      "📦 Running Logistic Regression for dataset: df1_UnderSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8061214044426246, 'precision': 0.5644225188624492, 'recall': 0.8319076133447391, 'f1': 0.6725449515905948, 'roc_auc': np.float64(0.9028437732068016)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8015149964172382, 'precision': 0.5554320644623506, 'recall': 0.8550042771599657, 'f1': 0.673404076132727, 'roc_auc': np.float64(0.9036792900156203)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8049953935919746, 'precision': 0.5611064069997177, 'recall': 0.8502994011976048, 'f1': 0.6760754973643938, 'roc_auc': np.float64(0.9070356892766174)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8094994369945747, 'precision': 0.5692307692307692, 'recall': 0.8387510692899914, 'f1': 0.6781947086287394, 'roc_auc': np.float64(0.9030578326592676)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7992629747159382, 'precision': 0.5530537573881227, 'recall': 0.8404619332763046, 'f1': 0.6671193345781701, 'roc_auc': np.float64(0.8990538157780983)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7980345992425018, 'precision': 0.5505680243834857, 'recall': 0.8498716852010265, 'f1': 0.6682360854212208, 'roc_auc': np.float64(0.9019886577844944)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8091923431262156, 'precision': 0.5671007927519819, 'recall': 0.8567151411462789, 'f1': 0.6824531516183986, 'roc_auc': np.float64(0.9048951523102938)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8063261336881974, 'precision': 0.5633882888004548, 'recall': 0.8477331052181352, 'f1': 0.6769125683060109, 'roc_auc': np.float64(0.9051888149417757)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7995700685842972, 'precision': 0.5540694365395561, 'recall': 0.8327630453378957, 'f1': 0.6654135338345865, 'roc_auc': np.float64(0.8977251967027362)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8108301770907974, 'precision': 0.569920091324201, 'recall': 0.8541488451668092, 'f1': 0.6836699760356042, 'roc_auc': np.float64(0.9067459406119993)}\n",
      "\n",
      "📦 Running Logistic Regression for dataset: df2_raw\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8576108097041663, 'precision': 0.7580381471389646, 'recall': 0.5949529512403764, 'f1': 0.6666666666666666, 'roc_auc': np.float64(0.9086134208312138)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8564847988535162, 'precision': 0.7516129032258064, 'recall': 0.5979469632164243, 'f1': 0.666031443544545, 'roc_auc': np.float64(0.9099274776475079)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8542327771522162, 'precision': 0.7397691500524659, 'recall': 0.6030795551753636, 'f1': 0.6644674835061263, 'roc_auc': np.float64(0.9084618409527332)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8551540587572934, 'precision': 0.7528767123287671, 'recall': 0.5876817792985458, 'f1': 0.6601008887821282, 'roc_auc': np.float64(0.9085823968879818)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8526973078104207, 'precision': 0.7354635935044526, 'recall': 0.6005132591958939, 'f1': 0.6611725924181775, 'roc_auc': np.float64(0.9035846928900144)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8553587880028662, 'precision': 0.7479892761394102, 'recall': 0.5966638152266894, 'f1': 0.6638115631691649, 'roc_auc': np.float64(0.9071257392936602)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8530044016787798, 'precision': 0.7409188034188035, 'recall': 0.5932420872540634, 'f1': 0.6589073634204275, 'roc_auc': np.float64(0.9099409462981874)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8581226328180981, 'precision': 0.7632743362831859, 'recall': 0.5902480752780154, 'f1': 0.6657018813314037, 'roc_auc': np.float64(0.9098683076778561)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8472719828027434, 'precision': 0.7306434023991276, 'recall': 0.5731394354148845, 'f1': 0.6423777564717162, 'roc_auc': np.float64(0.9022799893033588)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8574060804585935, 'precision': 0.7591881513987931, 'recall': 0.5919589392643285, 'f1': 0.6652247055996154, 'roc_auc': np.float64(0.9102891166740861)}\n",
      "\n",
      "📦 Running Logistic Regression for dataset: df2_OverSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8118538233186611, 'precision': 0.5734861845972957, 'recall': 0.8344739093242087, 'f1': 0.6797909407665506, 'roc_auc': np.float64(0.9083365652339132)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8103183539768656, 'precision': 0.5692263773908078, 'recall': 0.8528656971770744, 'f1': 0.6827598014038692, 'roc_auc': np.float64(0.9096332969909998)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8089876138806429, 'precision': 0.5675830469644902, 'recall': 0.8477331052181352, 'f1': 0.6799313893653516, 'roc_auc': np.float64(0.9082348884329502)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8143105742655339, 'precision': 0.5764294049008168, 'recall': 0.8451668092386655, 'f1': 0.685397155740548, 'roc_auc': np.float64(0.9079817756493473)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8056095813286928, 'precision': 0.5630203847258111, 'recall': 0.8387510692899914, 'f1': 0.6737673939185707, 'roc_auc': np.float64(0.9036225662752586)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8060190398198382, 'precision': 0.5627301047861796, 'recall': 0.8498716852010265, 'f1': 0.6771170557164764, 'roc_auc': np.float64(0.9070952333754546)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8134916572832429, 'precision': 0.5736721873215306, 'recall': 0.8592814371257484, 'f1': 0.688013698630137, 'roc_auc': np.float64(0.9102269536709501)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8130821987920974, 'precision': 0.5741599073001159, 'recall': 0.8477331052181352, 'f1': 0.6846286701208981, 'roc_auc': np.float64(0.9098081592164883)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8078616030299929, 'precision': 0.5672207640711577, 'recall': 0.8319076133447391, 'f1': 0.6745274839604647, 'roc_auc': np.float64(0.901938783486145)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8147200327566793, 'precision': 0.5766995932597327, 'recall': 0.84901625320787, 'f1': 0.6868512110726643, 'roc_auc': np.float64(0.9101612796093033)}\n",
      "\n",
      "📦 Running Logistic Regression for dataset: df2_UnderSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8107278124680111, 'precision': 0.5716378552593027, 'recall': 0.8344739093242087, 'f1': 0.67849069727004, 'roc_auc': np.float64(0.9082529905296968)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8104207185996519, 'precision': 0.569034090909091, 'recall': 0.8567151411462789, 'f1': 0.6838511437350632, 'roc_auc': np.float64(0.9096794587766622)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8091923431262156, 'precision': 0.5677142857142857, 'recall': 0.8498716852010265, 'f1': 0.6807125727989037, 'roc_auc': np.float64(0.907929311225867)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8149247620022521, 'precision': 0.5778038755137992, 'recall': 0.8417450812660393, 'f1': 0.6852367688022284, 'roc_auc': np.float64(0.9079060864371954)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8039717473641109, 'precision': 0.5606886657101865, 'recall': 0.8357570573139436, 'f1': 0.6711317190451658, 'roc_auc': np.float64(0.9030268950535401)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8041764766096837, 'precision': 0.5598086124401914, 'recall': 0.850727117194183, 'f1': 0.6752673569852317, 'roc_auc': np.float64(0.9070326674639647)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8136963865288156, 'precision': 0.574, 'recall': 0.8592814371257484, 'f1': 0.6882494004796164, 'roc_auc': np.float64(0.9098389529263753)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8118538233186611, 'precision': 0.5720046082949308, 'recall': 0.8494439692044482, 'f1': 0.6836488812392427, 'roc_auc': np.float64(0.9095891497471059)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8064284983109837, 'precision': 0.5646140503035559, 'recall': 0.8353293413173652, 'f1': 0.6737967914438503, 'roc_auc': np.float64(0.9020179837568073)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8157436789845429, 'precision': 0.5782887077997672, 'recall': 0.8498716852010265, 'f1': 0.6882577069622445, 'roc_auc': np.float64(0.910480670817083)}\n",
      "\n",
      "📊 Average Performance by Dataset:\n",
      "                   accuracy  precision  recall      f1  roc_auc\n",
      "dataset                                                        \n",
      "df1_OverSampling     0.8055     0.5624  0.8454  0.6754   0.9034\n",
      "df1_UnderSampling    0.8045     0.5608  0.8458  0.6744   0.9032\n",
      "df1_raw              0.8504     0.7299  0.5951  0.6556   0.9036\n",
      "df2_OverSampling     0.8106     0.5704  0.8457  0.6813   0.9077\n",
      "df2_UnderSampling    0.8101     0.5696  0.8463  0.6809   0.9076\n",
      "df2_raw              0.8547     0.7480  0.5929  0.6614   0.9079\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# List of dataset split arrays (you must already have these defined)\n",
    "datasets = {\n",
    "    'df1_raw': df1_raw,\n",
    "    'df1_OverSampling': df1_OverSampling,\n",
    "    'df1_UnderSampling': df1_UnderSampling,\n",
    "    'df2_raw': df2_raw,\n",
    "    'df2_OverSampling': df2_OverSampling,\n",
    "    'df2_UnderSampling': df2_UnderSampling,\n",
    "}\n",
    "\n",
    "# Initialize empty list to collect all results\n",
    "results = []\n",
    "\n",
    "for name, splits in datasets.items():\n",
    "    print(f\"\\n📦 Running Logistic Regression for dataset: {name}\")\n",
    "    \n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "        print(f\"  🔁 Split {i+1}/10\")\n",
    "        \n",
    "        # Create pipeline with scaling\n",
    "        model = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Compute metrics\n",
    "        metrics = {\n",
    "            'dataset': name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "        }\n",
    "        print(f\"    Metrics: {metrics}\")\n",
    "\n",
    "        results.append(metrics)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Show average metrics per dataset\n",
    "print(\"\\n📊 Average Performance by Dataset:\")\n",
    "print(results_df.groupby('dataset').mean(numeric_only=True).round(4))\n",
    "\n",
    "# Optional: save to CSV\n",
    "results_df.to_csv(\"logistic_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0222fe74",
   "metadata": {},
   "source": [
    "### **Conclusoes**\n",
    "\n",
    "falar do que se fez \n",
    "falar da pipeline e dizer que diminui muito o tempo de treino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d9b1fe",
   "metadata": {},
   "source": [
    "- **Random Forest Classifier**  \n",
    "  A robust ensemble method that reduces overfitting; chosen for its ability to handle non-linear relationships and mixed feature types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f421044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌲 Running Random Forest for dataset: df1_raw\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8584297266864571, 'precision': 0.7444956477214542, 'recall': 0.6218990590248076, 'f1': 0.6776975064087625, 'roc_auc': np.float64(0.9058187621527232)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8595557375371071, 'precision': 0.7386363636363636, 'recall': 0.6394354148845167, 'f1': 0.6854653828519028, 'roc_auc': np.float64(0.9071572812619182)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.852492578564848, 'precision': 0.7225806451612903, 'recall': 0.6227544910179641, 'f1': 0.6689639329198254, 'roc_auc': np.float64(0.9022129626208106)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.852492578564848, 'precision': 0.7289433384379785, 'recall': 0.6107784431137725, 'f1': 0.6646497556434722, 'roc_auc': np.float64(0.9003884209204291)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8518783908281298, 'precision': 0.72, 'recall': 0.6236099230111206, 'f1': 0.668347467338987, 'roc_auc': np.float64(0.9003282436798932)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8512642030914116, 'precision': 0.723823975720789, 'recall': 0.6120615911035072, 'f1': 0.6632676709154114, 'roc_auc': np.float64(0.901609204452851)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8537209540382844, 'precision': 0.7296614451743305, 'recall': 0.6176218990590248, 'f1': 0.6689830901088719, 'roc_auc': np.float64(0.9034577192002753)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8554611526256526, 'precision': 0.7359836901121305, 'recall': 0.6176218990590248, 'f1': 0.6716279069767442, 'roc_auc': np.float64(0.903751065260908)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8512642030914116, 'precision': 0.7286821705426356, 'recall': 0.6030795551753636, 'f1': 0.6599578750292534, 'roc_auc': np.float64(0.8957076331217835)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8531067663015662, 'precision': 0.7323726196603191, 'recall': 0.6086398631308811, 'f1': 0.6647979444055128, 'roc_auc': np.float64(0.9040618802765885)}\n",
      "\n",
      "🌲 Running Random Forest for dataset: df1_OverSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8485003582761798, 'precision': 0.6820882852292021, 'recall': 0.6873396065012831, 'f1': 0.6847038772901577, 'roc_auc': np.float64(0.902620331745529)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8521854846964889, 'precision': 0.6894067796610169, 'recall': 0.6958939264328486, 'f1': 0.6926351638995317, 'roc_auc': np.float64(0.9034863256933852)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8449175964786569, 'precision': 0.6719598829920602, 'recall': 0.6877673224978614, 'f1': 0.6797717184527584, 'roc_auc': np.float64(0.9007382892672466)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8490121813901116, 'precision': 0.6868774361195322, 'recall': 0.6783575705731394, 'f1': 0.6825909188723908, 'roc_auc': np.float64(0.8986955439141903)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8462483365748797, 'precision': 0.6748953974895398, 'recall': 0.6899059024807528, 'f1': 0.6823181049069373, 'roc_auc': np.float64(0.8974670475647126)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8439963148735797, 'precision': 0.6761904761904762, 'recall': 0.6680923866552609, 'f1': 0.6721170395869192, 'roc_auc': np.float64(0.8989843140870919)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8454294195925888, 'precision': 0.6752751905165114, 'recall': 0.6822070145423439, 'f1': 0.6787234042553192, 'roc_auc': np.float64(0.9013489544355547)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8470672535571706, 'precision': 0.6794217687074829, 'recall': 0.6834901625320787, 'f1': 0.6814498933901919, 'roc_auc': np.float64(0.899973857003681)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8419490224178524, 'precision': 0.6718614718614718, 'recall': 0.6638152266894782, 'f1': 0.6678141135972461, 'roc_auc': np.float64(0.8931786637233636)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8479885351622479, 'precision': 0.6839154808106943, 'recall': 0.6783575705731394, 'f1': 0.6811251878891991, 'roc_auc': np.float64(0.9006084088815276)}\n",
      "\n",
      "🌲 Running Random Forest for dataset: df1_UnderSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8163578667212611, 'precision': 0.5817307692307693, 'recall': 0.8280581693755347, 'f1': 0.6833745146487822, 'roc_auc': np.float64(0.9056586924196477)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8159484082301157, 'precision': 0.5790861159929701, 'recall': 0.8455945252352438, 'f1': 0.6874130737134909, 'roc_auc': np.float64(0.9066029944839545)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8077592384072064, 'precision': 0.5663972286374134, 'recall': 0.8391787852865698, 'f1': 0.6763185108583247, 'roc_auc': np.float64(0.9023275037099225)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8125703756781656, 'precision': 0.5761032722906034, 'recall': 0.820786997433704, 'f1': 0.6770153466219792, 'roc_auc': np.float64(0.9015817491264659)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8096018016173611, 'precision': 0.5697606538237011, 'recall': 0.834901625320787, 'f1': 0.6773074253990284, 'roc_auc': np.float64(0.9022627218024877)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8105230832224384, 'precision': 0.5718501032753025, 'recall': 0.8289136013686912, 'f1': 0.676794133053955, 'roc_auc': np.float64(0.9017394014094194)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8108301770907974, 'precision': 0.5727434679334917, 'recall': 0.8250641573994867, 'f1': 0.676130389064143, 'roc_auc': np.float64(0.9029444139577124)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8115467294503019, 'precision': 0.5730667450749779, 'recall': 0.8336184773310522, 'f1': 0.6792124063425684, 'roc_auc': np.float64(0.905427941049673)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8089876138806429, 'precision': 0.5705741626794258, 'recall': 0.8160821214713431, 'f1': 0.6715945089757128, 'roc_auc': np.float64(0.8967102993390346)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8183027945542021, 'precision': 0.5850710184345724, 'recall': 0.8280581693755347, 'f1': 0.6856738091021781, 'roc_auc': np.float64(0.9048027999598012)}\n",
      "\n",
      "🌲 Running Random Forest for dataset: df2_raw\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8443034087419388, 'precision': 0.6991711360312043, 'recall': 0.613344739093242, 'f1': 0.6534518113465482, 'roc_auc': np.float64(0.8947792171582781)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8426655747773569, 'precision': 0.6958435207823961, 'recall': 0.6086398631308811, 'f1': 0.64932694501483, 'roc_auc': np.float64(0.8942644153989731)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8438939502507933, 'precision': 0.6980029225523624, 'recall': 0.6129170230966638, 'f1': 0.65269870189023, 'roc_auc': np.float64(0.8922082877327414)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8429726686457161, 'precision': 0.7040609137055838, 'recall': 0.5932420872540634, 'f1': 0.6439182915506035, 'roc_auc': np.float64(0.8919893933800316)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8437915856280069, 'precision': 0.7003948667324777, 'recall': 0.606928999144568, 'f1': 0.65032080659945, 'roc_auc': np.float64(0.8895573809990032)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8397993653393387, 'precision': 0.6943187531422825, 'recall': 0.5906757912745937, 'f1': 0.638317541021493, 'roc_auc': np.float64(0.8917021772822081)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8464530658204524, 'precision': 0.707631318136769, 'recall': 0.6107784431137725, 'f1': 0.6556473829201102, 'roc_auc': np.float64(0.8959069576401727)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8426655747773569, 'precision': 0.7011551983927674, 'recall': 0.5970915312232677, 'f1': 0.6449526449526449, 'roc_auc': np.float64(0.8921886027817484)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8384686252431159, 'precision': 0.69, 'recall': 0.5902480752780154, 'f1': 0.636237897648686, 'roc_auc': np.float64(0.8860018586737938)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8403111884532706, 'precision': 0.6954773869346733, 'recall': 0.5919589392643285, 'f1': 0.6395563770794824, 'roc_auc': np.float64(0.8918068471166554)}\n",
      "\n",
      "🌲 Running Random Forest for dataset: df2_OverSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8371378851468932, 'precision': 0.6573957016434893, 'recall': 0.6672369546621043, 'f1': 0.6622797707493101, 'roc_auc': np.float64(0.891617192398754)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8331456648582249, 'precision': 0.6461601981833196, 'recall': 0.6693755346449958, 'f1': 0.657563025210084, 'roc_auc': np.float64(0.8911175284818793)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8328385709898659, 'precision': 0.6432344575375863, 'recall': 0.6770744225834047, 'f1': 0.659720775161492, 'roc_auc': np.float64(0.8884669670981584)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8390828129798341, 'precision': 0.6621507197290432, 'recall': 0.6689478186484175, 'f1': 0.6655319148936171, 'roc_auc': np.float64(0.8874919001031331)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8348858634455932, 'precision': 0.6502279320348114, 'recall': 0.6710863986313088, 'f1': 0.6604925278888655, 'roc_auc': np.float64(0.8857345289811405)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8327362063670796, 'precision': 0.6490262489415749, 'recall': 0.655688622754491, 'f1': 0.6523404255319148, 'roc_auc': np.float64(0.889275086138928)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8376497082608251, 'precision': 0.6569282136894825, 'recall': 0.6732249786142002, 'f1': 0.6649767638360794, 'roc_auc': np.float64(0.8919668592913947)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8343740403316614, 'precision': 0.6528013582342954, 'recall': 0.6578272027373824, 'f1': 0.6553046442266723, 'roc_auc': np.float64(0.8890730275995676)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8284368922100522, 'precision': 0.640373197625106, 'recall': 0.6458511548331908, 'f1': 0.6431005110732538, 'roc_auc': np.float64(0.8811051407767544)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8358071450506704, 'precision': 0.6557724957555179, 'recall': 0.6608212147134302, 'f1': 0.6582871751171708, 'roc_auc': np.float64(0.8901069192142274)}\n",
      "\n",
      "🌲 Running Random Forest for dataset: df2_UnderSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8114443648275156, 'precision': 0.5749697702539298, 'recall': 0.8135158254918734, 'f1': 0.6737513283740701, 'roc_auc': np.float64(0.8974546437432535)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8061214044426246, 'precision': 0.5649882903981265, 'recall': 0.825491873396065, 'f1': 0.6708376781369482, 'roc_auc': np.float64(0.8967585620039694)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.7983416931108609, 'precision': 0.5530259365994237, 'recall': 0.820786997433704, 'f1': 0.6608126721763086, 'roc_auc': np.float64(0.8936293167169325)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8068379568021292, 'precision': 0.5675351901766996, 'recall': 0.8105218135158255, 'f1': 0.6676061299982385, 'roc_auc': np.float64(0.8958949567270673)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8044835704780428, 'precision': 0.562793427230047, 'recall': 0.8203592814371258, 'f1': 0.6675948485903237, 'roc_auc': np.float64(0.8938876097507966)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8058143105742656, 'precision': 0.5649484536082474, 'recall': 0.8203592814371258, 'f1': 0.6691086691086691, 'roc_auc': np.float64(0.8947190686969103)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.806223769065411, 'precision': 0.5658868818477939, 'recall': 0.8173652694610778, 'f1': 0.6687664041994751, 'roc_auc': np.float64(0.8974943877744253)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.806223769065411, 'precision': 0.565614862872309, 'recall': 0.8203592814371258, 'f1': 0.6695758422063187, 'roc_auc': np.float64(0.8964979666366557)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8005937148121609, 'precision': 0.5585234093637454, 'recall': 0.7959794696321643, 'f1': 0.6564373897707231, 'roc_auc': np.float64(0.8875313275634555)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8122632818098066, 'precision': 0.5766423357664233, 'recall': 0.8109495295124037, 'f1': 0.6740135087095628, 'roc_auc': np.float64(0.8982997440150554)}\n",
      "\n",
      "📊 Average Random Forest Performance by Dataset:\n",
      "                   accuracy  precision  recall      f1  roc_auc\n",
      "dataset                                                        \n",
      "df1_OverSampling     0.8467     0.6792  0.6815  0.6803   0.8997\n",
      "df1_UnderSampling    0.8122     0.5746  0.8300  0.6791   0.9030\n",
      "df1_raw              0.8540     0.7305  0.6178  0.6694   0.9024\n",
      "df2_OverSampling     0.8346     0.6514  0.6647  0.6580   0.8886\n",
      "df2_UnderSampling    0.8058     0.5655  0.8156  0.6679   0.8952\n",
      "df2_raw              0.8425     0.6986  0.6016  0.6464   0.8920\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# List of dataset split arrays (already defined)\n",
    "datasets = {\n",
    "    'df1_raw': df1_raw,\n",
    "    'df1_OverSampling': df1_OverSampling,\n",
    "    'df1_UnderSampling': df1_UnderSampling,\n",
    "    'df2_raw': df2_raw,\n",
    "    'df2_OverSampling': df2_OverSampling,\n",
    "    'df2_UnderSampling': df2_UnderSampling,\n",
    "}\n",
    "\n",
    "# Initialize empty list to collect all results\n",
    "rf_results = []\n",
    "\n",
    "for name, splits in datasets.items():\n",
    "    print(f\"\\n🌲 Running Random Forest for dataset: {name}\")\n",
    "    \n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "        print(f\"  🔁 Split {i+1}/10\")\n",
    "\n",
    "        # Initialize Random Forest model\n",
    "        model = RandomForestClassifier(random_state=42, n_estimators= 100)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Compute metrics\n",
    "        metrics = {\n",
    "            'dataset': name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "        }\n",
    "        print(f\"    Metrics: {metrics}\")\n",
    "\n",
    "        rf_results.append(metrics)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "rf_results_df = pd.DataFrame(rf_results)\n",
    "\n",
    "# Show average metrics per dataset\n",
    "print(\"\\n📊 Average Random Forest Performance by Dataset:\")\n",
    "print(rf_results_df.groupby('dataset').mean(numeric_only=True).round(4))\n",
    "\n",
    "# Optional: save to CSV\n",
    "rf_results_df.to_csv(\"random_forest_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fd0a8e",
   "metadata": {},
   "source": [
    "### **Conclusoes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ca133c",
   "metadata": {},
   "source": [
    "- **Gradient Boosting (XGBoost or LightGBM)**  \n",
    "  A highly accurate boosting algorithm; selected for its strong performance in structured/tabular data and ability to capture complex patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80cb3580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚡ Running XGBoost for dataset: df1_raw\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8758317125601393, 'precision': 0.7845220030349014, 'recall': 0.6633875106928999, 'f1': 0.7188876013904982, 'roc_auc': np.float64(0.9299881694595697)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8750127955778483, 'precision': 0.7810770005032712, 'recall': 0.6638152266894782, 'f1': 0.7176878612716763, 'roc_auc': np.float64(0.9309147147771474)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.872965503122121, 'precision': 0.7714002968827314, 'recall': 0.6668092386655261, 'f1': 0.7153016746960312, 'roc_auc': np.float64(0.9290924466310473)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8719418568942573, 'precision': 0.7817522032141005, 'recall': 0.6449957228400343, 'f1': 0.7068197797047105, 'roc_auc': np.float64(0.9267538802088999)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8674378134916573, 'precision': 0.7621920563097033, 'recall': 0.6484174508126604, 'f1': 0.7007164317078808, 'roc_auc': np.float64(0.9228481154076874)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8694851059473846, 'precision': 0.7677581863979849, 'recall': 0.6518391787852865, 'f1': 0.7050659264399722, 'roc_auc': np.float64(0.9245970830125894)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8667212611321528, 'precision': 0.7551724137931034, 'recall': 0.655688622754491, 'f1': 0.7019230769230769, 'roc_auc': np.float64(0.9293295869763443)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8733749616132664, 'precision': 0.788370874803562, 'recall': 0.6437125748502994, 'f1': 0.7087355780550977, 'roc_auc': np.float64(0.9294955276597162)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8649810625447846, 'precision': 0.7671735710540115, 'recall': 0.625748502994012, 'f1': 0.689281507656066, 'roc_auc': np.float64(0.9216020349864893)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8728631384993346, 'precision': 0.7804503582395087, 'recall': 0.6522668947818648, 'f1': 0.7106244175209693, 'roc_auc': np.float64(0.9306556734849122)}\n",
      "\n",
      "⚡ Running XGBoost for dataset: df1_OverSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8384686252431159, 'precision': 0.619572057898049, 'recall': 0.8421727972626176, 'f1': 0.7139231327048586, 'roc_auc': np.float64(0.9292103836619973)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8383662606203296, 'precision': 0.6168051708217913, 'recall': 0.8571428571428571, 'f1': 0.7173796312869161, 'roc_auc': np.float64(0.9308186211347993)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8333503941037977, 'precision': 0.6084300549786195, 'recall': 0.8520102651839179, 'f1': 0.7099073414112615, 'roc_auc': np.float64(0.9279066010087214)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8336574879721568, 'precision': 0.6113714464229928, 'recall': 0.8370402053036784, 'f1': 0.7066257447192634, 'roc_auc': np.float64(0.9248480373585835)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8336574879721568, 'precision': 0.6106112317716413, 'recall': 0.8417450812660393, 'f1': 0.7077863693580291, 'roc_auc': np.float64(0.9228606919041552)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8287439860784113, 'precision': 0.6004228329809725, 'recall': 0.8502994011976048, 'f1': 0.7038413878562577, 'roc_auc': np.float64(0.9233805012387128)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8378544375063978, 'precision': 0.6155024509803921, 'recall': 0.8592814371257484, 'f1': 0.7172438414851838, 'roc_auc': np.float64(0.9285306772693724)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8364213327873887, 'precision': 0.6134969325153374, 'recall': 0.8554319931565441, 'f1': 0.7145409074669525, 'roc_auc': np.float64(0.9282323236334874)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8344764049544477, 'precision': 0.6148454921949665, 'recall': 0.825491873396065, 'f1': 0.7047653825086726, 'roc_auc': np.float64(0.9217902507459848)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8417442931722796, 'precision': 0.624215809284818, 'recall': 0.8511548331907614, 'f1': 0.7202316322837495, 'roc_auc': np.float64(0.9305965610735966)}\n",
      "\n",
      "⚡ Running XGBoost for dataset: df1_UnderSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8305865492885659, 'precision': 0.6016066646831301, 'recall': 0.864841745081266, 'f1': 0.7095981751184418, 'roc_auc': np.float64(0.9281738155847024)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8269014228682567, 'precision': 0.5943974321564051, 'recall': 0.8712574850299402, 'f1': 0.7066782307025152, 'roc_auc': np.float64(0.9289886401716434)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8229092025795884, 'precision': 0.5875576036866359, 'recall': 0.8725406330196749, 'f1': 0.7022375215146299, 'roc_auc': np.float64(0.9259814761157654)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8273108813594022, 'precision': 0.5967310549777117, 'recall': 0.8588537211291702, 'f1': 0.7041907767841487, 'roc_auc': np.float64(0.9242842822343087)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8236257549390931, 'precision': 0.5893635571054926, 'recall': 0.8674080410607357, 'f1': 0.7018515314068178, 'roc_auc': np.float64(0.9202711711360139)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8217831917289384, 'precision': 0.5863465432455887, 'recall': 0.8669803250641575, 'f1': 0.6995685936151855, 'roc_auc': np.float64(0.92292884097426)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8256730473948204, 'precision': 0.5927007299270073, 'recall': 0.8682634730538922, 'f1': 0.7044941870553532, 'roc_auc': np.float64(0.9252016182180884)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8259801412631794, 'precision': 0.5937683715461494, 'recall': 0.8639863130881095, 'f1': 0.7038327526132404, 'roc_auc': np.float64(0.9262698721594818)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8278227044733341, 'precision': 0.5980861244019139, 'recall': 0.8554319931565441, 'f1': 0.703977472720873, 'roc_auc': np.float64(0.920867763291112)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8317125601392159, 'precision': 0.6029062870699882, 'recall': 0.869546621043627, 'f1': 0.7120840630472854, 'roc_auc': np.float64(0.9276577187628319)}\n",
      "\n",
      "⚡ Running XGBoost for dataset: df2_raw\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8608864776333299, 'precision': 0.7503836317135549, 'recall': 0.6274593669803251, 'f1': 0.6834381551362684, 'roc_auc': np.float64(0.9146007253041066)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.860067560651039, 'precision': 0.7463216641298833, 'recall': 0.6291702309666382, 'f1': 0.6827570201902994, 'roc_auc': np.float64(0.9144615204679171)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8566895280990889, 'precision': 0.7392857142857143, 'recall': 0.6197604790419161, 'f1': 0.6742671009771987, 'roc_auc': np.float64(0.9119003759595405)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8587368205548163, 'precision': 0.7448875255623721, 'recall': 0.6231822070145423, 'f1': 0.6786213320912902, 'roc_auc': np.float64(0.9118789930376285)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8547446002661481, 'precision': 0.7287207565953211, 'recall': 0.6261762189905903, 'f1': 0.673567977915804, 'roc_auc': np.float64(0.9097960144075422)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.860067560651039, 'precision': 0.7473255221599593, 'recall': 0.6274593669803251, 'f1': 0.6821669379214136, 'roc_auc': np.float64(0.9106739804893355)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8559729757395844, 'precision': 0.7368956743002545, 'recall': 0.6193327630453379, 'f1': 0.6730188240762259, 'roc_auc': np.float64(0.9142876079549765)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8641621455624936, 'precision': 0.7661927330173776, 'recall': 0.6223267750213858, 'f1': 0.6868067028557941, 'roc_auc': np.float64(0.91379286527585)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8535162247927116, 'precision': 0.7393139841688654, 'recall': 0.5992301112061591, 'f1': 0.66194188518781, 'roc_auc': np.float64(0.9064126490660183)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df2_raw', 'accuracy': 0.8570989865902344, 'precision': 0.7476340694006309, 'recall': 0.6082121471343028, 'f1': 0.6707547169811321, 'roc_auc': np.float64(0.9137901024757108)}\n",
      "\n",
      "⚡ Running XGBoost for dataset: df2_OverSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8204524516327157, 'precision': 0.5890243902439024, 'recall': 0.8263473053892215, 'f1': 0.6877892488430046, 'roc_auc': np.float64(0.9122579283442458)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8203500870099294, 'precision': 0.5874062968515742, 'recall': 0.8378956372968349, 'f1': 0.6906398730830249, 'roc_auc': np.float64(0.9116137066659115)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8163578667212611, 'precision': 0.5817307692307693, 'recall': 0.8280581693755347, 'f1': 0.6833745146487822, 'roc_auc': np.float64(0.9113622055157232)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8173815129491248, 'precision': 0.5839902971497878, 'recall': 0.823781009409752, 'f1': 0.6834634492547906, 'roc_auc': np.float64(0.9079211379421215)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8206571808782884, 'precision': 0.5884127942063971, 'recall': 0.8340461933276304, 'f1': 0.6900212314225053, 'roc_auc': np.float64(0.9088094645244373)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8157436789845429, 'precision': 0.5805389221556886, 'recall': 0.8293413173652695, 'f1': 0.6829869672419866, 'roc_auc': np.float64(0.9086178240439358)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8213737332377931, 'precision': 0.5894959251433746, 'recall': 0.8353293413173652, 'f1': 0.6912050964431075, 'roc_auc': np.float64(0.9120864620605954)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8160507728529021, 'precision': 0.5811094452773613, 'recall': 0.8289136013686912, 'f1': 0.6832363828662084, 'roc_auc': np.float64(0.9102348967213505)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8170744190807657, 'precision': 0.58537341183762, 'recall': 0.8079555175363559, 'f1': 0.6788858939802336, 'roc_auc': np.float64(0.9043336995194684)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df2_OverSampling', 'accuracy': 0.8282321629644794, 'precision': 0.601041028781384, 'recall': 0.839606501283148, 'f1': 0.7005710206995004, 'roc_auc': np.float64(0.9141279986885908)}\n",
      "\n",
      "⚡ Running XGBoost for dataset: df2_UnderSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8082710615211383, 'precision': 0.5672159583694709, 'recall': 0.8391787852865698, 'f1': 0.6769018457823012, 'roc_auc': np.float64(0.9111851848526259)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8089876138806429, 'precision': 0.5665538635081783, 'recall': 0.8592814371257484, 'f1': 0.6828687967369137, 'roc_auc': np.float64(0.9104908586425973)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8086805200122837, 'precision': 0.5658522886829542, 'recall': 0.8618477331052181, 'f1': 0.6831666384132904, 'roc_auc': np.float64(0.9096644360509041)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8100112601085065, 'precision': 0.5692528735632184, 'recall': 0.8473053892215568, 'f1': 0.6809900309384668, 'roc_auc': np.float64(0.9116217072746485)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8052001228375474, 'precision': 0.5604670558798999, 'recall': 0.8622754491017964, 'f1': 0.6793597304128054, 'roc_auc': np.float64(0.9078202093995296)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8043812058552564, 'precision': 0.5603618886061634, 'recall': 0.8477331052181352, 'f1': 0.6747234042553192, 'roc_auc': np.float64(0.9083619484601936)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8116490940730884, 'precision': 0.5703787450537027, 'recall': 0.863130881094953, 'f1': 0.686861810755616, 'roc_auc': np.float64(0.9124344885406531)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8105230832224384, 'precision': 0.5696709585121602, 'recall': 0.8515825491873396, 'f1': 0.6826675810046289, 'roc_auc': np.float64(0.9121921391659267)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8055072167059064, 'precision': 0.5627507163323783, 'recall': 0.8400342172797263, 'f1': 0.6739876458476322, 'roc_auc': np.float64(0.9048565882250148)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df2_UnderSampling', 'accuracy': 0.8186098884225612, 'precision': 0.5829425556858148, 'recall': 0.850727117194183, 'f1': 0.6918260869565217, 'roc_auc': np.float64(0.9121733463691453)}\n",
      "\n",
      "📊 Average XGBoost Performance by Dataset:\n",
      "                   accuracy  precision  recall      f1  roc_auc\n",
      "dataset                                                        \n",
      "df1_OverSampling     0.8357     0.6135  0.8472  0.7116   0.9268\n",
      "df1_UnderSampling    0.8264     0.5943  0.8659  0.7049   0.9251\n",
      "df1_raw              0.8711     0.7740  0.6517  0.7075   0.9275\n",
      "df2_OverSampling     0.8194     0.5868  0.8291  0.6872   0.9101\n",
      "df2_UnderSampling    0.8092     0.5675  0.8523  0.6813   0.9101\n",
      "df2_raw              0.8582     0.7447  0.6202  0.6767   0.9122\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# List of dataset split arrays (already defined)\n",
    "datasets = {\n",
    "    'df1_raw': df1_raw,\n",
    "    'df1_OverSampling': df1_OverSampling,\n",
    "    'df1_UnderSampling': df1_UnderSampling,\n",
    "    'df2_raw': df2_raw,\n",
    "    'df2_OverSampling': df2_OverSampling,\n",
    "    'df2_UnderSampling': df2_UnderSampling,\n",
    "}\n",
    "\n",
    "# Initialize list to collect results\n",
    "xgb_results = []\n",
    "\n",
    "for name, splits in datasets.items():\n",
    "    print(f\"\\n⚡ Running XGBoost for dataset: {name}\")\n",
    "    \n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "        print(f\"  🔁 Split {i+1}/10\")\n",
    "\n",
    "        # Initialize XGBoost model\n",
    "        model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "\n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Metrics\n",
    "        metrics = {\n",
    "            'dataset': name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "        }\n",
    "        print(f\"    Metrics: {metrics}\")\n",
    "\n",
    "        xgb_results.append(metrics)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "xgb_results_df = pd.DataFrame(xgb_results)\n",
    "\n",
    "# Show average metrics per dataset\n",
    "print(\"\\n📊 Average XGBoost Performance by Dataset:\")\n",
    "print(xgb_results_df.groupby('dataset').mean(numeric_only=True).round(4))\n",
    "\n",
    "# Optional: Save to CSV\n",
    "xgb_results_df.to_csv(\"xgboost_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9020f7",
   "metadata": {},
   "source": [
    "### **Conclusoes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a828035",
   "metadata": {},
   "source": [
    "### **Hyperparameter Tuning and Model Selection**\n",
    "\n",
    "To improve model performance, we may apply:\n",
    "\n",
    "- **Cross-validation**  \n",
    "  Using k-fold cross-validation to evaluate model reliability across different data splits.\n",
    "\n",
    "- **Grid Search or Randomized Search**  \n",
    "  For systematic tuning of hyperparameters, especially in Random Forest and Gradient Boosting models.\n",
    "\n",
    "As an enhancement, we performed hyperparameter tuning using GridSearchCV for Random Forest and RandomizedSearchCV for XGBoost. This process involved k-fold cross-validation to systematically evaluate model performance across different parameter settings. The objective was to identify configurations that improve classification metrics such as F1-score and ROC AUC, thereby strengthening the model's generalization capability. Once optimal parameters were found, the models were re-evaluated to confirm the improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc50bf",
   "metadata": {},
   "source": [
    "### **Random Forest Hyperparameter Tuning**\n",
    "\n",
    "We will find 3 different tunes. One for each of these metrics f1,precision,recall,accuracy\n",
    "\n",
    "We will use the best dataset accordingly.\n",
    "\n",
    "For example:\n",
    "\n",
    "📊 Average Random Forest Performance by Dataset:\n",
    "                   accuracy  precision  recall      f1  roc_auc\n",
    "dataset                                                        \n",
    "df1_OverSampling     0.8467     0.6792  0.6815  0.6803   0.8997\n",
    "df1_UnderSampling    0.8122     0.5746  0.8300  0.6791   0.9030\n",
    "df1_raw              0.8540     0.7305  0.6178  0.6694   0.9024\n",
    "df2_OverSampling     0.8346     0.6514  0.6647  0.6580   0.8886\n",
    "df2_UnderSampling    0.8058     0.5655  0.8156  0.6679   0.8952\n",
    "df2_raw              0.8425     0.6986  0.6016  0.6464   0.8920\n",
    "\n",
    "\n",
    "We will get the hyper parameters to maximize f1 in the df1_OverSampling\n",
    "maximize precision and accuracy in df1_raw\n",
    "maximize recall in df1_UnderSampling\n",
    "\n",
    "\n",
    "\n",
    "Best parameters for F1: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "Best F1 score from CV: 0.9346096604901941\n",
    "\n",
    "Best parameters for Precision: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "Best Precision from CV: 0.792846480758207\n",
    "\n",
    "Best parameters for Recall: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
    "Best Recall from CV: 0.8921802674082911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5852974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  13.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  14.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  15.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  25.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  13.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  26.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  26.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  13.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  26.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  13.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  28.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  11.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  26.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  25.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  26.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  28.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  11.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  23.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  26.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  24.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  12.1s[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  12.2s\n",
      "\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  12.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  22.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  24.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  24.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  23.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  11.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  12.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  12.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  22.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  11.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  13.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  21.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  23.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  23.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   5.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  12.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  11.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  11.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  12.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  12.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  12.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  10.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  10.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  11.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  11.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  12.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  12.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  10.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  12.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  12.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  12.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  10.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  10.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  11.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  11.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  10.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  10.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  21.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  21.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  21.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  22.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  22.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  10.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  20.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  11.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  10.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  11.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  21.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  20.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  11.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   9.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  10.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  22.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  22.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  11.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   9.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  19.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  20.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  10.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  20.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  20.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  21.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  13.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  13.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  13.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  14.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  13.5s\n",
      "\n",
      "🔍 Best parameters for F1: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "✅ Best F1 score from CV: 0.9346096604901941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Use split 0 from df1_OverSampling\n",
    "X_train, X_test, y_train, y_test = df1_OverSampling[0]\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearchCV for F1\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=cv, scoring='f1', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output\n",
    "print(\"\\n🔍 Best parameters for F1:\", grid_search.best_params_)\n",
    "print(\"✅ Best F1 score from CV:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e28accb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌲 Running Random Forest for dataset: df1_OverSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8485003582761798, 'precision': 0.6820882852292021, 'recall': 0.6873396065012831, 'f1': 0.6847038772901577, 'roc_auc': np.float64(0.902620331745529)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8521854846964889, 'precision': 0.6894067796610169, 'recall': 0.6958939264328486, 'f1': 0.6926351638995317, 'roc_auc': np.float64(0.9034863256933852)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8449175964786569, 'precision': 0.6719598829920602, 'recall': 0.6877673224978614, 'f1': 0.6797717184527584, 'roc_auc': np.float64(0.9007382892672466)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8490121813901116, 'precision': 0.6868774361195322, 'recall': 0.6783575705731394, 'f1': 0.6825909188723908, 'roc_auc': np.float64(0.8986955439141903)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8462483365748797, 'precision': 0.6748953974895398, 'recall': 0.6899059024807528, 'f1': 0.6823181049069373, 'roc_auc': np.float64(0.8974670475647126)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8439963148735797, 'precision': 0.6761904761904762, 'recall': 0.6680923866552609, 'f1': 0.6721170395869192, 'roc_auc': np.float64(0.8989843140870919)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8454294195925888, 'precision': 0.6752751905165114, 'recall': 0.6822070145423439, 'f1': 0.6787234042553192, 'roc_auc': np.float64(0.9013489544355547)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8470672535571706, 'precision': 0.6794217687074829, 'recall': 0.6834901625320787, 'f1': 0.6814498933901919, 'roc_auc': np.float64(0.899973857003681)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8419490224178524, 'precision': 0.6718614718614718, 'recall': 0.6638152266894782, 'f1': 0.6678141135972461, 'roc_auc': np.float64(0.8931786637233636)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8479885351622479, 'precision': 0.6839154808106943, 'recall': 0.6783575705731394, 'f1': 0.6811251878891991, 'roc_auc': np.float64(0.9006084088815276)}\n",
      "\n",
      "📊 Average Random Forest Performance by Dataset:\n",
      "                  accuracy  precision  recall      f1  roc_auc\n",
      "dataset                                                       \n",
      "df1_OverSampling    0.8467     0.6792  0.6815  0.6803   0.8997\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# List of dataset split arrays (already defined)\n",
    "datasets = {\n",
    "    'df1_OverSampling': df1_OverSampling,\n",
    "}\n",
    "\n",
    "# Initialize empty list to collect all results\n",
    "rf_results = []\n",
    "\n",
    "for name, splits in datasets.items():\n",
    "    print(f\"\\n🌲 Running Random Forest for dataset: {name}\")\n",
    "    \n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "        print(f\"  🔁 Split {i+1}/10\")\n",
    "\n",
    "        # Initialize Random Forest model\n",
    "        model = RandomForestClassifier(random_state=42, max_depth= None, min_samples_leaf= 1, min_samples_split= 2, n_estimators= 100)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Compute metrics\n",
    "        metrics = {\n",
    "            'dataset': name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "        }\n",
    "        print(f\"    Metrics: {metrics}\")\n",
    "\n",
    "        rf_results.append(metrics)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "rf_results_df = pd.DataFrame(rf_results)\n",
    "\n",
    "# Show average metrics per dataset\n",
    "print(\"\\n📊 Average Random Forest Performance by Dataset:\")\n",
    "print(rf_results_df.groupby('dataset').mean(numeric_only=True).round(4))\n",
    "\n",
    "# Optional: save to CSV\n",
    "#rf_results_df.to_csv(\"random_forest_results.csv\", index=False)\n",
    "#before hyperparameter tuning\n",
    "#df1_OverSampling     0.8467     0.6792  0.6815  0.6803   0.8997\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7149e17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  15.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  16.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  16.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  16.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  16.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  14.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  16.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   8.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  17.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  18.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  15.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  14.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  14.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   7.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  13.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  13.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  14.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  13.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  13.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  13.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   8.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   8.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   8.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   7.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   8.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  13.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  14.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   7.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   7.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   8.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   7.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   8.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   8.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   8.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   8.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   8.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   8.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   8.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   8.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   8.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   8.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  13.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  13.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  12.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  13.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  13.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  12.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  13.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  12.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  12.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  12.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  11.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  11.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  11.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  11.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  12.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   8.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   7.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   7.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   7.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.6s\n",
      "\n",
      "🎯 Best parameters for Precision: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "✅ Best Precision from CV: 0.792846480758207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = df1_raw[0]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=cv, scoring='precision', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n🎯 Best parameters for Precision:\", grid_search.best_params_)\n",
    "print(\"✅ Best Precision from CV:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7947c2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌲 Running Random Forest for dataset: df1_raw\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8581226328180981, 'precision': 0.7956521739130434, 'recall': 0.5479041916167665, 'f1': 0.648936170212766, 'roc_auc': np.float64(0.915164365311709)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8607841130105436, 'precision': 0.8018518518518518, 'recall': 0.5556030795551754, 'f1': 0.6563921172309247, 'roc_auc': np.float64(0.9139490210420614)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8562800696079435, 'precision': 0.7858017135862914, 'recall': 0.5491873396065012, 'f1': 0.6465256797583081, 'roc_auc': np.float64(0.9142692756248849)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8601699252738254, 'precision': 0.8079847908745247, 'recall': 0.5453378956372968, 'f1': 0.6511746680286006, 'roc_auc': np.float64(0.9122066726458267)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8547446002661481, 'precision': 0.7786537295330503, 'recall': 0.5491873396065012, 'f1': 0.6440933032355154, 'roc_auc': np.float64(0.9088067592826343)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8590439144231754, 'precision': 0.798261949099938, 'recall': 0.5500427715996579, 'f1': 0.6513041276272474, 'roc_auc': np.float64(0.9106933488694794)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8521854846964889, 'precision': 0.7755856966707768, 'recall': 0.5380667236954663, 'f1': 0.6353535353535353, 'roc_auc': np.float64(0.9109666934082697)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8597604667826799, 'precision': 0.8059418457648546, 'recall': 0.5453378956372968, 'f1': 0.6505102040816326, 'roc_auc': np.float64(0.9141376684890785)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8530044016787798, 'precision': 0.7811720698254364, 'recall': 0.5359281437125748, 'f1': 0.6357179096905125, 'roc_auc': np.float64(0.9051607552528601)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8574060804585935, 'precision': 0.8030788967286723, 'recall': 0.5355004277159966, 'f1': 0.6425455478573261, 'roc_auc': np.float64(0.9144535198591801)}\n",
      "\n",
      "📊 Average Random Forest Performance by Dataset:\n",
      "         accuracy  precision  recall      f1  roc_auc\n",
      "dataset                                              \n",
      "df1_raw    0.8572     0.7934  0.5452  0.6463    0.912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# List of dataset split arrays (already defined)\n",
    "datasets = {\n",
    "    'df1_raw': df1_raw,\n",
    "}\n",
    "\n",
    "# Initialize empty list to collect all results\n",
    "rf_results = []\n",
    "\n",
    "for name, splits in datasets.items():\n",
    "    print(f\"\\n🌲 Running Random Forest for dataset: {name}\")\n",
    "    \n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "        print(f\"  🔁 Split {i+1}/10\")\n",
    "\n",
    "        # Initialize Random Forest model\n",
    "        model = RandomForestClassifier(random_state=42, max_depth= 10, min_samples_leaf= 1, min_samples_split=2, n_estimators=200)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Compute metrics\n",
    "        metrics = {\n",
    "            'dataset': name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "        }\n",
    "        print(f\"    Metrics: {metrics}\")\n",
    "\n",
    "        rf_results.append(metrics)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "rf_results_df = pd.DataFrame(rf_results)\n",
    "\n",
    "# Show average metrics per dataset\n",
    "print(\"\\n📊 Average Random Forest Performance by Dataset:\")\n",
    "print(rf_results_df.groupby('dataset').mean(numeric_only=True).round(4))\n",
    "\n",
    "# Optional: save to CSV\n",
    "#rf_results_df.to_csv(\"random_forest_results.csv\", index=False)\n",
    "#before hyperparameter tuning\n",
    "#df1_raw              0.8540     0.7305  0.6178  0.6694   0.9024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78c69c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   9.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   9.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  16.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  16.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  16.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  17.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  17.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  14.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  15.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  16.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  17.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  14.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  13.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  13.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  12.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  13.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  13.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  14.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   8.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   7.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  14.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  13.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   8.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   8.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  14.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  14.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   8.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   7.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   7.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   7.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   7.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   7.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   7.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   7.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   7.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   8.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   8.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   7.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   8.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   8.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   7.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   8.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  13.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  14.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  15.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  14.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  14.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  14.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  14.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  14.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  15.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  14.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   7.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   9.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   7.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   7.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  14.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  13.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  14.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  14.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  14.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   9.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   9.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   8.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   7.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.8s\n",
      "\n",
      "🎯 Best parameters for Accuracy: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "✅ Best Precision from CV: 0.8632046128141477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = df1_raw[0]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n🎯 Best parameters for Accuracy:\", grid_search.best_params_)\n",
    "print(\"✅ Best Precision from CV:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62761746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌲 Running Random Forest for dataset: df1_raw\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8683590950967346, 'precision': 0.7849404117009751, 'recall': 0.6197604790419161, 'f1': 0.6926386233269598, 'roc_auc': np.float64(0.9195892487474442)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8657999795270754, 'precision': 0.7738666666666667, 'recall': 0.6206159110350727, 'f1': 0.6888203180631379, 'roc_auc': np.float64(0.9189594742115054)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8638550516941345, 'precision': 0.771551724137931, 'recall': 0.6124893071000855, 'f1': 0.6828803051979018, 'roc_auc': np.float64(0.9177109763401854)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8657999795270754, 'precision': 0.7804478427089022, 'recall': 0.6112061591103507, 'f1': 0.6855360997841209, 'roc_auc': np.float64(0.9161577358576577)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8635479578257754, 'precision': 0.7688603531300161, 'recall': 0.6146278870829769, 'f1': 0.6831471357261707, 'roc_auc': np.float64(0.9141402586142093)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8632408639574163, 'precision': 0.7696447793326158, 'recall': 0.611633875106929, 'f1': 0.6816015252621545, 'roc_auc': np.float64(0.9153802378517663)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8595557375371071, 'precision': 0.7558262711864406, 'recall': 0.6103507271171942, 'f1': 0.6753431140558448, 'roc_auc': np.float64(0.9183254691378533)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8655952502815027, 'precision': 0.7817482133040132, 'recall': 0.6082121471343028, 'f1': 0.6841472215540053, 'roc_auc': np.float64(0.918928018580752)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8581226328180981, 'precision': 0.7647385984427141, 'recall': 0.588109495295124, 'f1': 0.6648936170212766, 'roc_auc': np.float64(0.9105340273947751)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8645716040536391, 'precision': 0.7827298050139275, 'recall': 0.6009409751924722, 'f1': 0.679893539801597, 'roc_auc': np.float64(0.9179983938921856)}\n",
      "\n",
      "📊 Average Random Forest Performance by Dataset:\n",
      "         accuracy  precision  recall      f1  roc_auc\n",
      "dataset                                              \n",
      "df1_raw    0.8638     0.7734  0.6098  0.6819   0.9168\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# List of dataset split arrays (already defined)\n",
    "datasets = {\n",
    "    'df1_raw': df1_raw,\n",
    "}\n",
    "\n",
    "# Initialize empty list to collect all results\n",
    "rf_results = []\n",
    "\n",
    "for name, splits in datasets.items():\n",
    "    print(f\"\\n🌲 Running Random Forest for dataset: {name}\")\n",
    "    \n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "        print(f\"  🔁 Split {i+1}/10\")\n",
    "\n",
    "        # Initialize Random Forest model\n",
    "        model = RandomForestClassifier(random_state=42, max_depth= None, min_samples_leaf= 2, min_samples_split=2, n_estimators=100)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Compute metrics\n",
    "        metrics = {\n",
    "            'dataset': name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "        }\n",
    "        print(f\"    Metrics: {metrics}\")\n",
    "\n",
    "        rf_results.append(metrics)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "rf_results_df = pd.DataFrame(rf_results)\n",
    "\n",
    "# Show average metrics per dataset\n",
    "print(\"\\n📊 Average Random Forest Performance by Dataset:\")\n",
    "print(rf_results_df.groupby('dataset').mean(numeric_only=True).round(4))\n",
    "\n",
    "# Optional: save to CSV\n",
    "#rf_results_df.to_csv(\"random_forest_results.csv\", index=False)\n",
    "#before hyperparameter tuning\n",
    "#df1_raw              0.8540     0.7305  0.6178  0.6694   0.9024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9134a3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "\n",
      "📈 Best parameters for Recall: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "✅ Best Recall from CV: 0.8921802674082911\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = df1_UnderSampling[0]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=cv, scoring='recall', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n📈 Best parameters for Recall:\", grid_search.best_params_)\n",
    "print(\"✅ Best Recall from CV:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a1def55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌲 Running Random Forest for dataset: df1_UnderSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7968062237690654, 'precision': 0.5462405030128373, 'recall': 0.8917878528656972, 'f1': 0.677497969130788, 'roc_auc': np.float64(0.9136711581738768)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7906643464018835, 'precision': 0.5377674658417118, 'recall': 0.8922155688622755, 'f1': 0.6710632137686987, 'roc_auc': np.float64(0.9109044440676293)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7887194185689426, 'precision': 0.5349133537206932, 'recall': 0.897775876817793, 'f1': 0.6703928457361865, 'roc_auc': np.float64(0.9113719040953794)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7936329204626881, 'precision': 0.5428647497337593, 'recall': 0.8721129170230967, 'f1': 0.66918280275681, 'roc_auc': np.float64(0.9086794690220459)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7811444364827516, 'precision': 0.5251762336354482, 'recall': 0.8922155688622755, 'f1': 0.6611727416798732, 'roc_auc': np.float64(0.9067775689177617)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7824751765789743, 'precision': 0.5269961977186312, 'recall': 0.8892215568862275, 'f1': 0.6617857711284418, 'roc_auc': np.float64(0.907653088770265)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7899477940423789, 'precision': 0.5366666666666666, 'recall': 0.8952095808383234, 'f1': 0.6710484129528695, 'roc_auc': np.float64(0.9086359836990188)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7923021803664654, 'precision': 0.5397683397683398, 'recall': 0.8969204448246364, 'f1': 0.6739514703519203, 'roc_auc': np.float64(0.9111881778861102)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7887194185689426, 'precision': 0.5356585111920874, 'recall': 0.8802395209580839, 'f1': 0.6660194174757281, 'roc_auc': np.float64(0.9016362856500506)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.8007984440577336, 'precision': 0.5519618239660657, 'recall': 0.8905047048759623, 'f1': 0.681505728314239, 'roc_auc': np.float64(0.9113947547548653)}\n",
      "\n",
      "📊 Average Random Forest Performance by Dataset:\n",
      "                   accuracy  precision  recall      f1  roc_auc\n",
      "dataset                                                        \n",
      "df1_UnderSampling    0.7905     0.5378  0.8898  0.6704   0.9092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# List of dataset split arrays (already defined)\n",
    "datasets = {\n",
    "    'df1_UnderSampling': df1_UnderSampling,\n",
    "}\n",
    "\n",
    "# Initialize empty list to collect all results\n",
    "rf_results = []\n",
    "\n",
    "for name, splits in datasets.items():\n",
    "    print(f\"\\n🌲 Running Random Forest for dataset: {name}\")\n",
    "    \n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "        print(f\"  🔁 Split {i+1}/10\")\n",
    "\n",
    "        # Initialize Random Forest model\n",
    "        model = RandomForestClassifier(random_state=42, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators= 100)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Compute metrics\n",
    "        metrics = {\n",
    "            'dataset': name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "        }\n",
    "        print(f\"    Metrics: {metrics}\")\n",
    "\n",
    "        rf_results.append(metrics)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "rf_results_df = pd.DataFrame(rf_results)\n",
    "\n",
    "# Show average metrics per dataset\n",
    "print(\"\\n📊 Average Random Forest Performance by Dataset:\")\n",
    "print(rf_results_df.groupby('dataset').mean(numeric_only=True).round(4))\n",
    "\n",
    "# Optional: save to CSV\n",
    "#rf_results_df.to_csv(\"random_forest_results.csv\", index=False)\n",
    "#before hyperparameter tuning\n",
    "#df1_UnderSampling    0.8122     0.5746  0.8300  0.6791   0.9030\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f56527",
   "metadata": {},
   "source": [
    "### Governement use case (recall for label 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c72ac544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.6s[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.0s\n",
      "\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   7.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   5.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   5.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   5.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "\n",
      "🎯 Best parameters for Recall (≤$50K class): {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "✅ Best Recall for ≤$50K from CV: 0.8067176533534761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "\n",
    "# Create a custom scorer for recall of class 0 (≤$50K)\n",
    "recall_class0_scorer = make_scorer(recall_score, pos_label=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = df1_UnderSampling[0]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=cv, scoring=recall_class0_scorer, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n🎯 Best parameters for Recall (≤$50K class):\", grid_search.best_params_)\n",
    "print(\"✅ Best Recall for ≤$50K from CV:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f3cc2803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌲 Running Random Forest for dataset: df1_UnderSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8182004299314157, 'precision': 0.9411764705882353, 'recall': 0.8117346252186786, 'f1': 0.8716763005780347, 'roc_auc': np.float64(0.9112015026409492)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8169720544579793, 'precision': 0.9452422281836831, 'recall': 0.8060826268335352, 'f1': 0.8701336432306799, 'roc_auc': np.float64(0.9113706953703182)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8087828846350701, 'precision': 0.9431256969890075, 'recall': 0.796662629524963, 'f1': 0.8637292092208929, 'roc_auc': np.float64(0.9079415423723174)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8158460436073293, 'precision': 0.9391765439800375, 'recall': 0.8103889113174539, 'f1': 0.8700426208191866, 'roc_auc': np.float64(0.9081998641853499)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8125703756781656, 'precision': 0.9431782209559987, 'recall': 0.8019109137397389, 'f1': 0.8668266783038766, 'roc_auc': np.float64(0.9072624691213915)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8132869280376702, 'precision': 0.9411487018095988, 'recall': 0.804871484322433, 'f1': 0.8676918613085739, 'roc_auc': np.float64(0.9072891186310693)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8125703756781656, 'precision': 0.9405286343612335, 'recall': 0.8044677701520657, 'f1': 0.8671937332269529, 'roc_auc': np.float64(0.9089204369967029)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8188146176681339, 'precision': 0.9451171567856581, 'recall': 0.8087740546359844, 'f1': 0.8716461203770849, 'roc_auc': np.float64(0.9107849241824328)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8116490940730884, 'precision': 0.9379602067993107, 'recall': 0.8056789126631678, 'f1': 0.8668017952801506, 'roc_auc': np.float64(0.9033095640428009)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8249564950353158, 'precision': 0.9417760617760618, 'recall': 0.8206163369667608, 'f1': 0.8770314971954551, 'roc_auc': np.float64(0.9108602680445671)}\n",
      "\n",
      "📊 Average Random Forest Performance (≤$50K as positive class):\n",
      "                   accuracy  precision  recall      f1  roc_auc\n",
      "dataset                                                        \n",
      "df1_UnderSampling    0.8154     0.9418  0.8071  0.8693   0.9087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# List of dataset split arrays (already defined)\n",
    "datasets = {\n",
    "    'df1_UnderSampling': df1_UnderSampling,\n",
    "}\n",
    "\n",
    "# Initialize empty list to collect all results\n",
    "rf_results = []\n",
    "\n",
    "for name, splits in datasets.items():\n",
    "    print(f\"\\n🌲 Running Random Forest for dataset: {name}\")\n",
    "    \n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "        print(f\"  🔁 Split {i+1}/{len(splits)}\")\n",
    "\n",
    "        # Initialize Random Forest model with best parameters from grid search\n",
    "        model = RandomForestClassifier(\n",
    "            random_state=42,\n",
    "            # Use the best parameters from your grid search\n",
    "            max_depth=grid_search.best_params_['max_depth'],\n",
    "            min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n",
    "            min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "            n_estimators=grid_search.best_params_['n_estimators']\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]  # Probability of class 1 (>50K)\n",
    "        \n",
    "        # Calculate metrics for ≤$50K as positive class (class 0)\n",
    "        # Convert targets to binary format for metrics calculation\n",
    "        y_test_binary = (y_test == 0).astype(int)  # 1 for ≤$50K, 0 for >$50K\n",
    "        y_pred_binary = (y_pred == 0).astype(int)  # 1 for ≤$50K, 0 for >$50K\n",
    "        \n",
    "        # Now calculate metrics with ≤$50K as the positive class\n",
    "        metrics = {\n",
    "            'dataset': name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test_binary, y_pred_binary),  # For ≤$50K\n",
    "            'recall': recall_score(y_test_binary, y_pred_binary),        # For ≤$50K\n",
    "            'f1': f1_score(y_test_binary, y_pred_binary),                # For ≤$50K\n",
    "            'roc_auc': roc_auc_score(y_test_binary, 1-y_proba)           # For ≤$50K, using 1-proba\n",
    "        }\n",
    "        print(f\"    Metrics (≤$50K as positive class): {metrics}\")\n",
    "\n",
    "        rf_results.append(metrics)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "rf_results_df = pd.DataFrame(rf_results)\n",
    "\n",
    "# Show average metrics per dataset\n",
    "print(\"\\n📊 Average Random Forest Performance (≤$50K as positive class):\")\n",
    "print(rf_results_df.groupby('dataset').mean(numeric_only=True).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79299a8",
   "metadata": {},
   "source": [
    "### **XGboost Hyperparameter Tuning**\n",
    "\n",
    "We will find 3 different tunes. One for each of these metrics f1,precision,recall,accuracy\n",
    "\n",
    "We will use the best dataset accordingly.\n",
    "\n",
    "For example:\n",
    "\n",
    "📊 Average XGBoost Performance by Dataset:\n",
    "                   accuracy  precision  recall      f1  roc_auc\n",
    "dataset                                                        \n",
    "df1_OverSampling     0.8357     0.6135  0.8472  0.7116   0.9268\n",
    "df1_UnderSampling    0.8264     0.5943  0.8659  0.7049   0.9251\n",
    "df1_raw              0.8711     0.7740  0.6517  0.7075   0.9275\n",
    "df2_OverSampling     0.8194     0.5868  0.8291  0.6872   0.9101\n",
    "df2_UnderSampling    0.8092     0.5675  0.8523  0.6813   0.9101\n",
    "df2_raw              0.8582     0.7447  0.6202  0.6767   0.9122\n",
    "\n",
    "\n",
    "We will get the hyper parameters to maximize f1 in the df1_OverSampling\n",
    "maximize precision and accuracy in df1_raw\n",
    "maximize recall in df1_UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdf99646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Define parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Common cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff2ddc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.6s[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.1s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.3s[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   6.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   6.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   6.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.4s\n",
      "\n",
      "🎯 Best parameters for F1: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "✅ Best F1 score from CV: 0.9204395724977565\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = df1_OverSampling[0]\n",
    "\n",
    "grid_search_f1 = GridSearchCV(\n",
    "    estimator=XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search_f1.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n🎯 Best parameters for F1:\", grid_search_f1.best_params_)\n",
    "print(\"✅ Best F1 score from CV:\", grid_search_f1.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91c38fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚡ Running XGBoost for dataset: df1_OverSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8501381922407616, 'precision': 0.662938105891126, 'recall': 0.7604790419161677, 'f1': 0.7083665338645418, 'roc_auc': np.float64(0.9176437482034604)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8573037158358071, 'precision': 0.6778447626224566, 'recall': 0.7694610778443114, 'f1': 0.7207532051282052, 'roc_auc': np.float64(0.9226177669460663)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8499334629951889, 'precision': 0.6602941176470588, 'recall': 0.7681779298545766, 'f1': 0.7101621194147885, 'roc_auc': np.float64(0.9180161506389146)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8439963148735797, 'precision': 0.6520926756352765, 'recall': 0.7463644140290847, 'f1': 0.6960510570402872, 'roc_auc': np.float64(0.9149049211111202)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8463507011976661, 'precision': 0.6565656565656566, 'recall': 0.7506415739948674, 'f1': 0.7004589902215127, 'roc_auc': np.float64(0.9137610067367427)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8433821271368614, 'precision': 0.6488577745025792, 'recall': 0.7532078699743371, 'f1': 0.6971496437054632, 'roc_auc': np.float64(0.9118821587461216)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8518783908281298, 'precision': 0.6680497925311203, 'recall': 0.7574850299401198, 'f1': 0.7099619162156745, 'roc_auc': np.float64(0.9187821945358952)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8538233186610708, 'precision': 0.6709241172051089, 'recall': 0.7639007698887939, 'f1': 0.7144, 'roc_auc': np.float64(0.9181204175650084)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8408230115672024, 'precision': 0.6514506769825918, 'recall': 0.72027373823781, 'f1': 0.6841356896201504, 'roc_auc': np.float64(0.9093136467707067)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_OverSampling', 'accuracy': 0.8526973078104207, 'precision': 0.6736191579760525, 'recall': 0.7459366980325064, 'f1': 0.7079358636086869, 'roc_auc': np.float64(0.9190494378910441)}\n",
      "\n",
      "📊 Average XGBoost Performance by Dataset:\n",
      "                  accuracy  precision  recall      f1  roc_auc\n",
      "dataset                                                       \n",
      "df1_OverSampling     0.849     0.6623  0.7536  0.7049   0.9164\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# List of dataset split arrays (already defined)\n",
    "datasets = {\n",
    "    'df1_OverSampling': df1_OverSampling,\n",
    "}\n",
    "\n",
    "# Initialize list to collect results\n",
    "xgb_results = []\n",
    "\n",
    "for name, splits in datasets.items():\n",
    "    print(f\"\\n⚡ Running XGBoost for dataset: {name}\")\n",
    "    \n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "        print(f\"  🔁 Split {i+1}/10\")\n",
    "\n",
    "        # Initialize XGBoost model\n",
    "        model = XGBClassifier(eval_metric='logloss', random_state=42, colsample_bytree=1.0, learning_rate=0.2, max_depth= 10, n_estimators= 200, subsample= 0.8)\n",
    "\n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Metrics\n",
    "        metrics = {\n",
    "            'dataset': name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "        }\n",
    "        print(f\"    Metrics: {metrics}\")\n",
    "\n",
    "        xgb_results.append(metrics)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "xgb_results_df = pd.DataFrame(xgb_results)\n",
    "\n",
    "# Show average metrics per dataset\n",
    "print(\"\\n📊 Average XGBoost Performance by Dataset:\")\n",
    "print(xgb_results_df.groupby('dataset').mean(numeric_only=True).round(4))\n",
    "\n",
    "# Optional: Save to CSV\n",
    "#xgb_results_df.to_csv(\"xgboost_results.csv\", index=False)\n",
    "\n",
    "#before hyperparameter tuning\n",
    "#df1_OverSampling     0.8357     0.6135  0.8472  0.7116   0.9268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcf72e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.6s[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.7s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "\n",
      "🎯 Best parameters for Precision: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "✅ Best Precision from CV: 0.9863354706941946\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = df1_raw[0]\n",
    "\n",
    "grid_search_precision = GridSearchCV(\n",
    "    estimator=XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=cv,\n",
    "    scoring='precision',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search_precision.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n🎯 Best parameters for Precision:\", grid_search_precision.best_params_)\n",
    "print(\"✅ Best Precision from CV:\", grid_search_precision.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0dd2b7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚡ Running XGBoost for dataset: df1_raw\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8184051591769884, 'precision': 0.9845360824742269, 'recall': 0.24508126603934988, 'f1': 0.39246575342465756, 'roc_auc': np.float64(0.9008494056353527)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8182004299314157, 'precision': 0.9795221843003413, 'recall': 0.24550898203592814, 'f1': 0.39261285909712723, 'roc_auc': np.float64(0.8971859902088667)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8173815129491248, 'precision': 0.9775862068965517, 'recall': 0.24251497005988024, 'f1': 0.3886223440712817, 'roc_auc': np.float64(0.8978009434732244)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8177909714402702, 'precision': 0.9894736842105263, 'recall': 0.24123182207014543, 'f1': 0.3878954607977992, 'roc_auc': np.float64(0.8971844361337882)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8155389497389702, 'precision': 0.9855072463768116, 'recall': 0.23267750213858, 'f1': 0.3764705882352941, 'roc_auc': np.float64(0.8931918158031937)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8142082096427474, 'precision': 0.9869646182495344, 'recall': 0.22668947818648416, 'f1': 0.36869565217391304, 'roc_auc': np.float64(0.8940087988277439)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8153342204933974, 'precision': 0.9819494584837545, 'recall': 0.23267750213858, 'f1': 0.37621023513139695, 'roc_auc': np.float64(0.8941584217227923)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8131845634148838, 'precision': 0.9885714285714285, 'recall': 0.2219846022241232, 'f1': 0.3625567586447782, 'roc_auc': np.float64(0.8953761834425619)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8121609171870202, 'precision': 0.9864603481624759, 'recall': 0.21813515825491872, 'f1': 0.3572679509632224, 'roc_auc': np.float64(0.8883313596579838)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8158460436073293, 'precision': 0.9855855855855856, 'recall': 0.2339606501283148, 'f1': 0.37815416522640855, 'roc_auc': np.float64(0.8968169261569139)}\n",
      "\n",
      "📊 Average XGBoost Performance by Dataset:\n",
      "         accuracy  precision  recall      f1  roc_auc\n",
      "dataset                                              \n",
      "df1_raw    0.8158     0.9846   0.234  0.3781   0.8955\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# List of dataset split arrays (already defined)\n",
    "datasets = {\n",
    "    'df1_raw': df1_raw\n",
    "}\n",
    "\n",
    "# Initialize list to collect results\n",
    "xgb_results = []\n",
    "\n",
    "for name, splits in datasets.items():\n",
    "    print(f\"\\n⚡ Running XGBoost for dataset: {name}\")\n",
    "    \n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "        print(f\"  🔁 Split {i+1}/10\")\n",
    "\n",
    "        # Initialize XGBoost model\n",
    "        model = XGBClassifier(eval_metric='logloss', random_state=42, colsample_bytree=0.8, learning_rate=0.01, max_depth= 3, n_estimators= 100, subsample= 1.0)\n",
    "\n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Metrics\n",
    "        metrics = {\n",
    "            'dataset': name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "        }\n",
    "        print(f\"    Metrics: {metrics}\")\n",
    "\n",
    "        xgb_results.append(metrics)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "xgb_results_df = pd.DataFrame(xgb_results)\n",
    "\n",
    "# Show average metrics per dataset\n",
    "print(\"\\n📊 Average XGBoost Performance by Dataset:\")\n",
    "print(xgb_results_df.groupby('dataset').mean(numeric_only=True).round(4))\n",
    "\n",
    "# Optional: Save to CSV\n",
    "#xgb_results_df.to_csv(\"xgboost_results.csv\", index=False)\n",
    "\n",
    "#before hyperparameter tuning\n",
    "#df1_raw              0.8711     0.7740  0.6517  0.7075   0.9275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3799b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.9s[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.9s[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "\n",
      "🎯 Best parameters for Accuracy: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'subsample': 1.0}\n",
      "✅ Best Accuracy from CV: 0.8736722790810857\n"
     ]
    }
   ],
   "source": [
    "grid_search_accuracy = GridSearchCV(\n",
    "    estimator=XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search_accuracy.fit(X_train, y_train)  # reuse X_train, y_train from df1_raw\n",
    "\n",
    "print(\"\\n🎯 Best parameters for Accuracy:\", grid_search_accuracy.best_params_)\n",
    "print(\"✅ Best Accuracy from CV:\", grid_search_accuracy.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d13c6e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚡ Running XGBoost for dataset: df1_raw\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8773671819019347, 'precision': 0.7911133810010215, 'recall': 0.6625320786997434, 'f1': 0.7211359404096834, 'roc_auc': np.float64(0.931582794385852)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8759340771829256, 'precision': 0.7863682604272635, 'recall': 0.6612489307100086, 'f1': 0.7184014869888475, 'roc_auc': np.float64(0.9328072904309611)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8748080663322756, 'precision': 0.7772252610641472, 'recall': 0.6685201026518391, 'f1': 0.7187859277994941, 'roc_auc': np.float64(0.930450794587076)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8723513153854028, 'precision': 0.7854526425954997, 'recall': 0.6420017108639863, 'f1': 0.7065191809837609, 'roc_auc': np.float64(0.927945596781522)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8695874705701709, 'precision': 0.77170582226762, 'recall': 0.646278870829769, 'f1': 0.7034450651769087, 'roc_auc': np.float64(0.9255422196727717)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8705087521752483, 'precision': 0.7727503812913066, 'recall': 0.6501283147989735, 'f1': 0.7061556329849012, 'roc_auc': np.float64(0.9263168685410194)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8699969290613164, 'precision': 0.770242914979757, 'recall': 0.65098374679213, 'f1': 0.7056096430227168, 'roc_auc': np.float64(0.9306142314828212)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8748080663322756, 'precision': 0.7902134305049453, 'recall': 0.649272882805817, 'f1': 0.7128433904672459, 'roc_auc': np.float64(0.9307877410874081)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.8646739686764254, 'precision': 0.7684989429175476, 'recall': 0.6218990590248076, 'f1': 0.6874704491725768, 'roc_auc': np.float64(0.9236157421589142)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_raw', 'accuracy': 0.874091513972771, 'precision': 0.7876427829698858, 'recall': 0.6488451668092386, 'f1': 0.7115384615384616, 'roc_auc': np.float64(0.9318817811634359)}\n",
      "\n",
      "📊 Average XGBoost Performance by Dataset:\n",
      "         accuracy  precision  recall      f1  roc_auc\n",
      "dataset                                              \n",
      "df1_raw    0.8724     0.7801  0.6502  0.7092   0.9292\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# List of dataset split arrays (already defined)\n",
    "datasets = {\n",
    "    'df1_raw': df1_raw,\n",
    "}\n",
    "\n",
    "# Initialize list to collect results\n",
    "xgb_results = []\n",
    "\n",
    "for name, splits in datasets.items():\n",
    "    print(f\"\\n⚡ Running XGBoost for dataset: {name}\")\n",
    "    \n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "        print(f\"  🔁 Split {i+1}/10\")\n",
    "\n",
    "        # Initialize XGBoost model\n",
    "        model = XGBClassifier(eval_metric='logloss', random_state=42, colsample_bytree=0.8, learning_rate=0.1, max_depth= 6, n_estimators= 200, subsample= 1.0)\n",
    "\n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Metrics\n",
    "        metrics = {\n",
    "            'dataset': name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "        }\n",
    "        print(f\"    Metrics: {metrics}\")\n",
    "\n",
    "        xgb_results.append(metrics)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "xgb_results_df = pd.DataFrame(xgb_results)\n",
    "\n",
    "# Show average metrics per dataset\n",
    "print(\"\\n📊 Average XGBoost Performance by Dataset:\")\n",
    "print(xgb_results_df.groupby('dataset').mean(numeric_only=True).round(4))\n",
    "\n",
    "# Optional: Save to CSV\n",
    "#xgb_results_df.to_csv(\"xgboost_results.csv\", index=False)\n",
    "\n",
    "#before hyperparameter tuning\n",
    "#df1_raw              0.8711     0.7740  0.6517  0.7075   0.9275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82d33e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.2s[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.4s[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.1s[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "\n",
      "📈 Best parameters for Recall: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
      "✅ Best Recall from CV: 0.8808412517203001\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = df1_UnderSampling[0]\n",
    "\n",
    "grid_search_recall = GridSearchCV(\n",
    "    estimator=XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=cv,\n",
    "    scoring='recall',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search_recall.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n📈 Best parameters for Recall:\", grid_search_recall.best_params_)\n",
    "print(\"✅ Best Recall from CV:\", grid_search_recall.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83e165ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚡ Running XGBoost for dataset: df1_UnderSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7787900501586652, 'precision': 0.5222865776882397, 'recall': 0.8870829769033362, 'f1': 0.6574734506260898, 'roc_auc': np.float64(0.9069654681064079)}\n",
      "  🔁 Split 2/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7774593100624424, 'precision': 0.520686175580222, 'recall': 0.8828058169375534, 'f1': 0.6550301491589972, 'roc_auc': np.float64(0.9039647505841883)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7772545808168697, 'precision': 0.5201292246520874, 'recall': 0.8952095808383234, 'f1': 0.6579691920779629, 'roc_auc': np.float64(0.9039258699280601)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7821680827106152, 'precision': 0.527244421380384, 'recall': 0.8691189050470488, 'f1': 0.6563307493540051, 'roc_auc': np.float64(0.9011674442222309)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7689630463711741, 'precision': 0.5099582001475289, 'recall': 0.8870829769033362, 'f1': 0.6476190476190476, 'roc_auc': np.float64(0.899263414459506)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7695772341078924, 'precision': 0.510866849862603, 'recall': 0.8746792130025663, 'f1': 0.6450086737107712, 'roc_auc': np.float64(0.8996177723565499)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7761285699662197, 'precision': 0.5187577639751553, 'recall': 0.893071000855432, 'f1': 0.6562942008486563, 'roc_auc': np.float64(0.9014503722240046)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7757191114750742, 'precision': 0.5184812672868997, 'recall': 0.8819503849443969, 'f1': 0.6530482977038796, 'roc_auc': np.float64(0.9015293710404901)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7735694543965606, 'precision': 0.5159251769464105, 'recall': 0.8729683490162532, 'f1': 0.6485541785827772, 'roc_auc': np.float64(0.8949255592281611)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics: {'dataset': 'df1_UnderSampling', 'accuracy': 0.7919950864981062, 'precision': 0.540326831839747, 'recall': 0.8768177929854577, 'f1': 0.6686236138290933, 'roc_auc': np.float64(0.9025263389824538)}\n",
      "\n",
      "📊 Average XGBoost Performance by Dataset:\n",
      "                   accuracy  precision  recall      f1  roc_auc\n",
      "dataset                                                        \n",
      "df1_UnderSampling    0.7772     0.5205  0.8821  0.6546   0.9015\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# List of dataset split arrays (already defined)\n",
    "datasets = {\n",
    "    'df1_UnderSampling': df1_UnderSampling,\n",
    "}\n",
    "\n",
    "# Initialize list to collect results\n",
    "xgb_results = []\n",
    "\n",
    "for name, splits in datasets.items():\n",
    "    print(f\"\\n⚡ Running XGBoost for dataset: {name}\")\n",
    "    \n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "        print(f\"  🔁 Split {i+1}/10\")\n",
    "\n",
    "        # Initialize XGBoost model\n",
    "        model = XGBClassifier(eval_metric='logloss', random_state=42, colsample_bytree=0.8, learning_rate=0.01, max_depth= 3, n_estimators= 200, subsample= 1.0)\n",
    "\n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Metrics\n",
    "        metrics = {\n",
    "            'dataset': name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_proba)\n",
    "        }\n",
    "        print(f\"    Metrics: {metrics}\")\n",
    "\n",
    "        xgb_results.append(metrics)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "xgb_results_df = pd.DataFrame(xgb_results)\n",
    "\n",
    "# Show average metrics per dataset\n",
    "print(\"\\n📊 Average XGBoost Performance by Dataset:\")\n",
    "print(xgb_results_df.groupby('dataset').mean(numeric_only=True).round(4))\n",
    "\n",
    "# Optional: Save to CSV\n",
    "#xgb_results_df.to_csv(\"xgboost_results.csv\", index=False)\n",
    "\n",
    "#before hyperparameter tuning\n",
    "#df1_UnderSampling    0.8264     0.5943  0.8659  0.7049   0.9251"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8dce3",
   "metadata": {},
   "source": [
    "### XGBoost UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4df5a439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.7s[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "\n",
      "📈 Best parameters for Recall (≤$50K class): {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 10, 'n_estimators': 100, 'subsample': 1.0}\n",
      "✅ Best Recall for ≤$50K from CV: 0.81752065075264\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "\n",
    "# Create a custom scorer for recall of class 0 (≤$50K)\n",
    "recall_class0_scorer = make_scorer(recall_score, pos_label=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = df1_UnderSampling[0]\n",
    "\n",
    "# Define parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Set up cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Grid search with custom scorer\n",
    "grid_search_recall = GridSearchCV(\n",
    "    estimator=XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=cv,\n",
    "    scoring=recall_class0_scorer,  # Using the custom scorer\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search_recall.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n📈 Best parameters for Recall (≤$50K class):\", grid_search_recall.best_params_)\n",
    "print(\"✅ Best Recall for ≤$50K from CV:\", grid_search_recall.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44496eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚡ Running XGBoost for dataset: df1_UnderSampling\n",
      "  🔁 Split 1/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8298699969290613, 'precision': 0.949229092041738, 'recall': 0.8202126227963935, 'f1': 0.8800173260179035, 'roc_auc': np.float64(0.0744287133674286)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Interpretation:\n",
      "True Negatives (correctly identified as <=50K): 6095\n",
      "False Positives (>50K incorrectly identified as <=50K): 1336\n",
      "False Negatives (<=50K incorrectly identified as >50K): 326\n",
      "True Positives (correctly identified as >50K): 2012\n",
      "\n",
      "Recall for <=50K class: 0.9492\n",
      "This means we correctly identify 94.92% of people who might need assistance\n",
      "We miss 5.08% of people who might need assistance\n",
      "  🔁 Split 2/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8246494011669567, 'precision': 0.9526599113362888, 'recall': 0.8097160543668416, 'f1': 0.8753909943987779, 'roc_auc': np.float64(0.0740029831334505)}\n",
      "  🔁 Split 3/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8186098884225612, 'precision': 0.9510600988362825, 'recall': 0.8028529134705962, 'f1': 0.8706946876824285, 'roc_auc': np.float64(0.07656902010040707)}\n",
      "  🔁 Split 4/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8224997440884431, 'precision': 0.9458444200970418, 'recall': 0.8132149105100256, 'f1': 0.8745296671490593, 'roc_auc': np.float64(0.07800351773527747)}\n",
      "  🔁 Split 5/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8200429931415703, 'precision': 0.9497383859204059, 'recall': 0.8060826268335352, 'f1': 0.8720337749308488, 'roc_auc': np.float64(0.08023407593947579)}\n",
      "  🔁 Split 6/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8178933360630566, 'precision': 0.9460227272727273, 'recall': 0.806620912394025, 'f1': 0.8707779472651994, 'roc_auc': np.float64(0.08041075125255573)}\n",
      "  🔁 Split 7/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8282321629644794, 'precision': 0.9493829089204812, 'recall': 0.8177903377741892, 'f1': 0.8786871023713129, 'roc_auc': np.float64(0.07614757796247865)}\n",
      "  🔁 Split 8/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8273108813594022, 'precision': 0.9479101684341859, 'recall': 0.8179249091643117, 'f1': 0.8781333525969804, 'roc_auc': np.float64(0.07538809571582941)}\n",
      "  🔁 Split 9/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8237281195618794, 'precision': 0.9441419013536643, 'recall': 0.8165791952630871, 'f1': 0.8757396449704142, 'roc_auc': np.float64(0.08092989866624671)}\n",
      "  🔁 Split 10/10\n",
      "    Metrics (≤$50K as positive class): {'dataset': 'df1_UnderSampling', 'accuracy': 0.8312007370252841, 'precision': 0.9473847106159083, 'recall': 0.8238460503296999, 'f1': 0.8813071330886058, 'roc_auc': np.float64(0.07438980393213226)}\n",
      "\n",
      "📊 Average XGBoost Performance (≤$50K as positive class):\n",
      "                   accuracy  precision  recall      f1  roc_auc\n",
      "dataset                                                        \n",
      "df1_UnderSampling    0.8244     0.9483  0.8135  0.8757   0.0771\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# List of dataset split arrays\n",
    "datasets = {\n",
    "    'df1_UnderSampling': df1_UnderSampling,\n",
    "}\n",
    "\n",
    "# Initialize list to collect results\n",
    "xgb_results = []\n",
    "\n",
    "for name, splits in datasets.items():\n",
    "    print(f\"\\n⚡ Running XGBoost for dataset: {name}\")\n",
    "    \n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(splits):\n",
    "        print(f\"  🔁 Split {i+1}/10\")\n",
    "\n",
    "        # Initialize XGBoost model with best parameters from grid search\n",
    "        model = XGBClassifier(\n",
    "            eval_metric='logloss', \n",
    "            random_state=42,\n",
    "            # Use the best parameters from your grid search\n",
    "            colsample_bytree=grid_search_recall.best_params_['colsample_bytree'],\n",
    "            learning_rate=grid_search_recall.best_params_['learning_rate'],\n",
    "            max_depth=grid_search_recall.best_params_['max_depth'],\n",
    "            n_estimators=grid_search_recall.best_params_['n_estimators'],\n",
    "            subsample=grid_search_recall.best_params_['subsample']\n",
    "        )\n",
    "\n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]  # Prob of class 1 (>$50K)\n",
    "\n",
    "        # Metrics for ≤$50K as positive class\n",
    "        metrics = {\n",
    "            'dataset': name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred, pos_label=0),  # For ≤$50K\n",
    "            'recall': recall_score(y_test, y_pred, pos_label=0),        # For ≤$50K\n",
    "            'f1': f1_score(y_test, y_pred, pos_label=0),                # For ≤$50K\n",
    "            'roc_auc': roc_auc_score(y_test, 1 - y_proba)               # Flip probs for ≤$50K\n",
    "        }\n",
    "        print(f\"    Metrics (≤$50K as positive class): {metrics}\")\n",
    "\n",
    "        # Create confusion matrix (only for the first split)\n",
    "        if i == 0:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"<=50K\", \">50K\"])\n",
    "            disp.plot(cmap='Blues', values_format='d')\n",
    "            plt.title('Confusion Matrix - Policy Making Model (XGBoost)\\nOptimized for <=50K Recall', fontsize=15)\n",
    "            \n",
    "            # Add subtitle for clarity\n",
    "            plt.figtext(0.5, 0.01, \n",
    "                    'Model optimized to minimize false negatives for the <=50K class (people who need assistance)',\n",
    "                    ha='center', fontsize=10, style='italic')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('figs/policy_making_xgboost_cm.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # Print interpretation\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            print(f\"\\nConfusion Matrix Interpretation:\")\n",
    "            print(f\"True Negatives (correctly identified as <=50K): {tn}\")\n",
    "            print(f\"False Positives (>50K incorrectly identified as <=50K): {fp}\")\n",
    "            print(f\"False Negatives (<=50K incorrectly identified as >50K): {fn}\")\n",
    "            print(f\"True Positives (correctly identified as >50K): {tp}\")\n",
    "            \n",
    "            # Calculate and print recall for <=50K class\n",
    "            recall_leq_50k = tn / (tn + fn)\n",
    "            print(f\"\\nRecall for <=50K class: {recall_leq_50k:.4f}\")\n",
    "            print(f\"This means we correctly identify {recall_leq_50k:.2%} of people who might need assistance\")\n",
    "            print(f\"We miss {1-recall_leq_50k:.2%} of people who might need assistance\")\n",
    "\n",
    "        xgb_results.append(metrics)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "xgb_results_df = pd.DataFrame(xgb_results)\n",
    "\n",
    "# Show average metrics per dataset\n",
    "print(\"\\n📊 Average XGBoost Performance (≤$50K as positive class):\")\n",
    "print(xgb_results_df.groupby('dataset').mean(numeric_only=True).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f8ddfe",
   "metadata": {},
   "source": [
    "# Simple Visualizations\n",
    "\n",
    "## For XGBoost which is our best model\n",
    "This will include:\n",
    "- confusion matrix\n",
    "- ROC curve\n",
    "- precision-recall curve\n",
    "and some other relevant info like feature importance and threshold analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2bcfc5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcefd20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best XGBoost model based on results\n",
    "best_model = XGBClassifier(\n",
    "    eval_metric='logloss', \n",
    "    random_state=42, \n",
    "    colsample_bytree=1.0, \n",
    "    learning_rate=0.2, \n",
    "    max_depth=10, \n",
    "    n_estimators=200, \n",
    "    subsample=0.8\n",
    ")\n",
    "\n",
    "# dataset split that performed best\n",
    "X_train, X_test, y_train, y_test = df1_OverSampling[0]  #first split\n",
    "\n",
    "# train\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e05bd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Metrics:\n",
      "Accuracy: 0.8501\n",
      "Precision: 0.6629\n",
      "Recall: 0.7605\n",
      "F1 Score: 0.7084\n",
      "ROC AUC: 0.9176\n"
     ]
    }
   ],
   "source": [
    "# perf metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f\"Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1f5f1a",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25846f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"<=50K\", \">50K\"])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix for XGBoost Model', fontsize=15)\n",
    "plt.savefig('figs/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d845e6",
   "metadata": {},
   "source": [
    "- True Negatives (<=50K predicted correctly): 6,527\n",
    "- False Positives (<=50K predicted as >50K): 904\n",
    "- False Negatives (>50K predicted as <=50K): 560\n",
    "- True Positives (>50K predicted correctly): 1,778\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a119426",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95b85e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC Curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=15)\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('figs/roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79730032",
   "metadata": {},
   "source": [
    "Very good value for ROC AUC: 0.9176"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6e1945",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c09423b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAAPdCAYAAADxjUr8AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3XlYlPX+//HXALIviqIooaOiCQouqLkVmBlabulJzRXX0EyxXE9ZuJOpuZTpsQK3XMqjlhu5YUpKmkuauFGkFWWuiCaCzO8Pf8zXiUUwlen0fFzXfeXc6/v+zF3XOS8/874NJpPJJAAAAAAAAACAVbAp7gIAAAAAAAAAAP+H0BYAAAAAAAAArAihLQAAAAAAAABYEUJbAAAAAAAAALAihLYAAAAAAAAAYEUIbQEAAAAAAADAihDaAgAAAAAAAIAVIbQFAAAAAAAAACtCaAsAAAAAAAAAVoTQFgAAAMVi8eLFMhgMCgwMVGZmZp777N27V7a2tipTpox+//33XNtNJpNWr16tLl26yGg0ytnZWU5OTjIajerQoYMWLlyotLS0XMeFh4fLYDDkWjw8PNSoUSPNnTtXWVlZ9/2erUl8fHyeY3DnEhUVVdxl/u0YjUYZDAalpKQUdykAAOBvzK64CwAAAMA/U69evbRkyRJt3bpV06ZN02uvvWaxPTMzUwMGDFB2drZmzJghLy8vi+2//PKLOnbsqMTERBkMBtWuXVv169eXra2tfvrpJ23atEnr1q3TmDFjlJCQoBo1auSqoWnTpvLz85MkZWVl6ccff9RXX32lxMREbdq0SRs2bJDBYHhwg/AXpaSkqHLlygoJCVF8fPw9naNcuXJq1apVntvq1Klz78XdA6PRqB9//FEmk+mhXhf37n48gwAAIDdCWwAAABSbBQsWqFatWpo0aZI6d+6satWqmbe99dZbOnr0qJ566in17t3b4ri0tDSFhITo9OnTeuaZZzR37lxVqVLFYp/09HR9+OGHmjRpks6fP5/n9fv376/w8HCLdfv379cTTzyhTZs2ac2aNerYseP9uVkrVaNGDcXGxhZ3GQAAALgD7REAAABQbKpUqaLx48frxo0bGjhwoHn9iRMnNGnSJDk5OWn+/Pm5jhs1apROnz6tsLAwffbZZ7kCW0lydXXVsGHDdOTIkTy356d+/fr617/+JUn68ssv7+GuAAAAgL+G0BYAAADFavjw4apbt67i4+P14YcfymQyaeDAgcrIyFBUVJSqVq1qsf/58+cVGxsrg8GgOXPmyNbWtsDze3t7q0KFCkWqqWzZspKUZ1/brKwszZ07V8HBwXJ1dZWrq6saNmyo999/X7du3crzfBcuXNDIkSNVrVo1OTo6ytPTU61atdIXX3yR5/4//vijBg0apOrVq8vZ2Vmenp6qWbOmXnzxRZ04cUKSFBUVpcqVK0uSdu7cadGL9s+zh++XzZs369lnn5WXl5ccHBxUpUoVvfLKK7pw4UKufVNTUzVt2jSFhITIx8dH9vb28vb2VseOHbVv3z6LfXP66/7444+SZHEvRqPRvF9Ov9i85Jzjz/ee0784Pj5ecXFxat68uUqWLCmDwaDLly/f073di5x7ycrK0sSJE+Xn5ycnJyf5+/srJibGvN/27dvVvHlzubu7q1SpUurVq1eeNYSGhpp75y5dulTBwcFydnZW2bJl1bt3b/3888951lHU5/fO63z88cdq1KiR3NzcVLJkyUI/g7t27dKQIUMUFBSkUqVKycnJSTVq1NCYMWMsvoMcd36XFy9e1KBBg1S+fHk5ODioVq1a+uijj/Id57Nnz2ro0KGqXr26nJyc5Onpqfr162v8+PG5+lubTCYtX75cTz75pEqVKiVHR0f5+/srKipK169fz/caAAA8DLRHAAAAQLGys7PTwoUL9dhjj2nkyJH65Zdf9OWXX6pOnTp65ZVXcu2/Y8cOZWRkKDg4WNWrV38gNe3fv1+S5O/vb7H+1q1bat++vTZu3Ch3d3e1bNlSJpNJ27dv1+DBg7VlyxZ9+umnsrH5v7kRP//8s5544gl9//33qlixojp06KDff/9dW7duVVxcnGbOnKnhw4eb9z979qzq1aunixcvqlq1anrmmWd069Yt/fjjj1q4cKEaN26sRx99VHXq1FGnTp20evXqXH1pmzVrdt/HZMyYMXrrrbdkb2+vBg0aqHz58jp8+LDeeecdffbZZ0pISFC5cuXM+69bt06jR4/Wo48+qqCgILm7u+vUqVNas2aN1q9fr/Xr1+vpp5+WdDtY7927tz799FNdu3bNoh1GmTJl7kv9H3/8sT744APVr19frVu3VnJysjkALuq9/RWdO3c2B7NVq1bVzp071bdvX0mSm5ubXnjhBTVq1EhhYWHas2ePlixZoh9++EFffvllnoH19OnTNW/ePD3++ONq37699u7dq8WLF2v79u3as2ePHnnkEfO+9/L85pg6dao++OADNW3aVG3atNHZs2cL/QyOHDlShw8fVlBQkFq0aKEbN27owIEDeuutt7R+/Xrt3btXrq6uua55+fJlNW7cWOnp6Xr88cd1/vx5ffnll+rXr5+ys7PVv39/i/137dqldu3a6fLlyzIajWrbtq3++OMPHT9+XFFRUWrfvr25T3N2drZ69Oih5cuXy9XVVfXr11epUqW0f/9+jR8/Xps2bVJ8fLycnJyK9gUDAHC/mAAAAAAr8Oqrr5okmSSZbG1tTfv27ctzv9dee80kydS/f/97vlbv3r1NkkwxMTHmdZmZmabk5GTT8OHDTZJMvr6+pitXrlgcN336dJMkU82aNU2//vqref0vv/xievTRR02STHPnzrU4pk2bNiZJpm7dupkyMjLM63ft2mVydnY22dramg4ePGhe/8Ybb5gkmYYMGZKr7h9//NF0+vRp8+cffvjBJMkUEhJS5DHYsWNHoY9dtWqVSZKpVq1aplOnTpnXZ2dnm+vt0qWLxTHffvut6ejRo7nOtXnzZpO9vb2patWqpuzsbIttlSpVMhX0f1EK2p5zP71797ZYn/NdSzKtWLHivtxbQXJq/OGHHyzW59RQq1Yt07lz58zrt2/fbpJkKl++vKl06dKm9evXm7dduXLFVLNmTZMk0/bt2y3OFxISYpJksrOzM23YsMG8/ubNm6bu3bubJJnat29vccy9PL8513F0dDTFx8fnut/CPIMbN240Xb582WLdjRs3TAMHDjRJMo0fP95iW853KcnUtWtX040bN8zb1qxZY5JkqlixosUxFy5cMHl5eZkkmd5++23TrVu3LLZ/9dVXpt9++838edq0aSZJptDQUFNqaqp5fUZGhqlfv34mSabRo0fne08AADxohLYAAACwCj///LPJYDCYJJn69u2b734REREmSaYxY8bkuX3atGmm3r17WywLFy602OfOIC+vpVu3bqaffvop17krVqxokmSKi4vLte2zzz4zSTL5+fmZ1yUnJ5skmVxdXU0XLlzIdcwrr7ySK4AeNGiQSZJp7dq1+Y5BjvsR2ua3VKpUybxv7dq1TZJMR44cyXWe7OxsU506dUy2tram33//vVDXzgkVv/32W4v1DzK0ffbZZ/M87n7f291C261bt+Y6pm7duiZJph49euTaNnv2bJMk05tvvmmxPidM7datW65jzp8/b3J2djYZDAbTmTNnzOuL+vzeeZ2XXnopz/v9K8/g9evXTXZ2dqZ69epZrM/5Lt3d3U3nz5/PdVytWrVyjfFbb71lkmRq1arVXa+bmZlpKlOmjMnFxcUivL6zLm9vb1OpUqVyhb8AADwstEcAAACAVXjzzTdlMpkkSXFxcbp69arc3NyKfJ64uDht27Yt1/o//5Rakpo2bSo/Pz9Jt/tb/vrrr9q/f79WrVqlUqVKafbs2eaeuWfOnNGZM2fk5eVl/ln/ndq0aaOSJUvq9OnT+vXXX+Xt7a3du3dLklq1aiVPT89cx/Ts2VMzZ87Url27zOuCg4MlSf/+979la2urp556So6OjkUeh8L688/ac+S0JTh37pwOHz6satWqqVatWrn2MxgMatq0qQ4dOqRvvvlGYWFh5m0ZGRnavHmzvv76a/3++++6efOmJOnIkSOSpFOnTikwMPBB3FYu7dq1y7Xur9zbvShRooRCQ0Nzra9SpYoOHjyY53OV8xK91NTUPM/ZtWvXXOtKly6tp59+WmvXrtXu3bv1wgsv3NPze6e8xq8ofv75Z33++ec6fvy40tLSlJ2dLUmyt7fXqVOn8jwmODhYpUuXzrW+evXqOnr0qFJTU809j7du3SpJevHFF+9ay4EDB3T+/Hm1bNkyz7YXTk5OCg4O1oYNG3Tq1Ck9+uijhb1NAADuG0JbAAAAFLsvv/xSH374ocqXL6/HHntMa9eu1WuvvaY5c+bk2jcnxDl//nye58oJbyRpxYoVeuGFF/K9bv/+/XO9uOrq1avq2rWr3nvvPXl6emrChAmSpF9++UWSVKlSpTzPZTAYVKlSJV2+fFk///yzvL29zcfc+TKtO+Wsv/OlUeHh4friiy+0atUqtW3bVo6OjmrQoIFatWqlvn375grT/qoaNWooNjY23+0pKSmSbges+b0ELMed38mRI0fUrl078/F5uXr1alFK/UsqVqyYa9293tu98vb2zvPFeTn9XH18fPLdlpGRkec583sec56tnGfwXp7fO+U1foU1c+ZMjRkzRpmZmUU67s5+vHfK+cucO8fk7NmzkpTrxYV5yfnet2zZUqjvndAWAFAcCG0BAABQrDIyMjRw4ECZTCbNnTtXzZo1086dO/Xee++pZ8+eatCggcX+tWvXliQdPHjwgdTj5uamadOmaePGjZo7d645tC2MuwVAhdnf1tZWK1eu1JgxY7Ru3Tpt375diYmJ2rVrl6Kjo7V582Y1adKkSNf5K3JmRHp7e991pmlOIGgymdS5c2elpKQoIiJCERERqlKlilxdXWUwGPTvf/9bU6dONc+svp915iev2cr3cm9/RV4v+CrK9getoOf3Xmd77927V6+++qo8PDw0e/ZshYaGytvbWw4ODpKkChUq5DuL+EGNR8737ufnp6ZNmxa4b14zfQEAeBgIbQEAAFCsJk2apBMnTqhdu3bq1KmTJGnatGkaMGCABgwYoP3798vO7v/+Z2vz5s3l4OCgAwcO6NSpU6pWrdp9r6ly5cqSbr+9/vfff5eXl5cqVKggSfrxxx/zPS5nW86MybsdkzPjL68ZlnXr1lXdunUVFRWltLQ0RUVF6Z133lFkZKS+/vrre7uxe5Az27FMmTIFzsi90/Hjx3X8+HHVr19f77//fq7t33///T3VYm9vL0lKT083z0DNkTPTsiju5d6szY8//qigoKA810v/9wzey/N7P6xZs0aSNHnyZPXu3dti2x9//KFff/31vlzH19dXx48fV3Jy8l1bbuR873ebZQ4AQHEq3r/KBQAAwD/a0aNH9dZbb8nNzU3vvfeeeX2/fv30+OOP6/Dhw3rnnXcsjilTpozCw8NlMpn08ssv69atW/e9rpxQ0WAwyNnZWdLtn4dXrFhRv//+e549czds2KBLly7Jz8/P/NPyZs2aSZI2b96sy5cv5zpm6dKlkqTHH3+8wHrc3d01depUGQwGHT161Lw+J8TMysoq4h0W3iOPPKIaNWro2LFjOnnyZKGOuXTpkvnYvLZt2bIlz+Pudj/ly5eXpDzryO+cBbmXe7M2q1atyrXu4sWL+uKLL8w9eaV7e34L427fWUHPwieffHLfZls/9dRTkqT//Oc/d923QYMG8vDw0M6dO3Xx4sX7cn0AAO43QlsAAAAUi+zsbA0YMECZmZmaPHmyRahjMBi0YMEC2dvbKyoqKldf1LfeektVq1ZVXFyc2rVrl+fMzZs3b2r//v1Fruvq1asaNWqUJCkkJEQuLi7mbS+//LIk6ZVXXtHvv/9uXv/rr79q5MiRkqRhw4aZ11epUkXPPvusrl69qmHDhln09NyzZ4/ef/992dra6qWXXjKvX7JkiUUwm2PTpk0ymUzy9fU1rytTpoxKlCih5OTkBxJe5xg3bpyys7PVqVMnHTp0KNf2CxcuaOHChebPfn5+srGx0fbt2y1eMnXjxg1FRETkG5TlzAY9ceJEnttDQkIkSVOnTrW43+XLl2v58uVFvi+p6PdmbVauXKm4uDjz56ysLA0fPlzXrl1TmzZtLHrRFvX5LYy7PYPVq1eXJH344YcWz/+xY8c0evToIl2rIP3791eZMmW0adMmzZo1K1cYvHfvXp07d06S5ODgoFGjRunq1avq2LFjnv/9+Pnnn7VkyZL7Vh8AAEVFewQAAAAUi3nz5mnv3r167LHHLELLHP7+/hozZowmTJigwYMHa+PGjeZtHh4e+vLLL9WxY0dt3LhRmzZtUu3atc1h4S+//KIjR47oypUrKlWqlJ555pk8a/jggw8UHx8v6XYf1t9++0379u3TxYsXVaZMGYvZv5I0fPhwbd++XZs2bVK1atX05JNPymQyadu2bbp69ao6dOigwYMHWxyzYMECPf7441q8eLF27typxo0b6/fff1d8fLxu3bqlGTNmqE6dOub9V69erV69eqlq1aoKDAyUk5OTfvjhByUmJsrGxkaTJk0y72tvb69WrVrp888/V+3atVWvXj3Z29uradOm6tOnT1G/knx169ZN3333naZMmaLg4GDVqVNHVatWlclkUnJysr799lu5urpqwIABkqSyZcuqX79+WrhwoWrXrq0nn3xSTk5O2rVrl27duqXw8PA8f5berl077dy5Uy1atFDz5s3l4uKiMmXKKDo6WpL00ksvaf78+fr0008VEBCgoKAgnTp1SkePHtWwYcNyzcp+EPdmbQYOHKjWrVvriSeeUPny5ZWYmKgffvhBFSpU0Lvvvmux7708v3dzt2ewT58+mjFjhj7//HM9+uijatCggS5evKidO3eqQ4cO+vrrrwts2VBYnp6e+uSTT9SuXTsNHz5cc+bMUYMGDfTHH38oKSlJp0+f1sGDB1W2bFlJ0pgxY3T8+HEtWbJE/v7+qlu3ripXrqybN2/qxIkTOnbsmIKCgtSzZ8+/XBsAAPfEBAAAADxkZ8+eNbm5uZns7OxM3377bb773bhxw1S9enWTJNOKFStybc/OzjZ9+umnpn/9618mX19fk6Ojo8nR0dHk6+tratu2ren99983Xb58OddxvXv3NknKtTg5OZkCAgJMr776qik1NTXPmjIzM02zZ8821a1b1+Ts7GxydnY21a9f3/Tee++ZsrKy8jzm/PnzpldffdVUtWpVk729valkyZKmp59+2hQXF5dr3507d5peeuklU506dUylS5c2OTo6mqpUqWLq2rWrad++fbn2/+2330w9e/Y0eXt7m2xtbU2STL179853THPs2LHDJMkUEhJy133vrO355583VahQwVSiRAlT6dKlTUFBQaYhQ4aYdu7cabFvVlaWacaMGaaAgACTo6OjqVy5cqbu3bubUlJSTG+++aZJkikmJsbimMzMTNPrr79uqlq1qqlEiRImSaZKlSpZ7JOUlGRq06aNyc3NzeTi4mJ64oknTNu3bzffz5/vPee73rFjx327t4JUqlTJJMn0ww8/WKzP614KU2N+9xUSEmK+TkxMjKlOnTomR0dHU+nSpU09e/Y0nT17Ns9rFfX5vfM6+bnbM3j27FlTt27dTD4+PiZHR0eTv7+/KTo62pSVlWUer8Lcc2HG6/vvvzdFRESYjEajyd7e3uTp6WkKDg42TZgwwZSWlpZr/3Xr1pmeffZZU9myZU0lSpQwlS1b1hQcHGwaNWqU6Ztvvsn3ngEAeNAMJtN9fGUrAAAAAOCBCw0N1c6dO/XDDz/IaDQWdzkAAOA+o6ctAAAAAAAAAFgRQlsAAAAAAAAAsCKEtgAAAAAAAABgRehpCwAAAAAAAABWhJm2AAAAAAAAAGBF7Iq7AADWLzs7W7/88ovc3NxkMBiKuxwAAAAAAIC/JZPJpKtXr6pChQqyscl/Pi2hLYC7+uWXX+Tr61vcZQAAAAAAAPxPOHv2rB555JF8txPaArgrNzc3Sbf/g+Lu7l7M1QAAAAAAAPw9paWlydfX15y15IfQFsBd5bREcHd3J7QFAAAAAAD4i+7WfpIXkQEAAAAAAACAFSG0BQAAAAAAAAArQmgLAAAAAAAAAFaE0BYAAAAAAAAArAihLQAAAAAAAABYEUJbAAAAAAAAALAihLYAAAAAAAAAYEUIbQEAAAAAAADAihDaAgAAAAAAAIAVIbQFAAAAAAAAACtCaAsAAAAAAAAAVoTQFgAAAAAAAACsCKEtAAAAAAAAAFgRQlsAAAAAAAAAsCKEtgAAAAAAAABgRQhtAQAAAAAAAMCKENoCAAAAAAAAgBUhtAUAAAAAAAAAK0JoCwAAAAAAAABWhNAWAAAAAAAAAKwIoS0AAAAAAAAAWBFCWwAAAAAAAACwIoS2AAAAAAAAAGBFCG0BAAAAAAAAwIoQ2gIAAAAAAACAFSG0BQAAAAAAAAArQmgLAAAAAAAAAFaE0BYAAAAAAAAArAihLQAAAAAAAABYEUJbAAAAAAAAALAihLYAAAAAAAAAYEUIbQEAAAAAAADAihDaAgAAAAAAAIAVIbQFAAAAAAAAACtCaAsAAAAAAAAAVoTQFgAAAAAAAACsCKEtAAAAAAAAAFgRQlsAAAAAAAAAsCJ2xV0AgL+PWm/GycbBubjLyFdK9LPFXQIAAAAAAMBfxkxbAAAAAAAAALAihLYAAAAAAAAAYEUIbQEAAAAAAADAihDaAgAAAAAAAIAVIbQFAAAAAAAAACtCaAsAAAAAAAAAVoTQFgAAAAAAAACsCKEtAAAAAAAAAFgRQlsAAAAAAAAAsCKEtgAAAAAAAABgRQhtAQAAAAAAAMCKENrigQoNDVVkZKTVnKewoqKiVKdOnQL3edg15SWvOqOiolSuXDkZDAatXbu2WOoCAAAAAADAvSO0hVWJj4+XwWDQ5cuXLdb/97//1cSJE4unqHzcz5q6du2qVq1aWazbvHmzDAaDoqKiLNZHRUWpYsWKkqQRI0Zo27Zt5m1JSUkaP368FixYoNTUVLVu3fq+1AcAAAAAAICHh9AW9+zmzZsP7Vqenp5yc3N7aNcrjPtZU/PmzZWQkKCsrCzzuh07dsjX11fx8fEW++7YsUPNmzeXJLm6uqp06dLmbcnJyZKk9u3by9vbWw4ODvelPgAAAAAAADw8hLYotNDQUA0ZMkSRkZEqU6aMwsLCdPToUbVu3Vqurq4qV66cevbsqfPnz+d7jiVLlqh+/fpyc3OTt7e3unXrpnPnzkmSUlJSzGFkqVKlZDAYFB4ebr72na0ILl26pF69eqlUqVJydnZW69atderUKfP22NhYlSxZUnFxcfL395erq6tatWql1NRU8z7x8fFq2LChXFxcVLJkSTVt2lQ//vhjrnqNRqM8PDzUtWtXXb161WI87qzJaDRq4sSJeuGFF+Ti4iIfHx+99957hRrb5s2bKz09Xfv377eob8yYMUpMTNSNGzckSTdu3FBiYqJ5nO5sjxAVFaW2bdtKkmxsbGQwGMzn+uCDD+Tv7y9HR0fVqFFD8+bNK1RdAAAAAAAAePgIbVEkixYtkr29vRISEhQdHa0nn3xSdevW1f79+7V582b99ttv6ty5c77HZ2ZmauLEiTp8+LDWrl2rlJQUczDr6+ur1atXS5JOnDih1NRUzZ49O8/zhIeHa//+/frss8+0Z88emUwmPfPMM8rMzDTvc/36dU2fPl1LlizRl19+qTNnzmjEiBGSpKysLHXo0EEhISH69ttvtWfPHg0cONAi6ExOTtbatWu1fv16rV+/Xjt37lR0dHSB4/P222+rdu3aOnjwoMaMGaNhw4Zpy5Ytdx3X6tWrq0KFCtqxY4ck6erVqzpw4ICef/55GY1G7dmzR5L01VdfKSMjwxza3mnEiBGKiYmRJKWmppoD6mXLlumNN97Q5MmTlZSUpClTpmjcuHFatGhRvvVkZGQoLS3NYgEAAAAAAMDDYVfcBeDvpVq1apo2bZokadKkSapbt66mTJli3v7RRx/J19dXJ0+eVPXq1XMd37dvX/Ofq1Spojlz5qhBgwZKT0+Xq6urPD09JUlly5ZVyZIl86zh1KlT+uyzz5SQkKAmTZpIuh1M+vr6au3atXr++ecl3Q6I58+fr6pVq0qShgwZogkTJkiS0tLSdOXKFbVp08a83d/f3+I62dnZio2NNbdA6Nmzp7Zt26bJkyfnOz5NmzbVmDFjJN0OYhMSEvTOO++oZcuW+R6To3nz5oqPj9fYsWO1a9cuVa9eXV5eXnriiScUHx9v3l65cmVVqlQp1/Gurq7mMfP29javf/PNNzVjxgx17NhRklS5cmUdO3ZMCxYsUO/evfOsZerUqRo/fvxdawYAAAAAAMD9x0xbFElwcLD5z4cPH9aOHTvk6upqXmrUqCHp/3qr/tk333yjtm3bqmLFinJzc1NISIgk6cyZM4WuISkpSXZ2dnrsscfM60qXLq1HH31USUlJ5nXOzs7mQFaSypcvb27F4OnpqfDwcIWFhalt27aaPXu2ResE6Xa7gzt71t55fH4aN26c6/OdNRUkNDRUCQkJyszMVHx8vEJDQyVJISEh5r62OeFtYV27dk3Jycnq16+fxfc0adKkfL8jSRo7dqyuXLliXs6ePVvoawIAAAAAAOCvIbRFkbi4uJj/nJ6errZt2+rQoUMWy6lTp/TEE0/kOvbatWsKCwuTu7u7li1bpn379mnNmjWSHsxLzUqUKGHx2WAwyGQymT/HxMRoz549atKkiVauXKnq1atr7969BR6fnZ193+vM0bx5c127dk379u3Tjh07zIF2SEiIEhMTdfHiRSUmJurJJ58s9DnT09MlSQsXLrT4jo4ePWpxr3/m4OAgd3d3iwUAAAAAAAAPB+0RcM/q1aun1atXy2g0ys7u7o/S8ePHdeHCBUVHR8vX11eSLF68JUn29vaSpFu3buV7Hn9/f2VlZSkxMdHcHuHChQs6ceKEAgICinQPdevWVd26dTV27Fg1btxYH3/8sRo1alSkc9zpz0Ho3r17c7VdyE/VqlXl6+urzz77TIcOHTKHtj4+PvLx8dGMGTN08+bNIs20LVeunCpUqKDvv/9e3bt3L/yNAAAAAAAAoNgw0xb37KWXXtLFixf1wgsvaN++fUpOTlZcXJz69OmTZ+hasWJF2dvba+7cufr+++/12WefaeLEiRb7VKpUSQaDQevXr9fvv/9unil6p2rVqql9+/YaMGCAdu/ercOHD6tHjx7y8fFR+/btC1X7Dz/8oLFjx2rPnj368ccf9cUXX+jUqVOFDljzk5CQoGnTpunkyZN677339Mknn2jYsGGFPr558+aaN2+e/Pz8VK5cOfP6kJAQzZ071/zCsqIYP368pk6dqjlz5ujkyZM6cuSIYmJiNHPmzCKdBwAAAAAAAA8HoS3uWYUKFZSQkKBbt27p6aefVmBgoCIjI1WyZEnZ2OR+tLy8vBQbG6tPPvlEAQEBio6O1vTp0y328fHx0fjx4zVmzBiVK1dOQ4YMyfPaMTExCg4OVps2bdS4cWOZTCZt3LgxV0uD/Dg7O+v48ePq1KmTqlevroEDB+qll17Siy++WPSBuMOrr76q/fv3q27dupo0aZJmzpypsLCwQh/fvHlzXb161dzPNkdISIiuXr1apFm2Ofr3768PPvhAMTExCgwMVEhIiGJjY1W5cuUinwsAAAAAAAAPnsF0Z5NPAPfMaDQqMjJSkZGRxV3KfZeWliYPDw/5Rq6SjYNzcZeTr5ToZ4u7BAAAAAAAgHzlZCxXrlwp8B1CzLQFAAAAAAAAACtCaAs8BMuWLZOrq2ueS82aNYu7PAAAAAAAAFgRu+IuAPhfkZKSku+2du3a6bHHHstzW2H78AIAAAAAAOCfgdAWeAjc3Nzk5uZW3GUAAAAAAADgb4D2CAAAAAAAAABgRQhtAQAAAAAAAMCKENoCAAAAAAAAgBUhtAUAAAAAAAAAK0JoCwAAAAAAAABWxK64CwDw93F0fJjc3d2LuwwAAAAAAID/acy0BQAAAAAAAAArQmgLAAAAAAAAAFaE0BYAAAAAAAAArAihLQAAAAAAAABYEUJbAAAAAAAAALAihLYAAAAAAAAAYEUIbQEAAAAAAADAitgVdwEA/j5qvRknGwfn4i4jXynRzxZ3CQAAAAAAAH8ZM20BAAAAAAAAwIoQ2gIAAAAAAACAFSG0BQAAAAAAAAArQmgLAAAAAAAAAFaE0BYAAAAAAAAArAihLQAAAAAAAABYEUJbAAAAAAAAALAihLYAAAAAAAAAYEUIbQEAAAAAAADAihDaAgAAAAAAAIAVIbQFAAAAAAAAACtCaAsAAAAAAAAAVoTQ9iEzGo2aNWtWcZeBv7HY2FiVLFmyuMsAAAAAAADAA0Jo+4DkF6zt27dPAwcOfPgFFYPQ0FBFRkY+8OukpKTIYDCYl9KlS+vpp5/WwYMHH9q1Dx06dF/OZzQazffh7OyswMBAffDBBxb7dOnSRSdPnrwv1wMAAAAAAID1IbR9yLy8vOTs7FzcZVgNk8mkrKys+3KurVu3KjU1VXFxcUpPT1fr1q11+fLl+3LuvNy8efOBnHfChAlKTU3V0aNH1aNHDw0YMECbNm0yb3dyclLZsmUfyLUBAAAAAABQ/Aht8xEaGqqhQ4dq1KhR8vT0lLe3t6KioszbZ86cqcDAQLm4uMjX11eDBw9Wenq6JCk+Pl59+vTRlStXzLMmc469sz1Ct27d1KVLF4vrZmZmqkyZMlq8eLEkKTs7W1OnTlXlypXl5OSk2rVr69NPP71r/QkJCQoNDZWzs7NKlSqlsLAwXbp0SZKUkZGhoUOHqmzZsnJ0dFSzZs20b98+87F5zRJeu3atDAaD+XNUVJTq1KmjJUuWyGg0ysPDQ127dtXVq1clSeHh4dq5c6dmz55tHoOUlBTFx8fLYDBo06ZNCg4OloODg5YuXSobGxvt37/f4pqzZs1SpUqVlJ2dfdf7laTSpUvL29tb9evX1/Tp0/Xbb78pMTHRfM07A9xDhw6Za8qxe/duPf7443JycpKvr6+GDh2qa9eumbcbjUZNnDhRvXr1kru7uwYOHKjKlStLkurWrSuDwaDQ0FBJt7+3CRMm6JFHHpGDg4Pq1KmjzZs3F+o+3Nzc5O3trSpVqmj06NHy9PTUli1bzNvz+n4+//xzNWjQQI6OjipTpoyee+4587ZLly6pV69eKlWqlJydndW6dWudOnWqwBoyMjKUlpZmsQAAAAAAAODhILQtwKJFi+Ti4qLExERNmzZNEyZMMIdnNjY2mjNnjr777jstWrRI27dv16hRoyRJTZo00axZs+Tu7q7U1FSlpqZqxIgRuc7fvXt3ff755+awV5Li4uJ0/fp1c+g2depULV68WPPnz9d3332n4cOHq0ePHtq5c2e+dR86dEgtWrRQQECA9uzZo927d6tt27a6deuWJGnUqFFavXq1Fi1apAMHDsjPz09hYWG6ePFikcYnOTlZa9eu1fr167V+/Xrt3LlT0dHRkqTZs2ercePGGjBggHkMfH19zceOGTNG0dHRSkpKUrt27fTUU08pJibG4vwxMTEKDw+XjU3RH1MnJydJhZ8Nm5ycrFatWqlTp0769ttvtXLlSu3evVtDhgyx2G/69OmqXbu2Dh48qHHjxunrr7+W9H+zfP/73/+a73/GjBmaPn26vv32W4WFhaldu3Z3DUvvlJ2drdWrV+vSpUuyt7fPd78NGzboueee0zPPPKODBw9q27ZtatiwoXl7eHi49u/fr88++0x79uyRyWTSM888o8zMzHzPOXXqVHl4eJiXO787AAAAAAAAPFgGk8lkKu4irFFoaKhu3bqlXbt2mdc1bNhQTz75pDmYvNOnn36qiIgInT9/XtLt2ZCRkZG5fp5vNBoVGRmpyMhIZWVlqXz58po5c6Z69uwp6fbs2+zsbK1YsUIZGRny9PTU1q1b1bhxY/M5+vfvr+vXr+vjjz/Os/Zu3brpzJkz2r17d65t165dU6lSpRQbG6tu3bpJuj27N6eukSNH5ln72rVr9dxzzynncYmKitLbb7+tX3/9VW5ubpJuh8Fffvml9u7dax7DOnXqWLx4LT4+Xs2bN9fatWvVvn178/pVq1YpIiJCqampcnBw0IEDB1S/fn19//33MhqNed5njpSUFFWuXFkHDx5UnTp1dPnyZfXt21dbtmzR6dOnlZSUpObNm+vSpUvmGaqHDh1S3bp19cMPP8hoNKp///6ytbXVggULzOfdvXu3QkJCdO3aNTk6OspoNKpu3bpas2ZNvtfO4ePjo5deekn//ve/zesaNmyoBg0a6L333sv3XoxGo1JTU1WiRAllZGQoKytLnp6eSkxMlJ+fn6Tcz1aTJk1UpUoVLV26NNf5Tp06perVqyshIUFNmjSRJF24cEG+vr5atGiRnn/++TzryMjIUEZGhvlzWlqafH195Ru5SjYO1tveIyX62eIuAQAAAAAAIF9paWny8PDQlStX5O7unu9+zLQtQFBQkMXn8uXL69y5c5Juz6xs0aKFfHx85Obmpp49e+rChQu6fv16oc9vZ2enzp07a9myZZJuB6rr1q1T9+7dJUmnT5/W9evX1bJlS7m6upqXxYsXKzk5WZJUs2ZN8/rWrVtL+r+ZtnlJTk5WZmammjZtal5XokQJNWzYUElJSYWuXbodMOYEtpLl+NxN/fr1LT536NBBtra25kA0NjZWzZs3v2tge6cmTZrI1dVVpUqV0uHDh7Vy5UqVK1euUMcePnxYsbGxFuMcFham7Oxs/fDDD/nWnZe0tDT98ssvFmMsSU2bNjWP8ZQpUyyudebMGfN+I0eO1KFDh7R9+3Y99thjeuedd8yBbV4K+r6TkpJkZ2enxx57zLyudOnSevTRRwv8vh0cHOTu7m6xAAAAAAAA4OGwK+4CrFmJEiUsPhsMBmVnZyslJUVt2rTRoEGDNHnyZHl6emr37t3q16+fbt68WaQXjXXv3l0hISE6d+6ctmzZIicnJ7Vq1UqSzG0TNmzYIB8fH4vjHBwcJEkbN240/8w9pyVAzj/vlY2Njf48ATuvn9LnNz6F4eLiYvHZ3t5evXr1UkxMjDp27KiPP/5Ys2fPLlLdK1euVEBAgEqXLm3R8zWnvcKd9/Tn+0lPT9eLL76ooUOH5jpvxYoV8637XkVERKhz587mzxUqVDD/uUyZMvLz85Ofn58++eQTBQYGqn79+goICMjzXH/1+wYAAAAAAIB1YabtPfjmm2+UnZ2tGTNmqFGjRqpevbp++eUXi33s7e3NPWQL0qRJE/n6+mrlypVatmyZnn/+eXMYGhAQIAcHB505c8Yc4uUsOT1GK1WqZF6XE+wGBQVp27ZteV6vatWqsre3V0JCgnldZmam9u3bZw4Fvby8dPXqVYuXcB06dKjwA1TEMcjRv39/bd26VfPmzVNWVpY6duxYpOv5+vqqatWquV7S5eXlJUlKTU01r/vz/dSrV0/Hjh3LNc5+fn4F9pPN2Xbnfbq7u6tChQoWYyzdfjlczhh7enpaXMPOLu+/P/H19VWXLl00duzYfGso6Pv29/dXVlaWEhMTzesuXLigEydO5BsCAwAAAAAAoHgx0/Ye+Pn5KTMzU3PnzlXbtm2VkJCg+fPnW+xjNBqVnp6ubdu2qXbt2nJ2ds53Bm63bt00f/58nTx5Ujt27DCvd3Nz04gRIzR8+HBlZ2erWbNmunLlihISEuTu7q7evXvneb6xY8cqMDBQgwcPVkREhOzt7bVjxw49//zzKlOmjAYNGqSRI0fK09NTFStW1LRp03T9+nX169dPkvTYY4/J2dlZ//73vzV06FAlJiYqNja2yONkNBqVmJiolJQUubq6ytPTs8D9/f391ahRI40ePVp9+/a9bzNIc0LuqKgoTZ48WSdPntSMGTMs9hk9erQaNWqkIUOGqH///nJxcdGxY8e0ZcsWvfvuu/meu2zZsnJyctLmzZv1yCOPyNHRUR4eHho5cqTefPNNVa1aVXXq1FFMTIwOHTpkboVRFMOGDVOtWrW0f//+PNszvPnmm2rRooWqVq2qrl27KisrSxs3btTo0aNVrVo1tW/fXgMGDNCCBQvk5uamMWPGyMfHx6KnMAAAAAAAAKwHM23vQe3atTVz5ky99dZbqlWrlpYtW6apU6da7NOkSRNFRESoS5cu8vLy0rRp0/I9X/fu3XXs2DH5+Pjk6oM6ceJEjRs3TlOnTpW/v79atWqlDRs2qHLlyvmer3r16vriiy90+PBhNWzYUI0bN9a6devMszmjo6PVqVMn9ezZU/Xq1dPp06cVFxenUqVKSbo9C3Tp0qXauHGjAgMDtXz5ckVFRRV5nEaMGCFbW1sFBATIy8vLom9rfnJaTPTt27fI18tPiRIltHz5ch0/flxBQUF66623NGnSJIt9goKCtHPnTp08eVKPP/646tatqzfeeMOibUFe7OzsNGfOHC1YsEAVKlQwB6FDhw7VK6+8oldffVWBgYHavHmzPvvsM1WrVq3I9QcEBOjpp5/WG2+8kef20NBQffLJJ/rss89Up04dPfnkk/r666/N22NiYhQcHKw2bdqocePGMplM2rhxY672FgAAAAAAALAOBtOfm5cCxWjixIn65JNP9O233xZ3KbhDzpsNfSNXycah8D2bH7aU6GeLuwQAAAAAAIB85WQsV65cKfDF78y0hVVIT0/X0aNH9e677+rll18u7nIAAAAAAACAYkNoC6swZMgQBQcHKzQ0NFdrhIiICLm6uua5REREFFPFAAAAAAAAwINBewRYvXPnziktLS3Pbe7u7ipbtuxDruifh/YIAAAAAAAAf11h2yPYPcSagHtStmxZglkAAAAAAAD8Y9AeAQAAAAAAAACsCKEtAAAAAAAAAFgRQlsAAAAAAAAAsCKEtgAAAAAAAABgRXgRGYBCOzo+rMA3GwIAAAAAAOCvY6YtAAAAAAAAAFgRQlsAAAAAAAAAsCKEtgAAAAAAAABgRQhtAQAAAAAAAMCKENoCAAAAAAAAgBUhtAUAAAAAAAAAK0JoCwAAAAAAAABWhNAWAAAAAAAAAKyIXXEXAODvo9abcbJxcC7uMgqUEv1scZcAAAAAAADwlzDTFgAAAAAAAACsCKEtAAAAAAAAAFgRQlsAAAAAAAAAsCKEtgAAAAAAAABgRQhtAQAAAAAAAMCKENoCAAAAAAAAgBUhtAUAAAAAAAAAK0JoCwAAAAAAAABWhNAWAAAAAAAAAKwIoS0AAAAAAAAAWBFCWwAAAAAAAACwIoS2/wPi4+NlMBh0+fLl4i4FxcRoNGrWrFmF3j82NlYlS5Z8YPUAAAAAAADg3hHa/s2EhoYqMjLSYl2TJk2UmpoqDw+Ph1aHwWDIc1mxYsVDqwH/Z9++fRo4cGBxlwEAAAAAAID7wK64C8BfZ29vL29v74d+3ZiYGLVq1cpiHbM3H66bN2/K3t5eXl5exV0KAAAAAAAA7pN/1EzbjIwMDR06VGXLlpWjo6OaNWumffv2mbd/9913atOmjdzd3eXm5qbHH39cycnJ5u0fffSRatasKQcHB5UvX15DhgyRJKWkpMhgMOjQoUPmfS9fviyDwaD4+HhJ/9fCYMOGDQoKCpKjo6MaNWqko0ePmo+5cOGCXnjhBfn4+MjZ2VmBgYFavny5eXt4eLh27typ2bNnm2e2pqSk5NkeYfXq1eZajUajZsyYYTEWRqNRU6ZMUd++feXm5qaKFSvqP//5T5HGs2TJkvL29rZYHB0dJUl9+/ZVUFCQMjIyJN0OF+vWratevXqZj1+3bp3q1asnR0dHValSRePHj1dWVpbFGL744osqV66cHB0dVatWLa1fvz7feqKiolSnTh199NFHqlixolxdXTV48GDdunVL06ZNk7e3t8qWLavJkydbHDdz5kwFBgbKxcVFvr6+Gjx4sNLT083bc1oJxMXFyd/fX66urmrVqpVSU1PN++zbt08tW7ZUmTJl5OHhoZCQEB04cMDiOsePH1ezZs3k6OiogIAAbd26VQaDQWvXrjXvc/bsWXXu3FklS5aUp6en2rdvr5SUFPP28PBwdejQQZMnT1aFChX06KOPSsrdHuFu93Q3GRkZSktLs1gAAAAAAADwcPyjQttRo0Zp9erVWrRokQ4cOCA/Pz+FhYXp4sWL+vnnn/XEE0/IwcFB27dv1zfffKO+ffuaQ8T3339fL730kgYOHKgjR47os88+k5+fX5FrGDlypGbMmKF9+/bJy8tLbdu2VWZmpiTpxo0bCg4O1oYNG3T06FENHDhQPXv21Ndffy1Jmj17tho3bqwBAwYoNTVVqamp8vX1zXWNb775Rp07d1bXrl115MgRRUVFady4cYqNjbXYb8aMGapfv74OHjyowYMHa9CgQTpx4kSR7ykvc+bM0bVr1zRmzBhJ0muvvabLly/r3XfflSTt2rVLvXr10rBhw3Ts2DEtWLBAsbGx5kA1OztbrVu3VkJCgpYuXapjx44pOjpatra2BV43OTlZmzZt0ubNm7V8+XJ9+OGHevbZZ/XTTz9p586deuutt/T6668rMTHRfIyNjY3mzJmj7777TosWLdL27ds1atQoi/Nev35d06dP15IlS/Tll1/qzJkzGjFihHn71atX1bt3b+3evVt79+5VtWrV9Mwzz+jq1auSpFu3bqlDhw5ydnZWYmKi/vOf/+i1116zuEZmZqbCwsLk5uamXbt2KSEhwRwQ37x507zftm3bdOLECW3ZsiXfELsw91SQqVOnysPDw7zk9ZwBAAAAAADgwTCYTCZTcRfxMFy7dk2lSpVSbGysunXrJul2SGY0GhUZGalLly5pxYoVOnHihEqUKJHreB8fH/Xp00eTJk3KtS0lJUWVK1fWwYMHVadOHUm3Z4mWKlVKO3bsUGhoqOLj49W8eXOtWLFCXbp0kSRdvHhRjzzyiGJjY9W5c+c8627Tpo1q1Kih6dOnS7rd07ZOnToWsypzzn3p0iWVLFlS3bt31++//64vvvjCvM+oUaO0YcMGfffdd5Juz8x8/PHHtWTJEkmSyWSSt7e3xo8fr4iIiLuOp8FgkKOjY64Q9dixY6pYsaIkac+ePQoJCdGYMWM0depU7dixQ82aNZMkPfXUU2rRooXGjh1rPnbp0qUaNWqUfvnlF33xxRdq3bq1kpKSVL169bvWI92eafv222/r119/lZubmySpVatWOnHihJKTk2Vjc/vvKGrUqKHw8HBzoPxnn376qSIiInT+/HlJt2fa9unTR6dPn1bVqlUlSfPmzdOECRP066+/5nmO7OxslSxZUh9//LHatGmjzZs3q23btjp79qy5lcXWrVvVsmVLrVmzRh06dNDSpUs1adIkJSUlyWAwSLo9Q7lkyZJau3atnn76aYWHh2vz5s06c+aM7O3tzdfLeY7/3O+4oHuKjIzM9+V1GRkZ5lnSkpSWliZfX1/5Rq6SjYNznsdYi5ToZ4u7BAAAAAAAgDylpaXJw8NDV65ckbu7e777/WN62iYnJyszM1NNmzY1rytRooQaNmyopKQk/frrr3r88cfzDGzPnTunX375RS1atPjLdTRu3Nj8Z09PTz366KNKSkqSdHs25pQpU7Rq1Sr9/PPPunnzpjIyMuTsXLSQLCkpSe3bt7dY17RpU82aNUu3bt0yB61BQUHm7QaDQd7e3jp37lyhr/POO+/oqaeeslhXoUIF858bN26sESNGaOLEiRo9erQ5sJWkw4cPKyEhwaJVwa1bt3Tjxg1dv35dhw4d0iOPPJJvYOvq6mr+c48ePTR//nxJt8PLnMBWksqVKydbW1tzYJuz7s773Lp1q6ZOnarjx48rLS1NWVlZ5jpyxt7Z2dkc2EpS+fLlLc7x22+/6fXXX1d8fLzOnTunW7du6fr16zpz5owk6cSJE/L19bXoPdywYUOLezp8+LBOnz5tUb90ewb2nW06AgMDLQLbvBTmngri4OAgBweHu+4HAAAAAACA++8fE9rejZOT0z1tk2QOBO+ctJzT8qAo3n77bc2ePVuzZs0y9yONjIy0+Gn8/fTngNpgMCg7O7vQx3t7exfYIiI7O1sJCQmytbXV6dOnLbalp6dr/Pjx6tixY67jHB0d7zrmd/YPvvNvJfK6p4LuMyUlRW3atNGgQYM0efJkeXp6avfu3erXr59u3rxpDjjzOsed33fv3r114cIFzZ49W5UqVZKDg4MaN25cpO8uPT1dwcHBWrZsWa5td75ozMXFpcDzFPaeAAAAAAAAYJ3+MaFt1apVZW9vr4SEBFWqVEnS7WB13759ioyM1LVr17Ro0SJlZmbmCujc3NxkNBq1bds2NW/ePNe5cwK11NRU1a1bV5JlqHinvXv3mtsHXLp0SSdPnpS/v78kKSEhQe3bt1ePHj0k3Q49T548qYCAAPPx9vb2unXrVoH36u/vr4SEBIt1CQkJql69+l17wt5Pb7/9to4fP66dO3cqLCxMMTEx6tOnjySpXr16OnHiRL6hb1BQkH766SedPHkyz9m299JPOC/ffPONsrOzNWPGDHP4vmrVqiKfJyEhQfPmzdMzzzwj6fYLxXJaEUjSo48+qrNnz+q3335TuXLlJMniJXjS7TFZuXKlypYtW+D0+Lu5X/cEAAAAAACA4vGPeRGZi4uLBg0apJEjR2rz5s06duyYBgwYoOvXr6tfv34aMmSI0tLS1LVrV+3fv1+nTp3SkiVLzC/mioqK0owZMzRnzhydOnVKBw4c0Ny5cyXdnonbqFEjRUdHKykpSTt37tTrr7+eZx0TJkzQtm3bdPToUYWHh6tMmTLq0KGDJKlatWrasmWLvvrqKyUlJenFF1/Ub7/9ZnG80WhUYmKiUlJSdP78+Txnxr766qvatm2bJk6cqJMnT2rRokV69913LV6cdT9cvnxZv/76q8Vy7do1SdLBgwf1xhtv6IMPPlDTpk01c+ZMDRs2TN9//70k6Y033tDixYs1fvx4fffdd0pKStKKFSvM4xYSEqInnnhCnTp10pYtW/TDDz+YXzB2P/n5+SkzM1Nz587V999/ryVLlphbLRRFtWrVtGTJEiUlJSkxMVHdu3e3mC3csmVLVa1aVb1799a3336rhIQE873m9K/t3r27ypQpo/bt22vXrl364YcfFB8fr6FDh+qnn3566PcEAAAAAACA4vGPCW0lKTo6Wp06dVLPnj1Vr149nT59WnFxcSpVqpRKly6t7du3Kz09XSEhIQoODtbChQvNs2579+6tWbNmad68eapZs6batGmjU6dOmc/90UcfKSsrS8HBwYqMjMzzhWU5NQwbNkzBwcH69ddf9fnnn5v7k77++uuqV6+ewsLCFBoaKm9vb3Ogm2PEiBGytbVVQECAvLy8zD1T71SvXj2tWrVKK1asUK1atfTGG29owoQJCg8Pvz8D+f/16dNH5cuXt1jmzp2rGzduqEePHgoPD1fbtm0lSQMHDlTz5s3Vs2dP3bp1S2FhYVq/fr2++OILNWjQQI0aNdI777xjngUtSatXr1aDBg30wgsvKCAgQKNGjbrrLOOiql27tmbOnKm33npLtWrV0rJlyzR16tQin+fDDz/UpUuXVK9ePfXs2VNDhw5V2bJlzdttbW21du1apaenq0GDBurfv79ee+01SbfbQUi3++Z++eWXqlixojp27Ch/f3/169dPN27cKNLM2/t1TwAAAAAAACgeBtOdjTnxwMTHx6t58+a6dOmSSpYsWdzlwAokJCSoWbNmOn36tMVLzqxRzpsNfSNXycbBunvipkQ/W9wlAAAAAAAA5CknY7ly5UqBk/T+MT1tgeK2Zs0aubq6qlq1ajp9+rSGDRumpk2bWn1gCwAAAAAAgIfrH9UeAYUzZcoUubq65rm0bt26uMv727p69apeeukl1ahRQ+Hh4WrQoIHWrVtX3GUBAAAAAADAytAeAblcvHhRFy9ezHObk5OTfHx8HnJFKG60RwAAAAAAAPjraI+Ae+bp6SlPT8/iLgMAAAAAAAD4R6I9AgAAAAAAAABYEUJbAAAAAAAAALAihLYAAAAAAAAAYEUIbQEAAAAAAADAihDaAgAAAAAAAIAVsSvuAgD8fRwdHyZ3d/fiLgMAAAAAAOB/GjNtAQAAAAAAAMCKENoCAAAAAAAAgBUhtAUAAAAAAAAAK0JoCwAAAAAAAABWhNAWAAAAAAAAAKwIoS0AAAAAAAAAWBFCWwAAAAAAAACwInbFXQCAv49ab8bJxsG5uMsoUEr0s8VdAgAAAAAAwF/CTFsAAAAAAAAAsCKEtgAAAAAAAABgRQhtAQAAAAAAAMCKENoCAAAAAAAAgBUhtAUAAAAAAAAAK0JoCwAAAAAAAABWhNAWAAAAAAAAAKwIoS0AAAAAAAAAWBFCWwAAAAAAAACwIoS2AAAAAAAAAGBFCG0BAAAAAAAAwIpYRWhrNBo1a9as4i4D91lUVJTq1KlTpGN4FnIzGAxau3ZtvttTUlJkMBh06NAhSVJ8fLwMBoMuX778UOoDAAAAAADA/fVQQ9vY2FiVLFky1/p9+/Zp4MCBD7OUYhMaGqrIyMgHfp2cIC9ncXNzU82aNfXSSy/p1KlTD/z6kjRixAht27atSMdYy7Nw59i5u7urQYMGWrduXXGXVShNmjRRamqqPDw8irsUAAAAAAAA3AOrmGnr5eUlZ2fn4i7DaphMJmVlZd2Xc23dulWpqak6fPiwpkyZoqSkJNWuXbvIYeq9cHV1VenSpYt0jDU9CzExMUpNTdX+/fvVtGlT/etf/9KRI0eKu6y7sre3l7e3twwGQ3GXAgAAAAAAgHtQpNA2NDRUQ4cO1ahRo+Tp6Slvb29FRUWZt8+cOVOBgYFycXGRr6+vBg8erPT0dEm3f7Ldp08fXblyxTyDMefYO38S361bN3Xp0sXiupmZmSpTpowWL14sScrOztbUqVNVuXJlOTk5qXbt2vr000/vWn9CQoJCQ0Pl7OysUqVKKSwsTJcuXZIkZWRkaOjQoSpbtqwcHR3VrFkz7du3z3xsXrOE165daxGM5bQDWLJkiYxGozw8PNS1a1ddvXpVkhQeHq6dO3dq9uzZ5jFISUkx/5x906ZNCg4OloODg5YuXSobGxvt37/f4pqzZs1SpUqVlJ2dfdf7laTSpUvL29tbVapUUfv27bV161Y99thj6tevn27dumXe7/3331fVqlVlb2+vRx99VEuWLLE4j8Fg0IIFC9SmTRs5OzvL399fe/bs0enTpxUaGioXFxc1adJEycnJucYjR3h4uDp06KDp06erfPnyKl26tF566SVlZmaa9/lze4TLly/rxRdfVLly5eTo6KhatWpp/fr1kqQLFy7ohRdekI+Pj5ydnRUYGKjly5db1H23Z7YgJUuWlLe3t6pXr66JEycqKytLO3bsMG8/e/asOnfurJIlS8rT01Pt27dXSkpKrvsdP368vLy85O7uroiICN28eTPf+5WkOnXq5KoxNTVVrVu3lpOTk6pUqVLg855Xe4SCnv28ZGRkKC0tzWIBAAAAAADAw1HkmbaLFi2Si4uLEhMTNW3aNE2YMEFbtmy5fTIbG82ZM0ffffedFi1apO3bt2vUqFGSbv9ke9asWXJ3d1dqaqpSU1M1YsSIXOfv3r27Pv/8c3PYK0lxcXG6fv26nnvuOUnS1KlTtXjxYs2fP1/fffedhg8frh49emjnzp351n3o0CG1aNFCAQEB2rNnj3bv3q22bduag8tRo0Zp9erVWrRokQ4cOCA/Pz+FhYXp4sWLRRqf5ORkrV27VuvXr9f69eu1c+dORUdHS5Jmz56txo0ba8CAAeYx8PX1NR87ZswYRUdHKykpSe3atdNTTz2lmJgYi/PHxMQoPDxcNjb3NknaxsZGw4YN048//qhvvvlGkrRmzRoNGzZMr776qo4ePaoXX3xRffr0sQgoJWnixInq1auXDh06pBo1aqhbt2568cUXNXbsWO3fv18mk0lDhgwp8Po7duxQcnKyduzYoUWLFik2NlaxsbF57pudna3WrVsrISFBS5cu1bFjxxQdHS1bW1tJ0o0bNxQcHKwNGzbo6NGjGjhwoHr27Kmvv/7a4jwFPbOFkZWVpQ8//FDS7Vms0u2/SAgLC5Obm5t27dqlhIQEubq6qlWrVhah7LZt25SUlKT4+HgtX75c//3vfzV+/PhCXzvHuHHj1KlTJx0+fFjdu3dX165dlZSUVKhj7/bs52Xq1Kny8PAwL3c+pwAAAAAAAHiw7Ip6QFBQkN58801JUrVq1fTuu+9q27ZtatmypUWvVqPRqEmTJikiIkLz5s2Tvb29PDw8ZDAY5O3tne/5w8LC5OLiojVr1qhnz56SpI8//ljt2rWTm5ubMjIyNGXKFG3dulWNGzeWJFWpUkW7d+/WggULFBISkud5p02bpvr162vevHnmdTVr1pQkXbt2Te+//75iY2PVunVrSdLChQu1ZcsWffjhhxo5cmShxyc7O1uxsbFyc3OTJPXs2VPbtm3T5MmT5eHhIXt7ezk7O+c5BhMmTFDLli3Nn/v376+IiAjNnDlTDg4OOnDggI4cOfKXe6vWqFFD0u2+tw0bNtT06dMVHh6uwYMHS5JeeeUV7d27V9OnT1fz5s3Nx/Xp00edO3eWJI0ePVqNGzfWuHHjFBYWJkkaNmyY+vTpU+C1S5UqpXfffVe2traqUaOGnn32WW3btk0DBgzIte/WrVv19ddfKykpSdWrV5d0+7vO4ePjYxH8v/zyy4qLi9OqVavUsGFD8/qCntmCvPDCC7K1tdUff/yh7OxsGY1G8/2vXLlS2dnZ+uCDD8yzrWNiYlSyZEnFx8fr6aeflnQ75P3oo4/k7OysmjVrasKECRo5cqQmTpxYpOD9+eefV//+/SXdDs+3bNmiuXPnWjzP+Sno2c/P2LFj9corr5g/p6WlEdwCAAAAAAA8JEWerhkUFGTxuXz58jp37pyk2yFbixYt5OPjIzc3N/Xs2VMXLlzQ9evXC31+Ozs7de7cWcuWLZN0O1Bdt26dunfvLkk6ffq0rl+/rpYtW8rV1dW8LF682PzT/Jo1a5rX54SwObMN85KcnKzMzEw1bdrUvK5EiRJq2LBhoWcz5jAajebAVrIcn7upX7++xecOHTrI1tZWa9askXS7RUPz5s1lNBqLVNOfmUwmSTKHjUlJSRb3LklNmzbNde93fvflypWTJAUGBlqsu3HjRoE/pa9Zs6Z5pqxU8PgcOnRIjzzyiDmw/bNbt25p4sSJCgwMlKenp1xdXRUXF6czZ87kW/efrxkREWHxHN3pnXfe0aFDh7Rp0yYFBATogw8+kKenpyTp8OHDOn36tNzc3MzHenp66saNGxYtImrXrm3Ro7dx48ZKT0/X2bNn8x2jvOT8BcWdn4s607YoHBwc5O7ubrEAAAAAAADg4SjyTNsSJUpYfDYYDMrOzlZKSoratGmjQYMGafLkyfL09NTu3bvVr18/3bx5s0gvl+revbtCQkJ07tw5bdmyRU5OTmrVqpUkmdsmbNiwQT4+PhbHOTg4SJI2btxo7pPq5ORk8c97ZWNjYw47c9zZizVHfuNTGC4uLhaf7e3t1atXL8XExKhjx476+OOPNXv27CJWnltO2Fe5cuUiHXfnveUEvnmtK+h+izI+d/vO3n77bc2ePVuzZs0y91KOjIy0aE9wt2tOmDAhzzYdkuTt7S0/Pz/5+fkpJiZGzzzzjI4dO6ayZcsqPT1dwcHB5r9cuJOXl1eBdd+psM/VX/FXn30AAAAAAAA8XPfWGDUP33zzjbKzszVjxgw1atRI1atX1y+//GKxj729fYF9NHM0adJEvr6+WrlypZYtW6bnn3/eHLwFBATIwcFBZ86cMQdqOUvOz7crVapkXpcT7AYFBWnbtm15Xi/nBVwJCQnmdZmZmdq3b58CAgIk3Q7irl69qmvXrpn3OXToUOEHqIhjkKN///7aunWr5s2bp6ysLHXs2LHI17xTdna25syZo8qVK6tu3bqSJH9/f4t7l26/uCrn3otLUFCQfvrpJ508eTLP7QkJCWrfvr169Oih2rVrq0qVKvnum5+yZctaPEP5adiwoYKDgzV58mRJUr169XTq1Klcx/v5+cnDw8N83OHDh/XHH3+YP+/du1eurq7mZ9XLy0upqanm7Wlpafrhhx9yXX/v3r25Pvv7+xfqHgt69gEAAAAAAGB97lto6+fnp8zMTM2dO1fff/+9lixZovnz51vsYzQalZ6erm3btun8+fMFtk3o1q2b5s+fry1btphbI0iSm5ubRowYoeHDh2vRokVKTk7WgQMHNHfuXC1atCjf840dO1b79u3T4MGD9e233+r48eN6//33df78ebm4uGjQoEEaOXKkNm/erGPHjmnAgAG6fv26+vXrJ0l67LHH5OzsrH//+99KTk7Wxx9/nO8LtApiNBqVmJiolJQUnT9//q6zcP39/dWoUSONHj1aL7zwQpFnTV64cEG//vqrvv/+e3322Wd66qmn9PXXX+vDDz80tykYOXKkYmNj9f777+vUqVOaOXOm/vvf/+Y7A/VhCQkJ0RNPPKFOnTppy5Yt+uGHH7Rp0yZt3rxZ0u3+tFu2bNFXX32lpKQkvfjii/rtt98eWD2RkZFasGCBfv75Z3Xv3l1lypRR+/bttWvXLv3www+Kj4/X0KFD9dNPP5mPuXnzpvr166djx45p48aNevPNNzVkyBBzP9snn3xSS5Ys0a5du3TkyBH17t3bon1Ejk8++UQfffSRTp48qTfffFNff/31XV/6lqOgZx8AAAAAAADW576FtrVr19bMmTP11ltvqVatWlq2bJmmTp1qsU+TJk0UERGhLl26yMvLS9OmTcv3fN27d9exY8fk4+OTq9/qxIkTNW7cOE2dOlX+/v5q1aqVNmzYUODP/atXr64vvvhChw8fVsOGDdW4cWOtW7dOdna3O0RER0erU6dO6tmzp+rVq6fTp08rLi5OpUqVkiR5enpq6dKl2rhxowIDA7V8+XJFRUUVeZxGjBghW1tbBQQEyMvLK1f/1bzktJjo27dvka/31FNPqXz58goMDNSYMWPk7++vb7/91uIFYx06dNDs2bM1ffp01axZUwsWLFBMTIxCQ0OLfL37bfXq1WrQoIFeeOEFBQQEaNSoUeaZyq+//rrq1aunsLAwhYaGytvbWx06dHhgtbRq1UqVK1fW5MmT5ezsrC+//FIVK1ZUx44d5e/vr379+unGjRsW/V9btGihatWq6YknnlCXLl3Url07i+dm7NixCgkJUZs2bfTss8+qQ4cOqlq1aq5rjx8/XitWrFBQUJAWL16s5cuXF3om9N2efQAAAAAAAFgXg+nPDTVhdSZOnKhPPvlE3377bXGXgiIIDw/X5cuXtXbt2uIu5S9LS0uTh4eHfCNXycah8P2pi0NK9LPFXQIAAAAAAECecjKWK1euFPji9/s20xb3X3p6uo4ePap3331XL7/8cnGXAwAAAAAAAOAhILS1YkOGDFFwcLBCQ0NztUaIiIiQq6trnktEREQxVQwAAAAAAADgr6I9wt/UuXPnlJaWluc2d3d3lS1b9iFXhP9ltEcAAAAAAAD46wrbHoE3Ef1NlS1blmAWAAAAAAAA+B9EewQAAAAAAAAAsCKEtgAAAAAAAABgRQhtAQAAAAAAAMCKENoCAAAAAAAAgBUhtAUAAAAAAAAAK2JX3AUA+Ps4Oj5M7u7uxV0GAAAAAADA/zRm2gIAAAAAAACAFSG0BQAAAAAAAAArQmgLAAAAAAAAAFaE0BYAAAAAAAAArAihLQAAAAAAAABYEUJbAAAAAAAAALAihLYAAAAAAAAAYEXsirsAAH8ftd6Mk42Dc3GXcVcp0c8WdwkAAAAAAAD3jJm2AAAAAAAAAGBFCG0BAAAAAAAAwIoQ2gIAAAAAAACAFSG0BQAAAAAAAAArQmgLAAAAAAAAAFaE0BYAAAAAAAAArAihLQAAAAAAAABYEUJbAAAAAAAAALAihLYAAAAAAAAAYEUIbQEAAAAAAADAihDaAgAAAAAAAIAVIbS1UvHx8TIYDLp8+XJxl/LAGI1GzZo1K9/tKSkpMhgMOnTo0EOr6X4LDw9Xhw4dirsMAAAAAAAA/I0Q2lqB0NBQRUZGWqxr0qSJUlNT5eHh8dDqMBgMMhgM2rt3r8X6jIwMlS5dWgaDQfHx8Q+tHl9fX6WmpqpWrVoP7Zr32+zZsxUbG1vcZZjFxsaqZMmSxV0GAAAAAAAACkBoa6Xs7e3l7e0tg8HwUK/r6+urmJgYi3Vr1qyRq6vrQ61DkmxtbeXt7S07O7uHfu37xcPDg5AUAAAAAAAARfK3D20zMjI0dOhQlS1bVo6OjmrWrJn27dtn3v7dd9+pTZs2cnd3l5ubmx5//HElJyebt3/00UeqWbOmHBwcVL58eQ0ZMkRS3j/Nv3z5ssVs05wWBhs2bFBQUJAcHR3VqFEjHT161HzMhQsX9MILL8jHx0fOzs4KDAzU8uXLzdvDw8O1c+dOzZ492zzTNSUlJc/2CKtXrzbXajQaNWPGDIuxMBqNmjJlivr27Ss3NzdVrFhR//nPf4o0nr1799aKFSv0xx9/WIxR7969c+07evRoVa9eXc7OzqpSpYrGjRunzMxMi30+//xzNWjQQI6OjipTpoyee+45i+3Xr1/Pt94/fwc5Y7Jt2zbVr19fzs7OatKkiU6cOGFxznXr1qlevXpydHRUlSpVNH78eGVlZRV435cuXVKvXr1UqlQpOTs7q3Xr1jp16pR5e84M1bVr16patWpydHRUWFiYzp49W+B5/9weITQ0VEOHDtWoUaPk6ekpb29vRUVFmbebTCZFRUWpYsWKcnBwUIUKFTR06FDzdqPRqIkTJ+qFF16Qi4uLfHx89N5771lc8/Lly3rxxRdVrlw5OTo6qlatWlq/fr3i4+PVp08fXblyxfys3XltAAAAAAAAWIe/fWg7atQorV69WosWLdKBAwfk5+ensLAwXbx4UT///LOeeOIJOTg4aPv27frmm2/Ut29fc4D3/vvv66WXXtLAgQN15MgRffbZZ/Lz8ytyDSNHjtSMGTO0b98+eXl5qW3btubw8saNGwoODtaGDRt09OhRDRw4UD179tTXX38t6fbP5xs3bqwBAwYoNTVVqamp8vX1zXWNb775Rp07d1bXrl115MgRRUVFady4cbl+ej9jxgzVr19fBw8e1ODBgzVo0KBcoWZBgoODZTQatXr1aknSmTNn9OWXX6pnz5659nVzc1NsbKyOHTum2bNna+HChXrnnXfM2zds2KDnnntOzzzzjA4ePKht27apYcOGf7ne1157TTNmzND+/ftlZ2envn37mrft2rVLvXr10rBhw3Ts2DEtWLBAsbGxmjx5coHnDA8P1/79+/XZZ59pz549MplMeuaZZyxC6OvXr2vy5MlavHixEhISdPnyZXXt2rXA8+Zl0aJFcnFxUWJioqZNm6YJEyZoy5Ytkm4H8++8844WLFigU6dOae3atQoMDLQ4/u2331bt2rV18OBBjRkzRsOGDTMfn52drdatWyshIUFLly7VsWPHFB0dLVtbWzVp0kSzZs2Su7u7+VkbMWJEnjVmZGQoLS3NYgEAAAAAAMDDYTCZTKbiLuJeXbt2TaVKlVJsbKy6desmScrMzJTRaFRkZKQuXbqkFStW6MSJEypRokSu4318fNSnTx9NmjQp17aUlBRVrlxZBw8eVJ06dSTdnsFYqlQp7dixQ6GhoYqPj1fz5s21YsUKdenSRZJ08eJFPfLII4qNjVXnzp3zrLtNmzaqUaOGpk+fLun27Ms6depYvJQr59yXLl1SyZIl1b17d/3+++/64osvzPuMGjVKGzZs0HfffSfp9izMxx9/XEuWLJF0e9amt7e3xo8fr4iIiLuOp8Fg0Jo1a/Tjjz9q3bp12r59uyZMmKBDhw7po48+srj3vEyfPl0rVqzQ/v37Jd3uy1ulShUtXbo0z/3vVu+fv4OcMdm6datatGghSdq4caOeffZZ/fHHH3J0dNRTTz2lFi1aaOzYsebrLF26VKNGjdIvv/ySZx2nTp1S9erVlZCQoCZNmki6PUPa19dXixYt0vPPP6/Y2Fj16dNHe/fu1WOPPSZJOn78uPz9/ZWYmJgrjM4RHh6uy5cva+3atZJuf9e3bt3Srl27zPs0bNhQTz75pKKjozVz5kwtWLBAR48ezfOZNRqN8vf316ZNm8zrunbtqrS0NG3cuFFffPGFWrduraSkJFWvXj3X8bGxsYqMjLzrC+6ioqI0fvz4XOt9I1fJxsG5wGOtQUr0s8VdAgAAAAAAQC5paWny8PDQlStX5O7unu9+f+uZtsnJycrMzFTTpk3N60qUKKGGDRsqKSlJhw4d0uOPP55n+HXu3Dn98ssv5vDvr2jcuLH5z56ennr00UeVlJQkSbp165YmTpyowMBAeXp6ytXVVXFxcTpz5kyRrpGUlGRxn5LUtGlTnTp1Srdu3TKvCwoKMv/ZYDDI29tb586dK9K1evTooT179uj7779XbGysxUzWO61cuVJNmzaVt7e3XF1d9frrr1vc16FDh+46vvdS753HlC9fXpLMxxw+fFgTJkyQq6urecmZxXz9+nVFRERYbJNuj62dnZ05jJWk0qVLW3yPkmRnZ6cGDRqYP9eoUUMlS5ZUUlKSzpw5Y3HeKVOmFKr+nHvIqf/555/XH3/8oSpVqmjAgAFas2ZNrtYOdz5vOZ9z6jx06JAeeeSRPAPbohg7dqyuXLliXu7WBgIAAAAAAAD3z9/3DU+F4OTkdE/bJMnG5naefedE5D/3ay2Mt99+W7Nnz9asWbMUGBgoFxcXRUZG6ubNm0U+V2H8OaA2GAzKzs4u0jlKly6tNm3aqF+/frpx44Zat26tq1evWuyzZ88ede/eXePHj1dYWJg8PDy0YsUKiz67dxvje633zmNyXtSWc0x6errGjx+vjh075jrO0dFREyZMyLclwF9RoUIFi/7Hnp6e+e5b0D37+vrqxIkT2rp1q7Zs2aLBgwfr7bff1s6dO/P8y4c/K8yYF4aDg4McHBzuy7kAAAAAAABQNH/rmbZVq1aVvb29EhISzOsyMzO1b98+BQQEKCgoSLt27cozbHVzc5PRaNS2bdvyPLeXl5ckKTU11bzuzlDuTnv37jX/+dKlSzp58qT8/f0lSQkJCWrfvr169Oih2rVrq0qVKjp58qTF8fb29hazZfPi7+9vcZ85565evbpsbW0LPPZe9O3bV/Hx8erVq1ee5//qq69UqVIlvfbaa6pfv76qVaumH3/80WKfoKCgfMf3QalXr55OnDghPz+/XIuNjY3Kli1rsU66PbZZWVlKTEw0n+fChQs6ceKEAgICzOuysrLMrR8k6cSJE7p8+bL8/f1lZ2dncd6CQtu7cXJyUtu2bTVnzhzFx8drz549OnLkiHn7nc9bzuec5y0oKEg//fRTrmcsR2GeNQAAAAAAABSvv/VMWxcXFw0aNEgjR46Up6enKlasqGnTpun69evq16+fsrOzNXfuXHXt2lVjx46Vh4eH9u7dq4YNG+rRRx9VVFSUIiIiVLZsWfNs0oSEBL388stycnJSo0aNFB0drcqVK+vcuXN6/fXX86xjwoQJKl26tMqVK6fXXntNZcqUUYcOHSRJ1apV06effqqvvvpKpUqV0syZM/Xbb79ZhIFGo1GJiYlKSUmRq6trnoHfq6++qgYNGmjixInq0qWL9uzZo3fffVfz5s17IGPbqlUr/f777/n21qhWrZrOnDmjFStWqEGDBtqwYYPWrFljsc+bb76pFi1aqGrVquratauysrK0ceNGjR49+oHULElvvPGG2rRpo4oVK+pf//qXbGxsdPjwYR09ejTP3sU599K+fXsNGDBACxYskJubm8aMGSMfHx+1b9/evF+JEiX08ssva86cObKzs9OQIUPUqFGjfPvZ3ovY2FjdunVLjz32mJydnbV06VI5OTmpUqVK5n0SEhI0bdo0dejQQVu2bNEnn3yiDRs2SJJCQkL0xBNPqFOnTpo5c6b8/Px0/PhxGQwGtWrVSkajUenp6dq2bZtq164tZ2dnOTtbf49aAAAAAACAf5K/9UxbSYqOjlanTp3Us2dP1atXT6dPn1ZcXJxKlSql0qVLa/v27UpPT1dISIiCg4O1cOFC88/Me/furVmzZmnevHmqWbOm2rRpo1OnTpnP/dFHHykrK0vBwcGKjIzMN/SLjo7WsGHDFBwcrF9//VWff/657O3tJUmvv/666tWrp7CwMIWGhsrb29sc6OYYMWKEbG1tFRAQIC8vrzz73darV0+rVq3SihUrVKtWLb3xxhuaMGGCwsPD789A/onBYFCZMmXM9/Fn7dq10/DhwzVkyBDVqVNHX331lcaNG2exT2hoqD755BN99tlnqlOnjp588kl9/fXXD6TeHGFhYVq/fr2++OILNWjQQI0aNdI777xjEXrmJSYmRsHBwWrTpo0aN24sk8mkjRs3WrQkcHZ21ujRo9WtWzc1bdpUrq6uWrly5X2tv2TJklq4cKGaNm2qoKAgbd26VZ9//rlKly5t3ufVV1/V/v37VbduXU2aNEkzZ85UWFiYefvq1avVoEEDvfDCCwoICNCoUaPMs2ubNGmiiIgIdenSRV5eXpo2bdp9rR8AAAAAAAB/ncF0Z9NWFEl8fLyaN2+uS5cuqWTJksVdDh6g2NhYRUZG6vLly8Vah9FoVGRkpCIjIx/qdXPebOgbuUo2DtY/Mzcl+tniLgEAAAAAACCXnIzlypUr+f7CXfofmGkLAAAAAAAAAP9LCG3/IaZMmSJXV9c8l9atWxd3eQAAAAAAAAD+P9oj/ENcvHhRFy9ezHObk5OTfHx8HnJF+DuhPQIAAAAAAMBfV9j2CHYPsSYUI09PT3l6ehZ3GQAAAAAAAADugvYIAAAAAAAAAGBFCG0BAAAAAAAAwIoQ2gIAAAAAAACAFSG0BQAAAAAAAAArQmgLAAAAAAAAAFbErrgLAPD3cXR8mNzd3Yu7DAAAAAAAgP9pzLQFAAAAAAAAACtCaAsAAAAAAAAAVoTQFgAAAAAAAACsCKEtAAAAAAAAAFgRQlsAAAAAAAAAsCKEtgAAAAAAAABgRQhtAQAAAAAAAMCK2BV3AQD+Pmq9GScbB+fiLuOuUqKfLe4SAAAAAAAA7hkzbQEAAAAAAADAihDaAgAAAAAAAIAVIbQFAAAAAAAAACtCaAsAAAAAAAAAVoTQFgAAAAAAAACsCKEtAAAAAAAAAFgRQlsAAAAAAAAAsCKEtgAAAAAAAABgRQhtAQAAAAAAAMCKENoCAAAAAAAAgBUhtAUAAAAAAAAAK0JoCwAAAAAAAABWhNAWFoxGo2bNmlXcZfwjRUVFqU6dOgXuExoaqsjIyIdSDwAAAAAAAIoHoe0/VGxsrEqWLJlr/b59+zRw4MCHX1AxeNgB6OrVqxUaGioPDw+5uroqKChIEyZM0MWLFwt9jv/+97+aOHHiA6wSAAAAAAAAxY3QFha8vLzk7Oxc3GVYDZPJpKysrL98ntdee01dunRRgwYNtGnTJh09elQzZszQ4cOHtWTJkkKfx9PTU25ubn+5HgAAAAAAAFgvQtu/qdDQUA0dOlSjRo2Sp6envL29FRUVZd4+c+ZMBQYGysXFRb6+vho8eLDS09MlSfHx8erTp4+uXLkig8Egg8FgPvbO9gjdunVTly5dLK6bmZmpMmXKaPHixZKk7OxsTZ06VZUrV5aTk5Nq166tTz/99K71JyQkKDQ0VM7OzipVqpTCwsJ06dIlSVJGRoaGDh2qsmXLytHRUc2aNdO+ffvMx+Y1S3jt2rUyGAzmzzmtBpYsWSKj0SgPDw917dpVV69elSSFh4dr586dmj17tnkMUlJSFB8fL4PBoE2bNik4OFgODg5aunSpbGxstH//fotrzpo1S5UqVVJ2dnaB9/r1119rypQpmjFjht5++201adJERqNRLVu21OrVq9W7d2+L/fOrWco9O9hoNGrKlCnq27ev3NzcVLFiRf3nP/+xON/o0aNVvXp1OTs7q0qVKho3bpwyMzMLrDkjI0NpaWkWCwAAAAAAAB4OQtu/sUWLFsnFxUWJiYmaNm2aJkyYoC1btkiSbGxsNGfOHH333XdatGiRtm/frlGjRkmSmjRpolmzZsnd3V2pqalKTU3ViBEjcp2/e/fu+vzzz81hryTFxcXp+vXreu655yRJU6dO1eLFizV//nx99913Gj58uHr06KGdO3fmW/ehQ4fUokULBQQEaM+ePdq9e7fatm2rW7duSZJGjRql1atXa9GiRTpw4ID8/PwUFhZWpDYCkpScnKy1a9dq/fr1Wr9+vXbu3Kno6GhJ0uzZs9W4cWMNGDDAPAa+vr7mY8eMGaPo6GglJSWpXbt2euqppxQTE2Nx/piYGIWHh8vGpuB/jZYtWyZXV1cNHjw4z+13BtAF1ZyfGTNmqH79+jp48KAGDx6sQYMG6cSJE+btbm5uio2N1bFjxzR79mwtXLhQ77zzToHnnDp1qjw8PMzLnWMDAAAAAACAB4vQ9m8sKChIb775pqpVq6ZevXqpfv362rZtmyQpMjJSzZs3l9Fo1JNPPqlJkyZp1apVkiR7e3t5eHjIYDDI29tb3t7ecnV1zXX+sLAwubi4aM2aNeZ1H3/8sdq1ayc3NzdlZGRoypQp+uijjxQWFqYqVaooPDxcPXr00IIFC/Kte9q0aapfv77mzZun2rVrq2bNmhoyZIjKlCmja9eu6f3339fbb7+t1q1bKyAgQAsXLpSTk5M+/PDDIo1Pdna2YmNjVatWLT3++OPq2bOneXw8PDxkb28vZ2dn8xjY2tqaj50wYYJatmypqlWrytPTU/3799fy5cuVkZEhSTpw4ICOHDmiPn363LWOU6dOqUqVKipRosRfqjk/zzzzjAYPHiw/Pz+NHj1aZcqU0Y4dO8zbX3/9dfPs3rZt22rEiBHmZyE/Y8eO1ZUrV8zL2bNn71o7AAAAAAAA7g9C27+xoKAgi8/ly5fXuXPnJElbt25VixYt5OPjIzc3N/Xs2VMXLlzQ9evXC31+Ozs7de7cWcuWLZMkXbt2TevWrVP37t0lSadPn9b169fVsmVLubq6mpfFixcrOTlZklSzZk3z+tatW0v6v5m2eUlOTlZmZqaaNm1qXleiRAk1bNhQSUlJha5dut064M7+r3eOz93Ur1/f4nOHDh1ka2trDrBjY2PNofjdmEymB1rznc9BThB/5zErV65U06ZNzeH866+/rjNnzhR4TgcHB7m7u1ssAAAAAAAAeDjsirsA3Ls/z9w0GAzKzs5WSkqK2rRpo0GDBmny5Mny9PTU7t271a9fP928ebNILxrr3r27QkJCdO7cOW3ZskVOTk5q1aqVJJnbJmzYsEE+Pj4Wxzk4OEiSNm7caO6f6uTkZPHPe2VjY5MrCM2rR2t+41MYLi4uFp/t7e3Vq1cvxcTEqGPHjvr44481e/bsQp2revXq2r17tzIzM+862/Zeai7omD179qh79+4aP368wsLC5OHhoRUrVmjGjBmFqh0AAAAAAAAPHzNt/wd98803ys7O1owZM9SoUSNVr15dv/zyi8U+9vb25h6yBWnSpIl8fX21cuVKLVu2TM8//7w5JAwICJCDg4POnDkjPz8/iyWnB2qlSpXM63KC3aCgoHx/8l+1alXZ29srISHBvC4zM1P79u1TQECAJMnLy0tXr17VtWvXzPscOnSo8ANUxDHI0b9/f23dulXz5s1TVlaWOnbsWKjjunXrpvT0dM2bNy/P7ZcvXy50DUX11VdfqVKlSnrttddUv359VatWTT/++OMDux4AAAAAAAD+Omba/g/y8/NTZmam5s6dq7Zt2yohIUHz58+32MdoNCo9PV3btm1T7dq15ezsnO8M3G7dumn+/Pk6efKkRa9UNzc3jRgxQsOHD1d2draaNWumK1euKCEhQe7u7urdu3ee5xs7dqwCAwM1ePBgRUREyN7eXjt27NDzzz+vMmXKaNCgQRo5cqQ8PT1VsWJFTZs2TdevX1e/fv0kSY899picnZ3173//W0OHDlViYqJiY2OLPE5Go1GJiYlKSUmRq6urPD09C9zf399fjRo10ujRo9W3b99Czxh+7LHHNGrUKL366qv6+eef9dxzz6lChQo6ffq05s+fr2bNmmnYsGFFrr8wqlWrpjNnzmjFihVq0KCBNmzYYNGjGAAAAAAAANaHmbb/g2rXrq2ZM2fqrbfeUq1atbRs2TJNnTrVYp8mTZooIiJCXbp0kZeXl6ZNm5bv+bp3765jx47Jx8fHotesJE2cOFHjxo3T1KlT5e/vr1atWmnDhg2qXLlyvuerXr26vvjiCx0+fFgNGzZU48aNtW7dOtnZ3f47hOjoaHXq1Ek9e/ZUvXr1dPr0acXFxalUqVKSJE9PTy1dulQbN25UYGCgli9frqioqCKP04gRI2Rra6uAgAB5eXndtc+rJHOLib59+xbpWm+99ZY+/vhjJSYmKiwsTDVr1tQrr7yioKCgfMPt+6Fdu3YaPny4hgwZojp16uirr77SuHHjHtj1AAAAAAAA8NcZTEV5SxLwDzdx4kR98skn+vbbb4u7lIcqLS1NHh4e8o1cJRuHwvdELi4p0c8WdwkAAAAAAAC55GQsV65cKfDF78y0BQohPT1dR48e1bvvvquXX365uMsBAAAAAADA/zBCW6AQhgwZouDgYIWGhuZqjRARESFXV9c8l4iIiGKqGAAAAAAAAH9XtEcA/qJz584pLS0tz23u7u4qW7bsQ67o/qM9AgAAAAAAwF9X2PYIdg+xJuB/UtmyZf8nglkAAAAAAABYB9ojAAAAAAAAAIAVIbQFAAAAAAAAACtCaAsAAAAAAAAAVoTQFgAAAAAAAACsCC8iA1BoR8eHFfhmQwAAAAAAAPx1zLQFAAAAAAAAACtCaAsAAAAAAAAAVoTQFgAAAAAAAACsCKEtAAAAAAAAAFgRQlsAAAAAAAAAsCKEtgAAAAAAAABgRQhtAQAAAAAAAMCKENoCAAAAAAAAgBWxK+4CAPx91HozTjYOzsVdRqGkRD9b3CUAAAAAAADcE2baAgAAAAAAAIAVIbQFAAAAAAAAACtCaAsAAAAAAAAAVoTQFgAAAAAAAACsCKEtAAAAAAAAAFgRQlsAAAAAAAAAsCKEtgAAAAAAAABgRQhtAQAAAAAAAMCKENoCAAAAAAAAgBUhtAUAAAAAAAAAK0JoCwAAAAAAAABWhND2H8ZoNGrWrFnFXQbyEB8fL4PBoMuXLz/waxkMBq1du/aBXwcAAAAAAABFR2j7Pyo2NlYlS5bMtX7fvn0aOHDgwy+oGISGhioyMvKBXyclJUUGg0GHDh164NcCAAAAAADA/z674i4AD5eXl1dxl2BVTCaTbt26JTu7B/evwsO4BgAAAAAAAP53MNPWSoWGhmro0KEaNWqUPD095e3traioKPP2mTNnKjAwUC4uLvL19dXgwYOVnp4u6fbP7Pv06aMrV67IYDDIYDCYj72zPUK3bt3UpUsXi+tmZmaqTJkyWrx4sSQpOztbU6dOVeXKleXk5KTatWvr008/vWv9CQkJCg0NlbOzs0qVKqWwsDBdunRJkpSRkaGhQ4eqbNmycnR0VLNmzbRv3z7zsXnNEl67dq0MBoP5c1RUlOrUqaMlS5bIaDTKw8NDXbt21dWrVyVJ4eHh2rlzp2bPnm0eg5SUFHMLgk2bNik4OFgODg5aunSpbGxstH//fotrzpo1S5UqVVJ2dvZd7/dOeV1j9+7dRR7LCxcu6IUXXpCPj4+cnZ0VGBio5cuXW+xzt+dEkk6dOqUnnnhCjo6OCggI0JYtW+56DxkZGUpLS7NYAAAAAAAA8HAQ2lqxRYsWycXFRYmJiZo2bZomTJhgDtxsbGw0Z84cfffdd1q0aJG2b9+uUaNGSZKaNGmiWbNmyd3dXampqUpNTdWIESNynb979+76/PPPzWGvJMXFxen69et67rnnJElTp07V4sWLNX/+fH333XcaPny4evTooZ07d+Zb96FDh9SiRQsFBARoz5492r17t9q2batbt25JkkaNGqXVq1dr0aJFOnDggPz8/BQWFqaLFy8WaXySk5O1du1arV+/XuvXr9fOnTsVHR0tSZo9e7YaN26sAQMGmMfA19fXfOyYMWMUHR2tpKQktWvXTk899ZRiYmIszh8TE6Pw8HDZ2NzbvyZ3XiMoKKjIY3njxg0FBwdrw4YNOnr0qAYOHKiePXvq66+/ttivoOckOztbHTt2lL29vRITEzV//nyNHj36rrVPnTpVHh4e5uXOsQMAAAAAAMCDxe+1rVhQUJDefPNNSVK1atX07rvvatu2bWrZsqVFr1aj0ahJkyYpIiJC8+bNk729vTw8PGQwGOTt7Z3v+cPCwuTi4qI1a9aoZ8+ekqSPP/5Y7dq1k5ubmzIyMjRlyhRt3bpVjRs3liRVqVJFu3fv1oIFCxQSEpLneadNm6b69etr3rx55nU1a9aUJF27dk3vv/++YmNj1bp1a0nSwoULtWXLFn344YcaOXJkoccnOztbsbGxcnNzkyT17NlT27Zt0+TJk+Xh4SF7e3s5OzvnOQYTJkxQy5YtzZ/79++viIgIzZw5Uw4ODjpw4ICOHDmidevWFbqegq5xL2Pp4+NjEba//PLLiouL06pVq9SwYUPz+oKek61bt+r48eOKi4tThQoVJElTpkwxj31+xo4dq1deecX8OS0tjeAWAAAAAADgIWGmrRULCgqy+Fy+fHmdO3dOkrR161a1aNFCPj4+cnNzU8+ePXXhwgVdv3690Oe3s7NT586dtWzZMkm3A9V169ape/fukqTTp0/r+vXratmypVxdXc3L4sWLlZycLOl2GJuzPicIzJlpm5fk5GRlZmaqadOm5nUlSpRQw4YNlZSUVOjapdthdU5gK1mOz93Ur1/f4nOHDh1ka2urNWvWSLrdoqF58+YyGo1Fqim/axRmLP/s1q1bmjhxogIDA+Xp6SlXV1fFxcXpzJkzFvsV9JwkJSXJ19fXHNhKMofGBXFwcJC7u7vFAgAAAAAAgIeDmbZWrESJEhafDQaDsrOzlZKSojZt2mjQoEGaPHmyPD09tXv3bvXr1083b96Us7Nzoa/RvXt3hYSE6Ny5c9qyZYucnJzUqlUrSTK3TdiwYYN8fHwsjnNwcJAkbdy4UZmZmZIkJycni3/eKxsbG5lMJot1Ode4U37jUxguLi4Wn+3t7dWrVy/FxMSoY8eO+vjjjzV79uwiVp7/NQozln/29ttva/bs2Zo1a5a5f3FkZKRu3rxpsd9fGQcAAAAAAABYH0Lbv6FvvvlG2dnZmjFjhrnf6qpVqyz2sbe3N/eQLUiTJk3k6+urlStXatOmTXr++efNIWBAQIAcHBx05syZfFshVKpUKde6oKAgbdu2TePHj8+1rWrVqrK3t1dCQoL52MzMTO3bt8/c8sHLy0tXr17VtWvXzMHnoUOH7novf1bYMcjRv39/1apVS/PmzVNWVpY6duxY5GvmpzBj+WcJCQlq3769evToIel2O4iTJ08qICCg0Nf19/fX2bNnlZqaqvLly0uS9u7dW/QbAAAAAAAAwENDaPs35Ofnp8zMTM2dO1dt27ZVQkKC5s+fb7GP0WhUenq6tm3bptq1a8vZ2TnfGbjdunXT/PnzdfLkSe3YscO83s3NTSNGjNDw4cOVnZ2tZs2a6cqVK0pISJC7u7t69+6d5/nGjh2rwMBADR48WBEREbK3t9eOHTv0/PPPq0yZMho0aJBGjhwpT09PVaxYUdOmTdP169fVr18/SdJjjz0mZ2dn/fvf/9bQoUOVmJio2NjYIo+T0WhUYmKiUlJS5OrqKk9PzwL39/f3V6NGjTR69Gj17dv3L88YvtO9jGW1atX06aef6quvvlKpUqU0c+ZM/fbbb0UKbZ966ilVr15dvXv31ttvv620tDS99tpr9+2+AAAAAAAAcP/R0/ZvqHbt2po5c6beeust1apVS8uWLdPUqVMt9mnSpIkiIiLUpUsXeXl5adq0afmer3v37jp27Jh8fHwses1K0sSJEzVu3DhNnTpV/v7+atWqlTZs2KDKlSvne77q1avriy++0OHDh9WwYUM1btxY69atk53d7b8jiI6OVqdOndSzZ0/Vq1dPp0+fVlxcnEqVKiVJ8vT01NKlS7Vx40YFBgZq+fLlioqKKvI4jRgxQra2tgoICJCXl1euXrB5yWkx0bdv3yJf726KOpavv/666tWrp7CwMIWGhsrb21sdOnQo0jVtbGy0Zs0a/fHHH2rYsKH69++vyZMn34e7AQAAAAAAwINiMP25eSjwDzZx4kR98skn+vbbb4u7FKuSlpYmDw8P+Uauko1D4XsmF6eU6GeLuwQAAAAAAAALORnLlStXCnzxOzNtAd1+UdjRo0f17rvv6uWXXy7ucgAAAAAAAPAPRmgLSBoyZIiCg4MVGhqaqzVCRESEXF1d81wiIiKKqWIAAAAAAAD8r6I9AnAX586dU1paWp7b3N3dVbZs2Ydc0cNHewQAAAAAAIC/rrDtEeweYk3A31LZsmX/EcEsAAAAAAAArAPtEQAAAAAAAADAihDaAgAAAAAAAIAVIbQFAAAAAAAAACtCaAsAAAAAAAAAVoTQFgAAAAAAAACsiF1xFwDg7+Po+DC5u7sXdxkAAAAAAAD/05hpCwAAAAAAAABWhNAWAAAAAAAAAKwIoS0AAAAAAAAAWBFCWwAAAAAAAACwIoS2AAAAAAAAAGBFCG0BAAAAAAAAwIoQ2gIAAAAAAACAFbEr7gIA/H3UejNONg7OxV1GoaREP1vcJQAAAAAAANwTZtoCAAAAAAD8P/buPKyqav/j+OcIMk+iKEooTiAqmqCmkolTqEma5jyEY6amlEN608QhJae0TCtToa5mpmkmjpGYkhlazuRAod3CKCdC70UEf3/4sH8cGUQzOdn79Tz7uZy91177u/bZ3j8+rbM2AFgQQlsAAAAAAAAAsCCEtgAAAAAAAABgQQhtAQAAAAAAAMCCENoCAAAAAAAAgAUhtAUAAAAAAAAAC0JoCwAAAAAAAAAWhNAWAAAAAAAAACwIoS0AAAAAAAAAWBBCWwAAAAAAAACwIIS2AAAAAAAAAGBBCG1hxsfHRwsWLCjpMnAPhYSEKCIioqTLAAAAAAAAQDER2v5DRUdHy83NLd/+xMREDR069P4XVALuZ5i5fv16NWnSRK6urnJ2dladOnXu+bXj4+NlMpl06dKle9ovAAAAAAAA7i/rki4AlsXDw6OkS7AoN27cUHZ2tqyt7/6fSlxcnHr06KFXX31VTz75pEwmk44fP64dO3bcw0oBAAAAAADwoGCm7d9USEiIRo0apfHjx8vd3V2enp6KjIw0js+fP18BAQFydHSUt7e3hg8froyMDEk3Z2QOGDBAly9flslkkslkMs7NuzxC79691aNHD7PrZmVlqVy5cnr//fclSTk5OZo1a5aqVq0qe3t71a9fX2vXrr1t/QkJCQoJCZGDg4PKlCmj0NBQXbx4UZKUmZmpUaNGqXz58rKzs9Ojjz6qxMRE49yCZglv2LBBJpPJ+BwZGamHH35YH3zwgXx8fOTq6qqePXvqjz/+kCSFh4dr165dWrhwoXEPUlJSjNmqW7ZsUVBQkGxtbfXvf/9bpUqV0v79+82uuWDBAlWpUkU5OTlFjvWzzz5TcHCwxo0bJz8/P/n6+qpz58566623zNotWbJE1atXl42Njfz8/PTBBx8Yx1JSUmQymXTw4EFj36VLl2QymRQfH6+UlBS1bNlSklSmTBmZTCaFh4cbbXNycgp9VgqSmZmp9PR0sw0AAAAAAAD3B6Ht31hMTIwcHR21b98+zZ49W9OmTTNmb5YqVUpvvPGGjh07ppiYGH3xxRcaP368JKlZs2ZasGCBXFxclJqaqtTUVI0dOzZf/3369NFnn31mhL2StG3bNl29elVPPfWUJGnWrFl6//339fbbb+vYsWN64YUX1LdvX+3atavQug8ePKjWrVurdu3a2rt3r/bs2aOwsDBlZ2dLksaPH69169YpJiZG3377rWrUqKHQ0FBduHDhju5PcnKyNmzYoE2bNmnTpk3atWuXoqKiJEkLFy5U06ZNNWTIEOMeeHt7G+dOmDBBUVFRSkpK0pNPPqk2bdpoxYoVZv2vWLFC4eHhKlWq6H9Gnp6eOnbsmI4ePVpom/Xr12v06NEaM2aMjh49qmeffVYDBgzQzp07izVWb29vrVu3TpJ04sQJpaamauHChcbxop6VgsyaNUuurq7GlvfeAAAAAAAA4K9FaPs3Vq9ePU2ZMkU1a9ZU//791bBhQ8XFxUmSIiIi1LJlS/n4+KhVq1aaMWOG1qxZI0mysbGRq6urTCaTPD095enpKScnp3z9h4aGytHRUevXrzf2rVq1Sk8++aScnZ2VmZmpmTNnavny5QoNDVW1atUUHh6uvn376p133im07tmzZ6thw4ZavHix6tevrzp16mjkyJEqV66crly5oiVLlmjOnDlq3769ateuraVLl8re3l7Lli27o/uTk5Oj6Oho1a1bV82bN1e/fv2M++Pq6iobGxs5ODgY98DKyso4d9q0aWrbtq2qV68ud3d3DR48WB9++KEyMzMlSd9++62OHDmiAQMG3LaO559/Xo0aNVJAQIB8fHzUs2dPLV++3OhLkubOnavw8HANHz5cvr6+evHFF9WlSxfNnTu3WGO1srKSu7u7JKl8+fLy9PSUq6urcbyoZ6UgEydO1OXLl43tp59+KlYdAAAAAAAA+PMIbf/G6tWrZ/a5YsWKSktLkyR9/vnnat26tby8vOTs7Kx+/frp/Pnzunr1arH7t7a2Vvfu3bVy5UpJ0pUrV/Tpp5+qT58+kqTTp0/r6tWratu2rZycnIzt/fffV3JysiSpTp06xv727dtL+v+ZtgVJTk5WVlaWgoODjX2lS5dW48aNlZSUVOzapZtLPTg7Oxuf896f22nYsKHZ586dO8vKysoIsKOjo41Q/HYcHR0VGxur06dPa9KkSXJyctKYMWPUuHFj4/tISkoyG7MkBQcH3/GYC1PUs1IQW1tbubi4mG0AAAAAAAC4P3gR2d9Y6dKlzT6bTCbl5OQoJSVFHTt21HPPPadXX31V7u7u2rNnjwYNGqRr167JwcGh2Nfo06ePWrRoobS0NO3YsUP29vZq166dJBnLJsTGxsrLy8vsPFtbW0nS5s2blZWVJUmyt7c3+9+7VapUKd24ccNsX+418irs/hSHo6Oj2WcbGxv1799fK1asUJcuXbRq1Sqz5QeKo3r16qpevboGDx6sl19+Wb6+vvroo4+KNVs3dwmGvOMuaMyF+TP3AgAAAAAAAPcXM20fQAcOHFBOTo7mzZunJk2ayNfXV7/88otZGxsbG2MN2aI0a9ZM3t7e+uijj7Ry5Up169bNCABr164tW1tbnT17VjVq1DDbctdArVKlirEvN9itV69eoT/Nz30RV0JCgrEvKytLiYmJql27tiTJw8NDf/zxh65cuWK0yfuCruIq7j3INXjwYH3++edavHixrl+/ri5dutzxNXP5+PjIwcHBGIO/v7/ZmKWbL2vLO2ZJSk1NNY7fOmYbGxtJuqMxAQAAAAAAwPIw0/YBVKNGDWVlZenNN99UWFiYEhIS9Pbbb5u18fHxUUZGhuLi4lS/fn05ODgUOgO3d+/eevvtt3Xy5EmzF2M5Oztr7NixeuGFF5STk6NHH31Uly9fVkJCglxcXPTMM88U2N/EiRMVEBCg4cOHa9iwYbKxsdHOnTvVrVs3lStXTs8995zGjRsnd3d3Va5cWbNnz9bVq1c1aNAgSdIjjzwiBwcH/etf/9KoUaO0b98+RUdH3/F98vHx0b59+5SSkiInJydjTdjC+Pv7q0mTJnrppZc0cODAYs8YjoyM1NWrV9WhQwdVqVJFly5d0htvvKGsrCy1bdtWkjRu3Dh1795dDRo0UJs2bfTZZ5/pk08+0eeffy7p5uzkJk2aKCoqSlWrVlVaWpomTZpkdp0qVarIZDJp06ZN6tChg+zt7QtcqxgAAAAAAACWjZm2D6D69etr/vz5eu2111S3bl2tXLlSs2bNMmvTrFkzDRs2TD169JCHh4dmz55daH99+vTR8ePH5eXllW/d1enTp2vy5MmaNWuW/P391a5dO8XGxqpq1aqF9ufr66vt27fr0KFDaty4sZo2bapPP/1U1tY3/xtCVFSUunbtqn79+ikwMFCnT5/Wtm3bVKZMGUmSu7u7/v3vf2vz5s0KCAjQhx9+qMjIyDu+T2PHjpWVlZVq164tDw8PnT179rbn5C4xMXDgwGJfp0WLFvrhhx/Uv39/1apVS+3bt9e5c+e0fft2+fn5Sbq5Zu7ChQs1d+5c1alTR++8845WrFihkJAQo5/ly5fr+vXrCgoKUkREhGbMmGF2HS8vL02dOlUTJkxQhQoVNHLkyGLXCAAAAAAAAMthunHr4qAACjV9+nR9/PHHOnz4cEmXcl+lp6fL1dVV3hFrVMq2+Gsil6SUqCdKugQAAAAAAAAzuRnL5cuXi3zxOzNtgWLIyMjQ0aNHtWjRIj3//PMlXQ4AAAAAAAAeYIS2QDGMHDlSQUFBCgkJybc0wrBhw+Tk5FTgNmzYsBKqGAAAAAAAAH9XLI8A/ElpaWlKT08v8JiLi4vKly9/nyu691geAQAAAAAA4M8r7vII1vexJuCBVL58+QcimAUAAAAAAIBlYHkEAAAAAAAAALAghLYAAAAAAAAAYEEIbQEAAAAAAADAghDaAgAAAAAAAIAFIbQFAAAAAAAAAAtiXdIFAPj7ODo1VC4uLiVdBgAAAAAAwAONmbYAAAAAAAAAYEEIbQEAAAAAAADAghDaAgAAAAAAAIAFIbQFAAAAAAAAAAtCaAsAAAAAAAAAFoTQFgAAAAAAAAAsCKEtAAAAAAAAAFgQ65IuAMDfR90p21TK1qGky7hrKVFPlHQJAAAAAAAAt8VMWwAAAAAAAACwIIS2AAAAAAAAAGBBCG0BAAAAAAAAwIIQ2gIAAAAAAACABSG0BQAAAAAAAAALQmgLAAAAAAAAABaE0BYAAAAAAAAALAihLQAAAAAAAABYEEJbAAAAAAAAALAghLYAAAAAAAAAYEEIbQEAAAAAAADAghDa/oP4+PhowYIFJV0G/qSQkBBFRESUdBkAAAAAAAD4ixDaPoCio6Pl5uaWb39iYqKGDh16/wsqAfcr2ExJSZHJZJKVlZV+/vlns2OpqamytraWyWRSSkrKPbvmJ598ounTp9+z/gAAAAAAAGBZCG3/QTw8POTg4FDSZViMGzdu6Pr16/ekLy8vL73//vtm+2JiYuTl5XVP+s/L3d1dzs7O97xfAAAAAAAAWAZCWwsUEhKiUaNGafz48XJ3d5enp6ciIyON4/Pnz1dAQIAcHR3l7e2t4cOHKyMjQ5IUHx+vAQMG6PLlyzKZTDKZTMa5eZdH6N27t3r06GF23aysLJUrV84IH3NycjRr1ixVrVpV9vb2ql+/vtauXXvb+hMSEhQSEiIHBweVKVNGoaGhunjxoiQpMzNTo0aNUvny5WVnZ6dHH31UiYmJxrkFzRLesGGDTCaT8TkyMlIPP/ywPvjgA/n4+MjV1VU9e/bUH3/8IUkKDw/Xrl27tHDhQuMepKSkKD4+XiaTSVu2bFFQUJBsbW3173//W6VKldL+/fvNrrlgwQJVqVJFOTk5tx2vJD3zzDNasWKF2b4VK1bomWeeydf26NGjat++vZycnFShQgX169dPv//+u6Sb35+NjY12795ttJ89e7bKly+vX3/9VVL+WcSZmZl66aWX5O3tLVtbW9WoUUPLli0zju/atUuNGzeWra2tKlasqAkTJtyzsBoAAAAAAAD3HqGthYqJiZGjo6P27dun2bNna9q0adqxY4ckqVSpUnrjjTd07NgxxcTE6IsvvtD48eMlSc2aNdOCBQvk4uKi1NRUpaamauzYsfn679Onjz777DMj7JWkbdu26erVq3rqqackSbNmzdL777+vt99+W8eOHdMLL7ygvn37ateuXYXWffDgQbVu3Vq1a9fW3r17tWfPHoWFhSk7O1uSNH78eK1bt04xMTH69ttvVaNGDYWGhurChQt3dH+Sk5O1YcMGbdq0SZs2bdKuXbsUFRUlSVq4cKGaNm2qIUOGGPfA29vbOHfChAmKiopSUlKSnnzySbVp06bAwDU8PFylShXvn8iTTz6pixcvas+ePZKkPXv26OLFiwoLCzNrd+nSJbVq1UoNGjTQ/v37tXXrVv3666/q3r27pP8PZPv166fLly/ru+++0+TJk/Xee++pQoUKBV67f//++vDDD/XGG28oKSlJ77zzjpycnCRJP//8szp06KBGjRrp0KFDWrJkiZYtW6YZM2YUOZ7MzEylp6ebbQAAAAAAALg/rEu6ABSsXr16mjJliiSpZs2aWrRokeLi4tS2bVuzWZY+Pj6aMWOGhg0bpsWLF8vGxkaurq4ymUzy9PQstP/Q0FA5Ojpq/fr16tevnyRp1apVevLJJ+Xs7KzMzEzNnDlTn3/+uZo2bSpJqlatmvbs2aN33nlHLVq0KLDf2bNnq2HDhlq8eLGxr06dOpKkK1euaMmSJYqOjlb79u0lSUuXLtWOHTu0bNkyjRs3rtj3JycnR9HR0cYyAf369VNcXJxeffVVubq6ysbGRg4ODgXeg2nTpqlt27bG58GDB2vYsGGaP3++bG1t9e233+rIkSP69NNPi11P6dKl1bdvXy1fvlyPPvqoli9frr59+6p06dJm7RYtWqQGDRpo5syZxr7ly5fL29tbJ0+elK+vr2bMmKEdO3Zo6NChOnr0qJ555hk9+eSTBV735MmTWrNmjXbs2KE2bdpIuvk95Vq8eLG8vb21aNEimUwm1apVS7/88oteeuklvfLKK4WG0rNmzdLUqVOLPX4AAAAAAADcO8y0tVD16tUz+1yxYkWlpaVJkj7//HO1bt1aXl5ecnZ2Vr9+/XT+/HldvXq12P1bW1ure/fuWrlypaSbgeqnn36qPn36SJJOnz6tq1evqm3btnJycjK2999/X8nJyZJuhrG5+3ND2NyZtgVJTk5WVlaWgoODjX2lS5dW48aNlZSUVOzapZthdd51XfPen9tp2LCh2efOnTvLyspK69evl3RziYaWLVvKx8fnjmoaOHCgPv74Y507d04ff/yxBg4cmK/NoUOHtHPnTrN7WqtWLUky7quNjY1WrlypdevW6X//+59ef/31Qq958OBBWVlZFRqiJyUlqWnTpmbLSwQHBysjI0P/+c9/Cu134sSJunz5srH99NNPxboHAAAAAAAA+POYaWuhbp2haTKZlJOTo5SUFHXs2FHPPfecXn31Vbm7u2vPnj0aNGiQrl27dkcvGuvTp49atGihtLQ07dixQ/b29mrXrp0kGcsmxMbG5nuZlq2trSRp8+bNysrKkiTZ29ub/e/dKlWqlG7cuGG2L/caeRV2f4rD0dHR7LONjY369++vFStWqEuXLlq1apUWLlx4h5VLAQEBqlWrlnr16iV/f3/VrVtXBw8eNGuTkZGhsLAwvfbaa/nOr1ixovH3V199JUm6cOGCLly4kK/mXH/2fhfG1tbW+J4BAAAAAABwfzHT9m/mwIEDysnJ0bx589SkSRP5+vrql19+MWtjY2NjrCFblGbNmsnb21sfffSRVq5cqW7duhlhaO3atWVra6uzZ8+qRo0aZlvu+rBVqlQx9uUGu/Xq1VNcXFyB16tevbpsbGyUkJBg7MvKylJiYqJq164tSfLw8NAff/yhK1euGG1uDT6Lo7j3INfgwYP1+eefa/Hixbp+/bq6dOlyx9eUbs62jY+PL3CWrSQFBgbq2LFj8vHxyXdfc4PZ5ORkvfDCC1q6dKkeeeQRPfPMM4UG0gEBAcrJySl0nWF/f3/t3bvXLAhPSEiQs7OzHnroobsaIwAAAAAAAP5ahLZ/MzVq1FBWVpbefPNN/fDDD/rggw/09ttvm7Xx8fFRRkaG4uLi9Pvvvxe5bELv3r319ttva8eOHcbSCJLk7OyssWPH6oUXXlBMTIySk5P17bff6s0331RMTEyh/U2cOFGJiYkaPny4Dh8+rO+//15LlizR77//LkdHRz333HMaN26ctm7dquPHj2vIkCG6evWqBg0aJEl65JFH5ODgoH/9619KTk7WqlWrFB0dfcf3ycfHR/v27VNKSop+//33287C9ff3V5MmTfTSSy+pV69edz2DdciQIfrtt980ePDgAo+PGDFCFy5cUK9evZSYmKjk5GRt27ZNAwYMUHZ2trKzs9W3b1+FhoZqwIABWrFihQ4fPqx58+YVOs5nnnlGAwcO1IYNG/Tjjz8qPj5ea9askSQNHz5cP/30k55//nl9//33+vTTTzVlyhS9+OKLxX7JGgAAAAAAAO4vUpu/mfr162v+/Pl67bXXVLduXa1cuVKzZs0ya9OsWTMNGzZMPXr0kIeHh2bPnl1of3369NHx48fl5eVlttasJE2fPl2TJ0/WrFmz5O/vr3bt2ik2NlZVq1YttD9fX19t375dhw4dUuPGjdW0aVN9+umnsra+uRJHVFSUunbtqn79+ikwMFCnT5/Wtm3bVKZMGUmSu7u7/v3vf2vz5s0KCAjQhx9+qMjIyDu+T2PHjpWVlZVq164tDw8PnT179rbn5C4xUdgs2eKwtrZWuXLljPHeqlKlSkpISFB2drYef/xxBQQEKCIiQm5ubipVqpReffVVnTlzRu+8846km0smvPvuu5o0aZIOHTpUYJ9LlizR008/reHDh6tWrVoaMmSIMVPZy8tLmzdv1jfffKP69etr2LBhGjRokCZNmnTXYwQAAAAAAMBfy3Tj1gVEgX+o6dOn6+OPP9bhw4dLuhSLk56eLldXV3lHrFEp2+Kvm2xpUqKeKOkSAAAAAADAP1huxnL58mW5uLgU2o6ZtvjHy8jI0NGjR7Vo0SI9//zzJV0OAAAAAAAA/uEIbfGPN3LkSAUFBSkkJCTf0gjDhg2Tk5NTgduwYcNKqGIAAAAAAAA8yFgeAShCWlqa0tPTCzzm4uKi8uXL3+eKSgbLIwAAAAAAAPx5xV0eoeC3JQGQJJUvX/4fE8wCAAAAAADAMrA8AgAAAAAAAABYEEJbAAAAAAAAALAghLYAAAAAAAAAYEEIbQEAAAAAAADAghDaAgAAAAAAAIAFsS7pAgD8fRydGioXF5eSLgMAAAAAAOCBxkxbAAAAAAAAALAghLYAAAAAAAAAYEEIbQEAAAAAAADAghDaAgAAAAAAAIAFIbQFAAAAAAAAAAtCaAsAAAAAAAAAFoTQFgAAAAAAAAAsiHVJFwDg76PulG0qZetQ0mX8KSlRT5R0CQAAAAAAAEVipi0AAAAAAAAAWBBCWwAAAAAAAACwIIS2AAAAAAAAAGBBCG0BAAAAAAAAwIIQ2gIAAAAAAACABSG0BQAAAAAAAAALQmgLAAAAAAAAABaE0BYAAAAAAAAALAihLQAAAAAAAABYEEJbAAAAAAAAALAghLYAAAAAAAAAYEEIbQEAAAAAAADAghDa/oVCQkIUERFhMf0UV2RkpB5++OEi29zvmm4nPDxcnTt3LukyinSvavw7jBUAAAAAAAB3j9DWgsTHx8tkMunSpUtm+z/55BNNnz69ZIoqxF9R01dffaUOHTqoTJkysrOzU0BAgObPn6/s7GyjTUpKikwmkw4ePHhPr22JChvrwoULFR0dXSI1AQAAAAAA4K9HaHuXrl27dt+u5e7uLmdn5/t2veK41zWtX79eLVq00EMPPaSdO3fq+++/1+jRozVjxgz17NlTN27cuGfXKq7s7Gzl5OTctt39fBYkydXVVW5ubvf1mgAAAAAAALh/CG2LKSQkRCNHjlRERITKlSun0NBQHT16VO3bt5eTk5MqVKigfv366ffffy+0jw8++EANGzaUs7OzPD091bt3b6WlpUm6OauyZcuWkqQyZcrIZDIpPDzcuHbepQguXryo/v37q0yZMnJwcFD79u116tQp43h0dLTc3Ny0bds2+fv7y8nJSe3atVNqaqrRJj4+Xo0bN5ajo6Pc3NwUHBysM2fO5KvXx8dHrq6u6tmzp/744w+z+5G3Jh8fH02fPl29evWSo6OjvLy89NZbbxXr3l65ckVDhgzRk08+qXfffVcPP/ywfHx8NHjwYMXExGjt2rVas2aNJKlq1aqSpAYNGshkMikkJMSsr7lz56pixYoqW7asRowYoaysLONYZmamxo4dKy8vLzk6OuqRRx5RfHx8vvu2ceNG1a5dW7a2tjp79my+enOXJ3j11VdVqVIl+fn5SZJ++uknde/eXW5ubnJ3d1enTp2UkpJS6Li3bt2qRx99VG5ubipbtqw6duyo5ORk43hhY827PMK7776rSpUq5QuXO3XqpIEDBxqfP/30UwUGBsrOzk7VqlXT1KlTdf369UJry8zMVHp6utkGAAAAAACA+4PQ9g7ExMTIxsZGCQkJioqKUqtWrdSgQQPt379fW7du1a+//qru3bsXen5WVpamT5+uQ4cOacOGDUpJSTGCWW9vb61bt06SdOLECaWmpmrhwoUF9hMeHq79+/dr48aN2rt3r27cuKEOHTqYBZRXr17V3Llz9cEHH+jLL7/U2bNnNXbsWEnS9evX1blzZ7Vo0UKHDx/W3r17NXToUJlMJuP85ORkbdiwQZs2bdKmTZu0a9cuRUVFFXl/5syZo/r16+u7777ThAkTNHr0aO3YseO293X79u06f/68UV9eYWFh8vX11YcffihJ+uabbyRJn3/+uVJTU/XJJ58YbXfu3Knk5GTt3LlTMTExio6ONltGYOTIkdq7d69Wr16tw4cPq1u3bmrXrp1Z4H316lW99tpreu+993Ts2DGVL1++wJrj4uJ04sQJ7dixQ5s2bVJWVpZCQ0Pl7Oys3bt3KyEhwQjLC5uJe+XKFb344ovav3+/4uLiVKpUKT311FNGAFvUWHN169ZN58+f186dO419Fy5c0NatW9WnTx9J0u7du9W/f3+NHj1ax48f1zvvvKPo6Gi9+uqrBdYlSbNmzZKrq6uxeXt7F9oWAAAAAAAA95Z1SRfwd1KzZk3Nnj1bkjRjxgw1aNBAM2fONI4vX75c3t7eOnnypHx9ffOdn3fmY7Vq1fTGG2+oUaNGysjIkJOTk9zd3SVJ5cuXL/Tn76dOndLGjRuVkJCgZs2aSZJWrlwpb29vbdiwQd26dZN0MyB+++23Vb16dUk3A8tp06ZJktLT03X58mV17NjROO7v7292nZycHEVHRxtLIPTr109xcXFFBn3BwcGaMGGCJMnX11cJCQl6/fXX1bZt20LPkaSTJ08WWEOuWrVqGW08PDwkSWXLlpWnp6dZuzJlymjRokWysrJSrVq19MQTTyguLk5DhgzR2bNntWLFCp09e1aVKlWSJI0dO1Zbt27VihUrjO8xKytLixcvVv369Yus2dHRUe+9955sbGwkSf/+97+Vk5Oj9957zwi/V6xYITc3N8XHx+vxxx/P10fXrl3NPi9fvlweHh46fvy46tatW+RY8465ffv2WrVqlVq3bi1JWrt2rcqVK2fM3J46daomTJigZ555RtLNZ2/69OkaP368pkyZUmC/EydO1Isvvmh8Tk9PJ7gFAAAAAAC4T5hpeweCgoKMvw8dOqSdO3fKycnJ2GrVqiVJZj9xz+vAgQMKCwtT5cqV5ezsrBYtWkhSgT/BL0xSUpKsra31yCOPGPvKli0rPz8/JSUlGfscHByMQFaSKlasaCzF4O7urvDwcIWGhiosLEwLFy40WzpBurncQd41a/OeX5imTZvm+5y3ptv5s+vW1qlTR1ZWVsbnvDUfOXJE2dnZ8vX1NfvOdu3aZfZ92djYqF69epJufi952+YN6AMCAozAVrr5PJw+fVrOzs5Ge3d3d/3vf/8r9Hk4deqUevXqpWrVqsnFxUU+Pj7Gde9Enz59tG7dOmVmZkq6GeL37NlTpUqVMmqbNm2a2ViGDBmi1NRUXb16tcA+bW1t5eLiYrYBAAAAAADg/mCm7R1wdHQ0/s7IyFBYWJhee+21fO0qVqyYb9+VK1cUGhqq0NBQrVy5Uh4eHjp79qxCQ0P/khdZlS5d2uyzyWQyC0VXrFihUaNGaevWrfroo480adIk7dixQ02aNCn0/OK8lOtu5M5KTkpKMmYP55WUlKTatWvftp+ias7IyJCVlZUOHDhgFuxKkpOTk/G3vb29MVO2UqVKOnjwoHEsdya0ZP4s5PYfFBSklStX5qsrd8bsrcLCwlSlShUtXbrUWJe2bt26d/w8hIWF6caNG4qNjVWjRo20e/duvf7662a1TZ06VV26dMl3rp2d3R1dCwAAAAAAAH89Qtu7FBgYqHXr1snHx0fW1re/jd9//73Onz+vqKgo42fm+/fvN2uTO3MzOzu70H78/f11/fp17du3zwg4z58/rxMnThQr2MyrQYMGatCggSZOnKimTZtq1apVRmh7N77++ut8nwtb8iCvxx9/XO7u7po3b16+0Hbjxo06deqUpk+fLql496ggDRo0UHZ2ttLS0tS8efNinWNtba0aNWoUq21gYKA++ugjlS9fvlizUnO/s6VLlxr17Nmzx6xNccdqZ2enLl26aOXKlTp9+rT8/PwUGBhoVtuJEyeKPRYAAAAAAACULJZHuEsjRozQhQsX1KtXLyUmJio5OVnbtm3TgAEDCgzZKleuLBsbG7355pv64YcftHHjRiOIzFWlShWZTCZt2rRJv/32mzIyMvL1U7NmTXXq1ElDhgzRnj17dOjQIfXt21deXl7q1KlTsWr/8ccfNXHiRO3du1dnzpzR9u3bderUqWIFrEVJSEjQ7NmzdfLkSb311lv6+OOPNXr06Nue5+joqHfeeUeffvqphg4dqsOHDyslJUXLli1TeHi4nn76aeMFb+XLl5e9vb3x4rfLly8XqzZfX1/16dNH/fv31yeffKIff/xR33zzjWbNmqXY2Ng/NW7p5hIF5cqVU6dOnbR79279+OOPio+P16hRo/Sf//wnX/syZcqobNmyevfdd3X69Gl98cUXZmvI3ulY+/Tpo9jYWC1fvtx4AVmuV155Re+//76mTp2qY8eOKSkpSatXr9akSZP+9LgBAAAAAABw7xHa3qVKlSopISFB2dnZevzxxxUQEKCIiAi5ubkZa4nm5eHhoejoaH388ceqXbu2oqKiNHfuXLM2Xl5exkujKlSooJEjRxZ47RUrVigoKEgdO3ZU06ZNdePGDW3evDnf8gCFcXBw0Pfff6+uXbvK19dXQ4cO1YgRI/Tss8/e+Y3IY8yYMdq/f78aNGigGTNmaP78+QoNDS3WuU8//bR27typs2fPqnnz5vLz89Prr7+ul19+WatXrzaWLLC2ttYbb7yhd955R5UqVSp2UC3dvG/9+/fXmDFj5Ofnp86dOysxMVGVK1e+q/Hm5eDgoC+//FKVK1dWly5d5O/vr0GDBul///tfgTNvS5UqpdWrV+vAgQOqW7euXnjhBc2ZM8eszZ2MtVWrVnJ3d9eJEyfUu3dvs2OhoaHatGmTtm/frkaNGqlJkyZ6/fXXVaVKlT89bgAAAAAAANx7pht/9u1PgG6+uCwiIkIRERElXQr+Aunp6XJ1dZV3xBqVsnUo6XL+lJSoJ0q6BAAAAAAA8A+Vm7Fcvny5yCU2mWkLAAAAAAAAABaE0BZ/uZUrV8rJyanArU6dOiVdHgAAAAAAAGBRrEu6ADwYUlJSCj325JNP6pFHHinwWHHX4QUAAAAAAAD+KQht8ZdzdnaWs7NzSZcBAAAAAAAA/C2wPAIAAAAAAAAAWBBCWwAAAAAAAACwIIS2AAAAAAAAAGBBCG0BAAAAAAAAwILwIjIAxXZ0aqhcXFxKugwAAAAAAIAHGjNtAQAAAAAAAMCCENoCAAAAAAAAgAUhtAUAAAAAAAAAC0JoCwAAAAAAAAAWhNAWAAAAAAAAACwIoS0AAAAAAAAAWBBCWwAAAAAAAACwIIS2AAAAAAAAAGBBrEu6AAB/H3WnbFMpW4eSLuOeS4l6oqRLAAAAAAAAMDDTFgAAAAAAAAAsCKEtAAAAAAAAAFgQQlsAAAAAAAAAsCCEtgAAAAAAAABgQQhtAQAAAAAAAMCCENoCAAAAAAAAgAUhtAUAAAAAAAAAC0JoCwAAAAAAAAAWhNAWAAAAAAAAACwIoS0AAAAAAAAAWBBCWwAAAAAAAACwIIS2/yDx8fEymUy6dOlSSZdSpHtRZ3h4uDp37nzPagIAAAAAAADuF0LbB1RISIgiIiLM9jVr1kypqalydXW9b3WYTCZjc3V1VXBwsL744osizymJOgEAAAAAAABLQWj7D2JjYyNPT0+ZTKb7et0VK1YoNTVVCQkJKleunDp27KgffvihwLZZWVklVueD6Nq1ayVdAgAAAAAAAO4QoW0BMjMzNWrUKJUvX152dnZ69NFHlZiYaBw/duyYOnbsKBcXFzk7O6t58+ZKTk42ji9fvlx16tSRra2tKlasqJEjR0qSUlJSZDKZdPDgQaPtpUuXZDKZFB8fL+n/lwaIjY1VvXr1ZGdnpyZNmujo0aPGOefPn1evXr3k5eUlBwcHBQQE6MMPPzSOh4eHa9euXVq4cKExyzUlJaXAZQfWrVtn1Orj46N58+aZ3QsfHx/NnDlTAwcOlLOzsypXrqx33333ju6nm5ubPD09VbduXS1ZskT//e9/tWPHDkk3Z+IuWbJETz75pBwdHfXqq6+a1Zmeni57e3tt2bLFrM/169fL2dlZV69eLfLac+fOVcWKFVW2bFmNGDFCWVlZxrGLFy+qf//+KlOmjBwcHNS+fXudOnXKOB4ZGamHH37YrL8FCxbIx8fH+BwfH6/GjRvL0dFRbm5uCg4O1pkzZ4zjn376qQIDA2VnZ6dq1app6tSpun79eqH1Xrt2TSNHjlTFihVlZ2enKlWqaNasWcbxS5cuafDgwfLw8JCLi4tatWqlQ4cO5av5vffeU9WqVWVnZ6d3331XlSpVUk5Ojtm1OnXqpIEDBxZYR2ZmptLT0802AAAAAAAA3B+EtgUYP3681q1bp5iYGH377beqUaOGQkNDdeHCBf3888967LHHZGtrqy+++EIHDhzQwIEDjSBuyZIlGjFihIYOHaojR45o48aNqlGjxh3XMG7cOM2bN0+JiYny8PBQWFiYETj+73//U1BQkGJjY3X06FENHTpU/fr10zfffCNJWrhwoZo2baohQ4YoNTVVqamp8vb2zneNAwcOqHv37urZs6eOHDmiyMhITZ48WdHR0Wbt5s2bp4YNG+q7777T8OHD9dxzz+nEiRN3PCZJsre3l2Q+AzQyMlJPPfWUjhw5ki9EdHFxUceOHbVq1Sqz/StXrlTnzp3l4OBQ6LV27typ5ORk7dy5UzExMYqOjjYbW3h4uPbv36+NGzdq7969unHjhjp06GAW7Bbl+vXr6ty5s1q0aKHDhw9r7969Gjp0qDFDePfu3erfv79Gjx6t48eP65133lF0dLReffXVQvt84403tHHjRq1Zs0YnTpzQypUrzULibt26KS0tTVu2bNGBAwcUGBio1q1b68KFC0ab06dPa926dfrkk0908OBBdevWTefPn9fOnTuNNhcuXNDWrVvVp0+fAuuYNWuWXF1dja2g5wcAAAAAAAB/DeuSLsDSXLlyRUuWLFF0dLTat28vSVq6dKl27NihZcuW6eLFi3J1ddXq1atVunRpSZKvr69x/owZMzRmzBiNHj3a2NeoUaM7rmPKlClq27atJCkmJkYPPfSQ1q9fr+7du8vLy0tjx4412j7//PPatm2b1qxZo8aNG8vV1VU2NjZycHCQp6dnodeYP3++WrdurcmTJxvjOH78uObMmaPw8HCjXYcOHTR8+HBJ0ksvvaTXX39dO3fulJ+f3x2N6erVq5o0aZKsrKzUokULY3/v3r01YMAA4/OtSyf06dNH/fr109WrV+Xg4KD09HTFxsZq/fr1RV6vTJkyWrRokaysrFSrVi098cQTiouL05AhQ3Tq1Clt3LhRCQkJatasmaSbQbC3t7c2bNigbt263XY86enpunz5sjp27Kjq1atLkvz9/Y3jU6dO1YQJE/TMM89IkqpVq6bp06dr/PjxmjJlSoF9nj17VjVr1tSjjz4qk8mkKlWqGMf27Nmjb775RmlpabK1tZV0cybxhg0btHbtWg0dOlTSzUD8/fffl4eHh3Fu+/bttWrVKrVu3VqStHbtWpUrV04tW7YssI6JEyfqxRdfNBsrwS0AAAAAAMD9wUzbWyQnJysrK0vBwcHGvtKlS6tx48ZKSkrSwYMH1bx5cyOwzSstLU2//PKLEYz9GU2bNjX+dnd3l5+fn5KSkiRJ2dnZmj59ugICAuTu7i4nJydt27ZNZ8+evaNrJCUlmY1TkoKDg3Xq1CllZ2cb++rVq2f8bTKZ5OnpqbS0tGJfp1evXnJycpKzs7PWrVunZcuWmfXZsGHDIs/v0KGDSpcurY0bN0q6uaSDi4uL2rRpo7Nnz8rJycnYZs6caZxXp04dWVlZGZ8rVqxo1J2UlCRra2s98sgjxvGyZcua3efbcXd3V3h4uEJDQxUWFqaFCxcqNTXVOH7o0CFNmzbNrL7c2c9Xr17VsGHDzI5JN2f/Hjx4UH5+fho1apS2b99u1l9GRobKli1rdt6PP/5otjxHlSpVzAJb6WbwvW7dOmVmZkq6GVD37NlTpUoV/H8Btra2cnFxMdsAAAAAAABwfzDT9g7l/rz/To9JMgKyGzduGPuK+1P8vObMmaOFCxdqwYIFCggIkKOjoyIiIv6yl07dGlCbTKZ866MW5fXXX1ebNm3k6uqaL0yUJEdHxyLPt7Gx0dNPP61Vq1apZ8+eWrVqlXr06CFra2tVqlTJbI1gd3f3e1Z3qVKlzL4rKf/3tWLFCo0aNUpbt27VRx99pEmTJmnHjh1q0qSJMjIyNHXqVHXp0iVf33Z2dpo2bZrZjGlJCgwM1I8//qgtW7bo888/V/fu3dWmTRutXbtWGRkZqlixorH+cV5ubm7G3wXdz7CwMN24cUOxsbFq1KiRdu/erddff73Y9wIAAAAAAAD3D6HtLapXry4bGxslJCQYP03PyspSYmKiIiIidOXKFcXExCgrKytfKOjs7CwfHx/FxcUV+LPz3MAyNTVVDRo0kCSzwDGvr7/+WpUrV5Z084VZJ0+eNH56n5CQoE6dOqlv376SpJycHJ08eVK1a9c2zrexsTGbLVsQf39/JSQkmO1LSEiQr6+v2QzVP8vT0/Ou1vXNq0+fPmrbtq2OHTumL774QjNmzJAkWVtb31Xf/v7+un79uvbt22csj3D+/HmdOHHCuI8eHh46d+6cbty4YaxTW9D31aBBAzVo0EATJ05U06ZNtWrVKjVp0kSBgYE6ceJEofWVL19e5cuXz7ffxcVFPXr0UI8ePfT000+rXbt2unDhggIDA3Xu3DlZW1ubrXNbHHZ2durSpYtWrlyp06dPy8/PT4GBgXfUBwAAAAAAAO4PQttbODo66rnnntO4cePk7u6uypUra/bs2bp69aoGDRqknJwcvfnmm+rZs6cmTpwoV1dXff3112rcuLH8/PwUGRmpYcOGqXz58mrfvr3++OMPJSQk6Pnnn5e9vb2aNGmiqKgoVa1aVWlpaZo0aVKBdUybNk1ly5ZVhQoV9PLLL6tcuXLq3LmzJKlmzZpau3atvvrqK5UpU0bz58/Xr7/+ahba+vj4aN++fUpJSZGTk5PZDNRcY8aMUaNGjTR9+nT16NFDe/fu1aJFi7R48eK/5N7+GY899pg8PT3Vp08fVa1a1WxZg7tRs2ZNderUSUOGDNE777wjZ2dnTZgwQV5eXurUqZMkKSQkRL/99ptmz56tp59+Wlu3btWWLVuMpQJ+/PFHvfvuu3ryySdVqVIlnThxQqdOnVL//v0lSa+88oo6duyoypUr6+mnn1apUqV06NAhHT161AidbzV//nxVrFhRDRo0UKlSpfTxxx/L09NTbm5uatOmjZo2barOnTtr9uzZ8vX11S+//KLY2Fg99dRTt11mok+fPurYsaOOHTtmBP4AAAAAAACwPKxpW4CoqCh17dpV/fr1U2BgoE6fPq1t27apTJkyKlu2rL744gtlZGSoRYsWCgoK0tKlS41Zt88884wWLFigxYsXq06dOurYsaNOnTpl9L18+XJdv35dQUFBioiIKDS8i4qK0ujRoxUUFKRz587ps88+k42NjSRp0qRJCgwMVGhoqEJCQuTp6WkEurnGjh0rKysr1a5dWx4eHgWudxsYGKg1a9Zo9erVqlu3rl555RVNmzbN7CVklsJkMqlXr146dOiQ+vTpc0/6XLFihYKCgtSxY0c1bdpUN27c0ObNm43v0t/fX4sXL9Zbb72l+vXr65tvvjFbzsDBwUHff/+9unbtKl9fXw0dOlQjRozQs88+K0kKDQ3Vpk2btH37djVq1EhNmjTR66+/bvZysVs5Oztr9uzZatiwoRo1aqSUlBRt3rxZpUqVkslk0ubNm/XYY49pwIAB8vX1Vc+ePXXmzBlVqFDhtuNt1aqV3N3ddeLECfXu3ftP3j0AAAAAAAD8VUw3bl20EyUqPj5eLVu21MWLF83WKQVKUnp6ulxdXeUdsUalbB1Kupx7LiXqiZIuAQAAAAAA/APkZiyXL18u8sXvzLQFAAAAAAAAAAtCaIu7NnPmTDk5ORW4tW/fvqTLAwAAAAAAAP6WeBGZhQkJCdHfZcWKYcOGqXv37gUes7e3v8/VAAAAAAAAAA8GQlvcNXd3d7m7u5d0GQAAAAAAAMADheURAAAAAAAAAMCCENoCAAAAAAAAgAUhtAUAAAAAAAAAC0JoCwAAAAAAAAAWhNAWAAAAAAAAACyIdUkXAODv4+jUULm4uJR0GQAAAAAAAA80ZtoCAAAAAAAAgAUhtAUAAAAAAAAAC0JoCwAAAAAAAAAWhNAWAAAAAAAAACwIoS0AAAAAAAAAWBBCWwAAAAAAAACwIIS2AAAAAAAAAGBBrEu6AAB/H3WnbFMpW4eSLuMvkxL1REmXAAAAAAAAwExbAAAAAAAAALAkhLYAAAAAAAAAYEEIbQEAAAAAAADAghDaAgAAAAAAAIAFIbQFAAAAAAAAAAtCaAsAAAAAAAAAFoTQFgAAAAAAAAAsCKEtAAAAAAAAAFgQQlsAAAAAAAAAsCCEtgAAAAAAAABgQQhtAQAAAAAAAMCCENr+Q8THx8tkMunSpUslXcp9FxISooiIiPtyrQ0bNqhGjRqysrJSRESEoqOj5ebmVqxzi9M2PDxcnTt3/tN1AgAAAAAAwHJZl3QBuPdCQkL08MMPa8GCBca+Zs2aKTU1Va6urvetDpPJlG9fcHCw9uzZc99qkKRPPvlEpUuXvi/XevbZZzVgwACNGjVKzs7Osra2VocOHe5Z/wsXLtSNGzfuWX8AAAAAAACwPIS2/xA2Njby9PS879ddsWKF2rVrZ1bH3bh27dpdn+vu7n5X592pjIwMpaWlKTQ0VJUqVTL229vb37Nr3M/QHQAAAAAAACWD5RFukZmZqVGjRql8+fKys7PTo48+qsTEROP4sWPH1LFjR7m4uMjZ2VnNmzdXcnKycXz58uWqU6eObG1tVbFiRY0cOVKSlJKSIpPJpIMHDxptL126JJPJpPj4eEn/v4RBbGys6tWrJzs7OzVp0kRHjx41zjl//rx69eolLy8vOTg4KCAgQB9++KFxPDw8XLt27dLChQtlMplkMpmUkpJS4PII69atM2r18fHRvHnzzO6Fj4+PZs6cqYEDB8rZ2VmVK1fWu+++e0f3083NTZ6ensbm7u5+2zFIN2cLjxw5UhERESpXrpxCQ0ONMWzbtk0NGjSQvb29WrVqpbS0NG3ZskX+/v5ycXFR7969dfXqVbO+8i6PUJxxffXVV3r44YdlZ2enhg0basOGDfm+v7zi4+Pl7OwsSWrVqpXxvd665MGhQ4fUsmVLOTs7y8XFRUFBQdq/f79ZX9u2bZO/v7+cnJzUrl07paamGsduXR4hJCREo0aN0vjx4+Xu7i5PT09FRkaa9ff999/r0UcflZ2dnWrXrq3PP/9cJpNJGzZsKORbu/nvID093WwDAAAAAADA/UFoe4vx48dr3bp1iomJ0bfffqsaNWooNDRUFy5c0M8//6zHHntMtra2+uKLL3TgwAENHDhQ169flyQtWbJEI0aM0NChQ3XkyBFt3LhRNWrUuOMaxo0bp3nz5ikxMVEeHh4KCwtTVlaWJOl///ufgoKCFBsbq6NHj2ro0KHq16+fvvnmG0k3fz7ftGlTDRkyRKmpqUpNTZW3t3e+axw4cEDdu3dXz549deTIEUVGRmry5MmKjo42azdv3jw1bNhQ3333nYYPH67nnntOJ06cuOMx5XW7MeSKiYmRjY2NEhIS9Pbbbxv7IyMjtWjRIn311Vf66aef1L17dy1YsECrVq1SbGystm/frjfffLPIGooaV3p6usLCwhQQEKBvv/1W06dP10svvVRkf82aNTPOX7dunVJTU9WsWbN87fr06aOHHnpIiYmJOnDggCZMmGC2dMPVq1c1d+5cffDBB/ryyy919uxZjR07tshrx8TEyNHRUfv27dPs2bM1bdo07dixQ5KUnZ2tzp07y8HBQfv27dO7776rl19+ucj+JGnWrFlydXU1toKeIQAAAAAAAPw1WB4hjytXrmjJkiWKjo5W+/btJUlLly7Vjh07tGzZMl28eFGurq5avXq1EbT5+voa58+YMUNjxozR6NGjjX2NGjW64zqmTJmitm3bSroZyD300ENav369unfvLi8vL7MQ7/nnn9e2bdu0Zs0aNW7cWK6urrKxsZGDg0ORyyHMnz9frVu31uTJk41xHD9+XHPmzFF4eLjRrkOHDho+fLgk6aWXXtLrr7+unTt3ys/Pr1hj6dWrl6ysrIzP//73v9W5c+cix5CrZs2amj17tvE5d8bpjBkzFBwcLEkaNGiQJk6cqOTkZFWrVk2S9PTTT2vnzp1FBq1FjWvVqlUymUxaunSpMTv1559/1pAhQwrtz8bGRuXLl5ckY8ZrQc6ePatx48apVq1axhjzysrK0ttvv63q1atLkkaOHKlp06YVel1JqlevnqZMmWL0t2jRIsXFxalt27basWOHkpOTFR8fb9T06quvGs9XYSZOnKgXX3zR+Jyenk5wCwAAAAAAcJ8Q2uaRnJysrKwsIxCUpNKlS6tx48ZKSkrSuXPn1Lx58wJfapWWlqZffvlFrVu3/tN1NG3a1Pjb3d1dfn5+SkpKknRz5uTMmTO1Zs0a/fzzz7p27ZoyMzPl4OBwR9dISkpSp06dzPYFBwdrwYIFys7ONoLWevXqGcdNJpM8PT2VlpZW7Ou8/vrratOmjfG5YsWKxR5DUFBQgX3mralChQpycHAwAtvcfbfO2i2qj1vHdeLECWN5ilx5w2RJqlOnjs6cOSNJat68ubZs2VLk9XK9+OKLGjx4sD744AO1adNG3bp1MwJaSXJwcDD7XLFixdve77xjufWcEydOyNvb2yxEvnUsBbG1tZWtrW2xxgQAAAAAAIB7i9D2DhT1QqnbvWyqVKmbK1HcuHHD2Je75MGdmDNnjhYuXKgFCxYoICBAjo6OioiI0LVr1+64r+K4NaA2mUzKyckp9vmenp75loiIiooq1hgcHR1vW5PJZLqrGv/suDZv3mx8f3fyorHIyEj17t1bsbGx2rJli6ZMmaLVq1frqaeeKrSuvM9MQf7sWAAAAAAAAGBZWNM2j+rVqxtrqObKyspSYmKiateurXr16mn37t0Fhq3Ozs7y8fFRXFxcgX17eHhIktlLpQp7qdXXX39t/H3x4kWdPHlS/v7+kqSEhAR16tRJffv2Vf369VWtWjWdPHnS7HwbGxtlZ2cXOVZ/f3+zceb27evra7acwV+hOGMoSX5+fjpy5IgyMzONfXlfRidJVapUUY0aNVSjRg15eXndUf++vr564YUXtH37dnXp0kUrVqy4J3UXxM/PTz/99JN+/fVXY9+tYwEAAAAAAIBlIbTNw9HRUc8995zGjRunrVu36vjx4xoyZIiuXr2qQYMGaeTIkUpPT1fPnj21f/9+nTp1Sh988IHxAqrIyEjNmzdPb7zxhk6dOqVvv/3WeCGWvb29mjRpoqioKCUlJWnXrl2aNGlSgXVMmzZNcXFxOnr0qMLDw1WuXDl17txZ0s01S3fs2KGvvvpKSUlJevbZZ80COUny8fHRvn37lJKSot9//73AWZdjxoxRXFycpk+frpMnTyomJkaLFi267Uuv7oXijKEk9e7dWzk5ORo6dKiSkpK0bds2zZ07V9LNWax367///a9Gjhyp+Ph4nTlzRgkJCUpMTDQC+b9C27ZtVb16dT3zzDM6fPiwEhISjOfuz4wFAAAAAAAAfx1C21tERUWpa9eu6tevnwIDA3X69Glt27ZNZcqUUdmyZfXFF18oIyNDLVq0UFBQkJYuXWr8PP2ZZ57RggULtHjxYtWpU0cdO3bUqVOnjL6XL1+u69evKygoSBEREZoxY0ahNYwePVpBQUE6d+6cPvvsM9nY2EiSJk2apMDAQIWGhiokJESenp5GoJtr7NixsrKyUu3ateXh4aGzZ8/mu0ZgYKDWrFmj1atXq27dunrllVc0bdo0s5eQ/VWKM4aS5OLios8++0wHDx7Uww8/rJdfflmvvPKKJJmtc3unrKysdP78efXv31++vr7q3r272rdvr6lTp96r0gu85oYNG5SRkaFGjRpp8ODBevnllyX9ubEAAAAAAADgr2O6cbsFM3HfxMfHq2XLlrp48aLc3NxKuhzksXLlSg0YMECXL1++ozVsLVFCQoIeffRRnT592uylZ0VJT0+Xq6urvCPWqJTtnb307u8kJeqJki4BAAAAAAA8wHIzlsuXL8vFxaXQdryIDCjA+++/r2rVqsnLy0uHDh3SSy+9pO7du/8tA9v169fLyclJNWvW1OnTpzV69GgFBwcXO7AFAAAAAADA/cXyCLgrM2fOlJOTU4Fb+/btS7q8P+3cuXPq27ev/P399cILL6hbt2569913S7qsu/LHH39oxIgRqlWrlsLDw9WoUSN9+umnJV0WAAAAAAAACsHyCLgrFy5c0IULFwo8Zm9vLy8vr/tcEf5KLI8AAAAAAADw57E8Av5S7u7ucnd3L+kyAAAAAAAAgAcOyyMAAAAAAAAAgAUhtAUAAAAAAAAAC0JoCwAAAAAAAAAWhNAWAAAAAAAAACwIoS0AAAAAAAAAWBDrki4AwN/H0amhcnFxKekyAAAAAAAAHmjMtAUAAAAAAAAAC0JoCwAAAAAAAAAWhNAWAAAAAAAAACwIoS0AAAAAAAAAWBBCWwAAAAAAAACwIIS2AAAAAAAAAGBBCG0BAAAAAAAAwIJYl3QBAP4+6k7ZplK2DiVdxn2XEvVESZcAAAAAAAD+QZhpCwAAAAAAAAAWhNAWAAAAAAAAACwIoS0AAAAAAAAAWBBCWwAAAAAAAACwIIS2AAAAAAAAAGBBCG0BAAAAAAAAwIIQ2gIAAAAAAACABSG0BQAAAAAAAAALQmgLAAAAAAAAABaE0BYAAAAAAAAALAihLQAAAAAAAABYEEJbCxcfHy+TyaRLly6VdCn3TXR0tNzc3IzPkZGRevjhh0usnsKEhIQoIiKipMsAAAAAAADAA4bQ1oIUFAI2a9ZMqampcnV1vW91mEwmbdiwId/+8PBwde7c+b7VAQAAAAAAAPwTEdpaOBsbG3l6espkMpV0KX9rWVlZJV1Cibl27VpJlwAAAAAAAIA78MCEtpmZmRo1apTKly8vOzs7Pfroo0pMTDSOHzt2TB07dpSLi4ucnZ3VvHlzJScnG8eXL1+uOnXqyNbWVhUrVtTIkSMlSSkpKTKZTDp48KDR9tKlSzKZTIqPj5f0/0sYxMbGql69erKzs1OTJk109OhR45zz58+rV69e8vLykoODgwICAvThhx8ax8PDw7Vr1y4tXLhQJpNJJpNJKSkpBS6PsG7dOqNWHx8fzZs3z+xe+Pj4aObMmRo4cKCcnZ1VuXJlvfvuu/fiNpvZunWrHn30Ubm5uals2bLq2LGj2T3NvXeffPKJWrZsKQcHB9WvX1979+416yc6OlqVK1eWg4ODnnrqKZ0/f/62137vvffk7+8vOzs71apVS4sXL8533Y8++kgtWrSQnZ2dVq5cqTNnzigsLExlypSRo6Oj6tSpo82bNxd5nYSEBIWEhMjBwUFlypRRaGioLl68WGDbzMxMjR07Vl5eXnJ0dNQjjzxiPCPS7Z8B6eZs61GjRmn8+PFyd3eXp6enIiMjzdpcunRJgwcPloeHh1xcXNSqVSsdOnTIOJ67nMR7772nqlWrys7OTpK0du1aBQQEyN7eXmXLllWbNm105cqV295rAAAAAAAA3F8PTGg7fvx4rVu3TjExMfr2229Vo0YNhYaG6sKFC/r555/12GOPydbWVl988YUOHDiggQMH6vr165KkJUuWaMSIERo6dKiOHDmijRs3qkaNGndcw7hx4zRv3jwlJibKw8NDYWFhxgzP//3vfwoKClJsbKyOHj2qoUOHql+/fvrmm28kSQsXLlTTpk01ZMgQpaamKjU1Vd7e3vmuceDAAXXv3l09e/bUkSNHFBkZqcmTJys6Otqs3bx589SwYUN99913Gj58uJ577jmdOHHijsdUlCtXrujFF1/U/v37FRcXp1KlSumpp55STk6OWbuXX35ZY8eO1cGDB+Xr66tevXoZ937fvn0aNGiQRo4cqYMHD6ply5aaMWNGkddduXKlXnnlFb366qtKSkrSzJkzNXnyZMXExJi1mzBhgkaPHq2kpCSFhoZqxIgRyszM1JdffqkjR47otddek5OTU6HXOXjwoFq3bq3atWtr79692rNnj8LCwpSdnV1g+5EjR2rv3r1avXq1Dh8+rG7duqldu3Y6deqUpNs/A7liYmLk6Oioffv2afbs2Zo2bZp27NhhHO/WrZvS0tK0ZcsWHThwQIGBgWrdurUuXLhgtDl9+rTWrVunTz75RAcPHlRqaqp69eqlgQMHKikpSfHx8erSpYtu3LhR4FgyMzOVnp5utgEAAAAAAOD+MN0oLLX5G7ly5YrKlCmj6Oho9e7dW9LNn8P7+PgoIiJCFy9e1OrVq3XixAmVLl063/leXl4aMGBAgWFhSkqKqlatqu+++854GdalS5dUpkwZ7dy5UyEhIYqPj1fLli21evVq9ejRQ5J04cIFPfTQQ4qOjlb37t0LrLtjx46qVauW5s6dK+nmLMuHH35YCxYsMNrk9n3x4kW5ubmpT58++u2337R9+3ajzfjx4xUbG6tjx45JujnTtnnz5vrggw8kSTdu3JCnp6emTp2qYcOG3fZ+mkwm2dnZycrKymx/ZmamnnjiiQLXu5Wk33//XR4eHjpy5Ijq1q1r3Lv33ntPgwYNkiQdP35cderUUVJSkmrVqqXevXvr8uXLio2NNfrp2bOntm7daswujoyM1IYNG4zZzjVq1ND06dPVq1cv45wZM2Zo8+bN+uqrr4zrLliwQKNHjzba1KtXT127dtWUKVNuew8kqXfv3jp79qz27NlT4PG839fZs2dVrVo1nT17VpUqVTLatGnTRo0bN9bMmTML7KOgZyA7O1u7d+822jRu3FitWrVSVFSU9uzZoyeeeEJpaWmytbU12tSoUUPjx4/X0KFDFRkZqZkzZ+rnn3+Wh4eHJOnbb79VUFCQUlJSVKVKlduOPTIyUlOnTs233ztijUrZOtz2/AdNStQTJV0CAAAAAAB4AKSnp8vV1VWXL1+Wi4tLoe0eiJm2ycnJysrKUnBwsLGvdOnSaty4sZKSknTw4EE1b968wMA2LS1Nv/zyi1q3bv2n62jatKnxt7u7u/z8/JSUlCRJys7O1vTp0xUQECB3d3c5OTlp27ZtOnv27B1dIykpyWyckhQcHKxTp06ZzQCtV6+e8bfJZJKnp6fS0tKKfZ3XX39dBw8eNNuefPJJszanTp1Sr169VK1aNbm4uMjHx0eS8o0pby0VK1aUJKOWpKQkPfLII2bt897HW125ckXJyckaNGiQnJycjG3GjBlmSzNIUsOGDc0+jxo1SjNmzFBwcLCmTJmiw4cPG8fq1Klj9NW+fXtJ/z/TtjiOHDmi7Oxs+fr6mtW1a9cuo67iPgN575d0857l3q9Dhw4pIyNDZcuWNbvOjz/+aDb+KlWqGIGtJNWvX1+tW7dWQECAunXrpqVLlxa6zIMkTZw4UZcvXza2n376qVj3AQAAAAAAAH+edUkXcD/Y29vf1TFJKlXqZq6dd0Ly3bzUas6cOVq4cKEWLFiggIAAOTo6KiIi4i97SdStAbXJZMq3bEFRPD098y0R4ezsbLa2blhYmKpUqaKlS5eqUqVKysnJUd26dfONKW8tuS9Uu5Na8srIyJAkLV26NF/Ye+vMYEdHR7PPgwcPVmhoqGJjY7V9+3bNmjVL8+bN0/PPP6/Nmzcb32vuM3G7Z+PWuqysrHTgwIF8deQuwVDcZ6Co7y4jI0MVK1Y0Wys3l5ubW6Fjt7Ky0o4dO/TVV19p+/btevPNN/Xyyy9r3759qlq1ar6+bG1tzWbyAgAAAAAA4P55IGbaVq9eXTY2NkpISDD2ZWVlKTExUbVr11a9evW0e/fuAsNWZ2dn+fj4KC4ursC+c2crpqamGvvyvpQsr6+//tr4++LFizp58qT8/f0l3XyhVadOndS3b1/Vr19f1apV08mTJ83Ot7GxKXS91Fz+/v5m48zt29fXN19Y+Fc6f/68Tpw4oUmTJql169by9/cvcuZmYfz9/bVv3z6zfXnv460qVKigSpUq6YcfflCNGjXMtoLCx1t5e3tr2LBh+uSTTzRmzBgtXbpU0s2Zqbn9eHl5Sbo547Ww5+JWDRo0UHZ2ttLS0vLV5enpKal4z8DtBAYG6ty5c7K2ts53nXLlyhV5rslkUnBwsKZOnarvvvtONjY2Wr9+/R1dHwAAAAAAAH+9B2KmraOjo5577jmNGzdO7u7uqly5smbPnq2rV69q0KBBysnJ0ZtvvqmePXtq4sSJcnV11ddff63GjRvLz89PkZGRGjZsmMqXL6/27dvrjz/+UEJCgp5//nnZ29urSZMmioqKUtWqVZWWlqZJkyYVWMe0adNUtmxZVahQQS+//LLKlSunzp07S5Jq1qyptWvX6quvvlKZMmU0f/58/frrr6pdu7Zxvo+Pj/bt26eUlBQ5OTnJ3d093zXGjBmjRo0aafr06erRo4f27t2rRYsWafHixX/JvS1MmTJlVLZsWb377ruqWLGizp49qwkTJtxxP6NGjVJwcLDmzp2rTp06adu2bdq6dWuR50ydOlWjRo2Sq6ur2rVrp8zMTO3fv18XL17Uiy++WOh5ERERat++vXx9fXXx4kXt3LnTCNULMnHiRAUEBGj48OEaNmyYbGxstHPnTnXr1i1fQOrr66s+ffqof//+mjdvnho0aKDffvtNcXFxqlevnp544oliPQO306ZNGzVt2lSdO3fW7Nmz5evrq19++UWxsbF66qmn8i0JkWvfvn2Ki4vT448/rvLly2vfvn367bffihw/AAAAAAAASsYDMdNWkqKiotS1a1f169dPgYGBOn36tLZt22aEi1988YUyMjLUokULBQUFaenSpcbP0J955hktWLBAixcvVp06ddSxY0edOnXK6Hv58uW6fv26goKCFBERUeALy3JrGD16tIKCgnTu3Dl99tlnsrGxkSRNmjRJgYGBCg0NVUhIiDw9PY1AN9fYsWNlZWWl2rVry8PDo8D1bgMDA7VmzRqtXr1adevW1SuvvKJp06YpPDz83tzIYipVqpRWr16tAwcOqG7dunrhhRc0Z86cO+6nSZMmWrp0qRYuXKj69etr+/bthYbiuQYPHqz33ntPK1asUEBAgFq0aKHo6OjbzrTNzs7WiBEj5O/vr3bt2snX17fIsNvX11fbt2/XoUOH1LhxYzVt2lSffvqprK0L/m8dK1asUP/+/TVmzBj5+fmpc+fOSkxMVOXKlSUV7xm4HZPJpM2bN+uxxx7TgAED5Ovrq549e+rMmTOqUKFCoee5uLjoyy+/VIcOHeTr66tJkyZp3rx5xvq9AAAAAAAAsBymG3kXa8VdiY+PV8uWLXXx4kWzdUWBB0Xumw29I9aolK1DSZdz36VEPVHSJQAAAAAAgAdAbsZy+fJlubi4FNrugZlpCwAAAAAAAAAPAkLbf5iZM2fKycmpwI2fygMAAAAAAAAl74F4EVlJCwkJ0d9llYlhw4ape/fuBR6zt7e/z9UAAAAAAAAAuBWh7T+Mu7u73N3dS7oMAAAAAAAAAIVgeQQAAAAAAAAAsCCEtgAAAAAAAABgQQhtAQAAAAAAAMCCENoCAAAAAAAAgAUhtAUAAAAAAAAAC2Jd0gUA+Ps4OjVULi4uJV0GAAAAAADAA42ZtgAAAAAAAABgQQhtAQAAAAAAAMCCENoCAAAAAAAAgAUhtAUAAAAAAAAAC0JoCwAAAAAAAAAWhNAWAAAAAAAAACwIoS0AAAAAAAAAWBDrki4AwN9H3SnbVMrWoaTLKHEpUU+UdAkAAAAAAOABxkxbAAAAAAAAALAghLYAAAAAAAAAYEEIbQEAAAAAAADAghDaAgAAAAAAAIAFIbQFAAAAAAAAAAtCaAsAAAAAAAAAFoTQFgAAAAAAAAAsCKEtAAAAAAAAAFgQQlsAAAAAAAAAsCCEtgAAAAAAAABgQQhtAQAAAAAAAMCCENoCAAAAAAAAgAV54EJbHx8fLViwwGL6QdHCw8PVuXPnP9VHfHy8TCaTLl26dE9qAgAAAAAAAErSAxfaJiYmaujQocZnk8mkDRs23Pc67va69zssjo6Olslkkr+/f75jH3/8sUwmk3x8fP6y6y9cuFDR0dF/Wf+32rt3r6ysrPTEE0/kO5aSkiKTyZRv69u3732rDwAAAAAAALAu6QLulWvXrsnGxkYeHh4lXcrfjqOjo9LS0rR37141bdrU2L9s2TJVrlz5T/ef+93klZ2dLZPJJFdX1z/d/51YtmyZnn/+eS1btky//PKLKlWqlK/N559/rjp16hif7e3t72eJAAAAAAAA+Ie7LzNtQ0JC9PzzzysiIkJlypRRhQoVtHTpUl25ckUDBgyQs7OzatSooS1btki6GegNGjRIVatWlb29vfz8/LRw4UKzPnN/Vv/qq6+qUqVK8vPzk2Q+UzV3huhTTz1lNmM0OTlZnTp1UoUKFeTk5KRGjRrp888/v6MxXbt2TSNHjlTFihVlZ2enKlWqaNasWX/quiEhITpz5oxeeOEFY5anJEVGRurhhx82u/6CBQvMZsDGx8ercePGcnR0lJubm4KDg3XmzJlijcXa2lq9e/fW8uXLjX3/+c9/FB8fr969e5u1Lc698/Hx0fTp09W/f3+5uLho6NChio6OlpubmzZu3KjatWvL1tZWZ8+ezbc8Qk5OjmbNmmV89/Xr19fatWvN+t+8ebN8fX1lb2+vli1bKiUlpVjjzMjI0EcffaTnnntOTzzxRKEzfMuWLStPT09jKypYPnPmjMLCwlSmTBk5OjqqTp062rx5s6T/X7YhNjZW9erVk52dnZo0aaKjR4+a9bFu3TrVqVNHtra28vHx0bx588yOFzRr283Nzai/qGdRki5duqTBgwfLw8NDLi4uatWqlQ4dOlTkvcrMzFR6errZBgAAAAAAgPvjvi2PEBMTo3Llyumbb77R888/r+eee07dunVTs2bN9O233+rxxx9Xv379dPXqVeXk5Oihhx7Sxx9/rOPHj+uVV17Rv/71L61Zs8asz7i4OJ04cUI7duzQpk2b8l0zMTFRkrRixQqlpqYanzMyMtShQwfFxcXpu+++U7t27RQWFqazZ88WezxvvPGGNm7cqDVr1ujEiRNauXKlEaLe7XU/+eQTPfTQQ5o2bZpSU1OVmpparFquX7+uzp07q0WLFjp8+LD27t2roUOHGqFvcQwcOFBr1qzR1atXJd1cNqFdu3aqUKGCWbvi3ru5c+eqfv36+u677zR58mRJ0tWrV/Xaa6/pvffe07Fjx1S+fPl8dcyaNUvvv/++3n77bR07dkwvvPCC+vbtq127dkmSfvrpJ3Xp0kVhYWE6ePCgBg8erAkTJhRrjGvWrFGtWrXk5+envn37avny5bpx40ax71FBRowYoczMTH355Zc6cuSIXnvtNTk5OZm1GTdunObNm6fExER5eHgoLCxMWVlZkqQDBw6oe/fu6tmzp44cOaLIyEhNnjz5jpaMKOpZlKRu3bopLS1NW7Zs0YEDBxQYGKjWrVvrwoULhfY5a9Ysubq6Gpu3t/cd3RcAAAAAAADcvfu2PEL9+vU1adIkSdLEiRMVFRWlcuXKaciQIZKkV155RUuWLNHhw4fVpEkTTZ061Ti3atWq2rt3r9asWaPu3bsb+x0dHfXee+/l++l9rtylEtzc3OTp6WlWS/369Y3P06dP1/r167Vx40aNHDmyWOM5e/asatasqUcffVQmk0lVqlT509d1d3eXlZWVnJ2dzc67nfT0dF2+fFkdO3ZU9erVJanANWqL0qBBA1WrVk1r165Vv379FB0drfnz5+uHH34wa1fce9eqVSuNGTPG+Lx7925lZWVp8eLFZufnlZmZqZkzZ+rzzz83lmmoVq2a9uzZo3feeUctWrTQkiVLVL16dWM2qp+fnxGW3s6yZcuM9WnbtWuny5cva9euXQoJCTFr16xZM5Uq9f//PWP37t1q0KBBgX2ePXtWXbt2VUBAgFHvraZMmaK2bdtKuvkfLx566CGtX79e3bt31/z589W6dWsj2Pb19dXx48c1Z84chYeH33ZMuTUU9izu2bNH33zzjdLS0mRrayvpZqC+YcMGrV271mz957wmTpyoF1980ficnp5OcAsAAAAAAHCf3LeZtvXq1TP+trKyUtmyZY2gS5IxozMtLU2S9NZbbykoKEgeHh5ycnLSu+++m282Z0BAQKGBbVEyMjI0duxY+fv7y83NTU5OTkpKSip0pu2wYcPk5ORkbNLN5RkOHjwoPz8/jRo1Stu3b7/n1y0ud3d3hYeHKzQ0VGFhYVq4cGGxZ+nmNXDgQK1YsUK7du3SlStX1KFDh7seQ8OGDfOda2NjY/Yc3Or06dO6evWq2rZta3a/33//fSUnJ0uSkpKS9Mgjj5idl3cdXklm5w4bNkySdOLECX3zzTfq1auXpJtLQvTo0UPLli3LV8dHH32kgwcPGlvt2rUlSXXq1DH6bd++vSRp1KhRmjFjhoKDgzVlyhQdPnw4X39563N3d5efn5+SkpKM8QQHB5u1Dw4O1qlTp5SdnV3ovcqrqGfx0KFDysjIUNmyZc3uy48//mjc04LY2trKxcXFbAMAAAAAAMD9cd9m2pYuXdrss8lkMtuX+1P+nJwcrV69WmPHjtW8efPUtGlTOTs7a86cOdq3b59ZH46OjndVy9ixY7Vjxw7NnTtXNWrUkL29vZ5++mldu3atwPbTpk3T2LFjzfYFBgbqxx9/1JYtW/T555+re/fuatOmTb71V//MdXOVKlUq38/4c39en2vFihUaNWqUtm7dqo8++kiTJk3Sjh071KRJkyL7zqtPnz4aP368IiMj1a9fP1lb5388ijuGgr4be3v7IpdsyMjIkCTFxsbKy8vL7FjuLNHiOHjwoPF3bti4bNkyXb9+3ezFYzdu3JCtra0WLVpktm6tt7e3atSoka/fzZs3G/c99+VkgwcPVmhoqGJjY7V9+3bNmjVL8+bN0/PPP1/sem/HZDIV+f0X9SxmZGSoYsWKio+Pz9evm5vbPasRAAAAAAAA9859C23vREJCgpo1a6bhw4cb+4qaFViU0qVL55uxmJCQoPDwcD311FOSboaFRb3Mqnz58gWuv+ri4qIePXqoR48eevrpp9WuXTtduHBB7u7ud31dGxubfOd5eHjo3LlzunHjhhF65g0mczVo0EANGjTQxIkT1bRpU61ateqOQlt3d3c9+eSTWrNmjd5+++0C29zpvbsTeV9Q1qJFiwLb+Pv7a+PGjWb7vv76a7PPtwau169f1/vvv6958+bp8ccfNzvWuXNnffjhh8aM3KLkXXYgL29vbw0bNkzDhg3TxIkTtXTpUrPQ9uuvv1blypUlSRcvXtTJkyeN5Sv8/f2VkJBg1l9CQoJ8fX1lZWUl6eb3n3fm9KlTp4y1h3MV9iwGBgbq3Llzsra2NlvnFgAAAAAAAJbrvi2PcCdq1qyp/fv3a9u2bTp58qQmT55svMzrTvn4+CguLk7nzp3TxYsXjf4/+eQTHTx4UIcOHVLv3r2Vk5NzR/3Onz9fH374ob7//nudPHlSH3/8sTw9PY3Zi3d7XR8fH3355Zf6+eef9fvvv0uSQkJC9Ntvv2n27NlKTk7WW2+9pS1bthjn/Pjjj5o4caL27t2rM2fOaPv27Tp16tQdr2sr3XwB2e+//65atWoVePxe3LvCODs7a+zYsXrhhRcUExOj5ORkffvtt3rzzTcVExMj6eZSFadOndK4ceN04sQJrVq16rYv7dq0aZMuXryoQYMGqW7dumZb165dC1wiobgiIiK0bds2/fjjj/r222+1c+fOfPd92rRpiouL09GjRxUeHq5y5cqpc+fOkqQxY8YoLi5O06dP18mTJxUTE6NFixaZzexu1aqVFi1apO+++0779+/XsGHDzGapF/UstmnTRk2bNlXnzp21fft2paSk6KuvvtLLL7+s/fv33/W4AQAAAAAA8NexyND22WefVZcuXdSjRw898sgjOn/+vNms2zsxb9487dixQ97e3sbLpObPn68yZcqoWbNmCgsLU2hoqAIDA++oX2dnZ82ePVsNGzZUo0aNlJKSos2bNxsvsLrb606bNk0pKSmqXr268UIzf39/LV68WG+99Zbq16+vb775xizUc3Bw0Pfff6+uXbvK19dXQ4cO1YgRI/Tss8/e8f2yt7dX2bJlCz1+L+5dUaZPn67Jkydr1qxZ8vf3V7t27RQbG6uqVatKkipXrqx169Zpw4YNql+/vt5++23NnDmzyD6XLVumNm3amC2BkKtr167av39/gWvRFkd2drZGjBhh1Orr66vFixebtYmKitLo0aMVFBSkc+fO6bPPPjPWYg4MDNSaNWu0evVq1a1bV6+88oqmTZtm9hKyefPmydvbW82bN1fv3r01duxYOTg4GMeLehZNJpM2b96sxx57TAMGDJCvr6969uypM2fOGOtIAwAAAAAAwLKYbty6WCaAeyI+Pl4tW7bUxYsX//brx6anp8vV1VXeEWtUytbh9ic84FKinijpEgAAAAAAwN9QbsZy+fLlIl/8bpEzbQEAAAAAAADgn4rQ9gFXp04dOTk5FbitXLmypMsDAAAAAAAAcAvrki4Af63NmzcrKyurwGOsafrXCgkJEauPAAAAAAAA4E4R2j7gqlSpUtIlAAAAAAAAALgDLI8AAAAAAAAAABaE0BYAAAAAAAAALAihLQAAAAAAAABYEEJbAAAAAAAAALAgvIgMQLEdnRoqFxeXki4DAAAAAADggcZMWwAAAAAAAACwIIS2AAAAAAAAAGBBCG0BAAAAAAAAwIIQ2gIAAAAAAACABSG0BQAAAAAAAAALQmgLAAAAAAAAABaE0BYAAAAAAAAALAihLQAAAAAAAABYEOuSLgDA30fdKdtUytahpMuwCClRT5R0CQAAAAAA4AHFTFsAAAAAAAAAsCCEtgAAAAAAAABgQQhtAQAAAAAAAMCCENoCAAAAAAAAgAUhtAUAAAAAAAAAC0JoCwAAAAAAAAAWhNAWAAAAAAAAACwIoS0AAAAAAAAAWBBCWwAAAAAAAACwIIS2AAAAAAAAAGBBCG0BAAAAAAAAwIIQ2j4gQkJCFBERYTH9FFdkZKQefvjhItvc75osyd3cHx8fHy1YsKDIc0wmkzZs2PCn6wMAAAAAAMC9Z13SBaBkxMfHq2XLlrp48aLc3NyM/Z988olKly5dcoUV4K+o6auvvtKMGTO0d+9e/fe//1XNmjU1YMAAjR49WlZWVvf0Wn81S/zOAAAAAAAAcPeYafs3cO3atft2LXd3dzk7O9+36xXHva5p/fr1atGihR566CHt3LlT33//vUaPHq0ZM2aoZ8+eunHjxj271v1gid8ZAAAAAAAA7h6hrQUKCQnRyJEjFRERoXLlyik0NFRHjx5V+/bt5eTkpAoVKqhfv376/fffC+3jgw8+UMOGDeXs7CxPT0/17t1baWlpkqSUlBS1bNlSklSmTBmZTCaFh4cb1877U/uLFy+qf//+KlOmjBwcHNS+fXudOnXKOB4dHS03Nzdt27ZN/v7+cnJyUrt27ZSammq0iY+PV+PGjeXo6Cg3NzcFBwfrzJkz+er18fGRq6urevbsqT/++MPsftz68//p06erV69ecnR0lJeXl956661i3dsrV65oyJAhevLJJ/Xuu+/q4Ycflo+PjwYPHqyYmBitXbtWa9askSQ9/fTTGjlypHFuRESETCaTvv/+e0k3w3RHR0d9/vnnRp2jRo3S+PHj5e7uLk9PT0VGRt62pv/85z/q1auX3N3d5ejoqIYNG2rfvn13fX9uderUKT322GOys7NT7dq1tWPHjtvWlJmZqfT0dLMNAAAAAAAA9wehrYWKiYmRjY2NEhISFBUVpVatWqlBgwbav3+/tm7dql9//VXdu3cv9PysrCxNnz5dhw4d0oYNG5SSkmIEs97e3lq3bp0k6cSJE0pNTdXChQsL7Cc8PFz79+/Xxo0btXfvXt24cUMdOnRQVlaW0ebq1auaO3euPvjgA3355Zc6e/asxo4dK0m6fv26OnfurBYtWujw4cPau3evhg4dKpPJZJyfnJysDRs2aNOmTdq0aZN27dqlqKioIu/PnDlzVL9+fX333XeaMGGCRo8eXawwcvv27Tp//rxRX15hYWHy9fXVhx9+KElq0aKF4uPjjeO7du1SuXLljH2JiYnKyspSs2bNjDYxMTFydHTUvn37NHv2bE2bNq3IujIyMtSiRQv9/PPP2rhxow4dOqTx48crJyfnT92fXDk5OerSpYtsbGy0b98+vf3223rppZdue96sWbPk6upqbN7e3sW6HgAAAAAAAP481rS1UDVr1tTs2bMlSTNmzFCDBg00c+ZM4/jy5cvl7e2tkydPytfXN9/5AwcONP6uVq2a3njjDTVq1EgZGRlycnKSu7u7JKl8+fJma9rmderUKW3cuFEJCQlGMLly5Up5e3trw4YN6tatm6SbAfHbb7+t6tWrS5JGjhypadOmSZLS09N1+fJldezY0Tju7+9vdp2cnBxFR0cbP/Hv16+f4uLi9OqrrxZ6f4KDgzVhwgRJkq+vrxISEvT666+rbdu2hZ4jSSdPniywhly1atUy2oSEhGj06NH67bffZG1trePHj2vy5MmKj4/XsGHDFB8fr0aNGsnBwcE4v169epoyZYqkm9/hokWLFBcXV2hdq1at0m+//abExETjO6lRo8afvj+5Pv/8c33//ffatm2bKlWqJEmaOXOm2rdvX+R5EydO1Isvvmh8Tk9PJ7gFAAAAAAC4T5hpa6GCgoKMvw8dOqSdO3fKycnJ2GrVqiXp5izMghw4cEBhYWGqXLmynJ2d1aJFC0nS2bNni11DUlKSrK2t9cgjjxj7ypYtKz8/PyUlJRn7HBwcjEBWkipWrGgsxeDu7q7w8HCFhoYqLCxMCxcuNFs6Qbq53EHeNVnznl+Ypk2b5vuct6bbKc66tXXr1pW7u7t27dql3bt3q0GDBurYsaN27dol6ebM25CQELNz6tWrZ/Y571iGDRtm9h1K0sGDB9WgQQMjsC3I3dyfXElJSfL29jYCWyn/vSuIra2tXFxczDYAAAAAAADcH4S2FsrR0dH4OyMjQ2FhYTp48KDZlrtW6a2uXLmi0NBQubi4aOXKlUpMTNT69esl/TUvNStdurTZZ5PJZBaKrlixQnv37lWzZs300UcfydfXV19//XWR5+ddHuBeyp2VXFjAm5SUZLQxmUx67LHHFB8fbwS09erVU2Zmpo4ePaqvvvrKCMNzFTWWadOmmX1/kmRvb3/bmu/n/QEAAAAAAEDJI7T9GwgMDNSxY8fk4+OjGjVqmG15w91c33//vc6fP6+oqCg1b95ctWrVyjcz08bGRpKUnZ1d6HX9/f11/fp1s5dinT9/XidOnFDt2rXvaAwNGjTQxIkT9dVXX6lu3bpatWrVHZ1/q7yhb+7nwpY8yOvxxx+Xu7u75s2bl+/Yxo0bderUKfXq1cvYl7uubXx8vEJCQlSqVCk99thjmjNnjjIzMxUcHFzsmsuXL2/23Uk3Z+YePHhQFy5cKHY/d8Lf318//fST2ezmW+8dAAAAAAAALAuh7d/AiBEjdOHCBfXq1UuJiYlKTk7Wtm3bNGDAgAJD18qVK8vGxkZvvvmmfvjhB23cuFHTp083a1OlShWZTCZt2rRJv/32mzIyMvL1U7NmTXXq1ElDhgzRnj17dOjQIfXt21deXl7q1KlTsWr/8ccfNXHiRO3du1dnzpzR9u3bderUqWIFrEVJSEjQ7NmzdfLkSb311lv6+OOPNXr06Nue5+joqHfeeUeffvqphg4dqsOHDyslJUXLli1TeHi4nn76abMXvIWEhOj48eM6duyYHn30UWPfypUr1bBhwwJD8zvRq1cveXp6qnPnzkpISNAPP/ygdevWae/evX+q31xt2rSRr6+vnnnmGR06dEi7d+/Wyy+/fE/6BgAAAAAAwF+D0PZvoFKlSkpISFB2drYef/xxBQQEKCIiQm5ubipVKv9X6OHhoejoaH388ceqXbu2oqKiNHfuXLM2Xl5emjp1qiZMmKAKFSpo5MiRBV57xYoVCgoKUseOHdW0aVPduHFDmzdvzveT/cI4ODjo+++/V9euXeXr66uhQ4dqxIgRevbZZ+/8RuQxZswY7d+/Xw0aNNCMGTM0f/58hYaGFuvcp59+Wjt37tTZs2fVvHlz+fn56fXXX9fLL7+s1atXy2QyGW0DAgLk5uamhx9+2FiHNiQkRNnZ2fnWs70bNjY22r59u8qXL68OHTooICBAUVFRsrKy+tN9S1KpUqW0fv16/fe//1Xjxo01ePDgYr3ADAAAAAAAACXHdKM4b2QCLIiPj48iIiIUERFR0qX8Y6Snp8vV1VXeEWtUytahpMuxCClRT5R0CQAAAAAA4G8mN2O5fPlykS9+Z6YtAAAAAAAAAFgQQls8UFauXCknJ6cCtzp16pR0eQAAAAAAAMBtWZd0AcCdSklJKfTYk08+qUceeaTAY8VdhxcAAAAAAAAoSYS2eKA4OzvL2dm5pMsAAAAAAAAA7hrLIwAAAAAAAACABSG0BQAAAAAAAAALQmgLAAAAAAAAABaE0BYAAAAAAAAALAihLQAAAAAAAABYEOuSLgDA38fRqaFycXEp6TIAAAAAAAAeaMy0BQAAAAAAAAALQmgLAAAAAAAAABaE0BYAAAAAAAAALAihLQAAAAAAAABYEEJbAAAAAAAAALAghLYAAAAAAAAAYEEIbQEAAAAAAADAgliXdAEA/j7qTtmmUrYOJV3G31ZK1BMlXQIAAAAAAPgbYKYtAAAAAAAAAFgQQlsAAAAAAAAAsCCEtgAAAAAAAABgQQhtAQAAAAAAAMCCENoCAAAAAAAAgAUhtAUAAAAAAAAAC0JoCwAAAAAAAAAWhNAWAAAAAAAAACwIoS0AAAAAAAAAWBBCWwAAAAAAAACwIIS2AAAAAAAAAGBBCG1RpPj4eJlMJl26dKmkSym2kJAQRURElHQZf5mUlBSZTCYdPHiwpEsBAAAAAADAX4DQFoaCws5mzZopNTVVrq6u97WWTZs2qUWLFnJ2dpaDg4MaNWqk6OhoszZ/x0D5XvD29lZqaqrq1q1b0qUAAAAAAADgL0BoiyLZ2NjI09NTJpPpvl3zzTffVKdOnRQcHKx9+/bp8OHD6tmzp4YNG6axY8fetzryunbt2n25TlZW1m3bWFlZydPTU9bW1vehIgAAAAAAANxvhLb3SGZmpkaNGqXy5cvLzs5Ojz76qBITE43jx44dU8eOHeXi4iJnZ2c1b95cycnJxvHly5erTp06srW1VcWKFTVy5EhJBf8U/tKlSzKZTIqPj5f0/zNOY2NjVa9ePdnZ2alJkyY6evSocc758+fVq1cveXl5ycHBQQEBAfrwww+N4+Hh4dq1a5cWLlwok8kkk8mklJSUAmezrlu3zqjVx8dH8+bNM7sXPj4+mjlzpgYOHChnZ2dVrlxZ7777brHu408//aQxY8YoIiJCM2fOVO3atVWjRg2NGTNGc+bM0bx587Rv3z6lpKSoZcuWkqQyZcrIZDIpPDzc6CcnJ0fjx4+Xu7u7PD09FRkZaXadS5cuafDgwfLw8JCLi4tatWqlQ4cOGccjIyP18MMP67333lPVqlVlZ2dXYL1r165VQECA7O3tVbZsWbVp00ZXrlwxjr/33nvy9/eXnZ2datWqpcWLFxvHcr/bjz76SC1atJCdnZ2WLFkie3t7bdmyxew669evl7Ozs65evVrgM3G756uoOgqSmZmp9PR0sw0AAAAAAAD3B6HtPTJ+/HitW7dOMTEx+vbbb1WjRg2FhobqwoUL+vnnn/XYY4/J1tZWX3zxhQ4cOKCBAwfq+vXrkqQlS5ZoxIgRGjp0qI4cOaKNGzeqRo0ad1zDuHHjNG/ePCUmJsrDw0NhYWHGzM3//e9/CgoKUmxsrI4ePaqhQ4eqX79++uabbyRJCxcuVNOmTTVkyBClpqYqNTVV3t7e+a5x4MABde/eXT179tSRI0cUGRmpyZMn51u6YN68eWrYsKG+++47DR8+XM8995xOnDhx2zGsXbtWWVlZBc6offbZZ+Xk5KQPP/xQ3t7eWrdunSTpxIkTSk1N1cKFC422MTExcnR01L59+zR79mxNmzZNO3bsMI5369ZNaWlp2rJliw4cOKDAwEC1bt1aFy5cMNqcPn1a69at0yeffFLg+rGpqanq1auXBg4cqKSkJMXHx6tLly66ceOGJGnlypV65ZVX9OqrryopKUkzZ87U5MmTFRMTY9bPhAkTNHr0aCUlJalbt27q2LGjVq1aZdZm5cqV6ty5sxwcHPLVcbvnq7h15DVr1iy5uroaW0HPAgAAAAAAAP4a/L76Hrhy5YqWLFmi6OhotW/fXpK0dOlS7dixQ8uWLdPFixfl6uqq1atXq3Tp0pIkX19f4/wZM2ZozJgxGj16tLGvUaNGd1zHlClT1LZtW0k3Q8uHHnpI69evV/fu3eXl5WUWhD7//PPatm2b1qxZo8aNG8vV1VU2NjZycHCQp6dnodeYP3++WrdurcmTJxvjOH78uObMmWM207VDhw4aPny4JOmll17S66+/rp07d8rPz6/IMZw8eVKurq6qWLFivmM2NjaqVq2aTp48KSsrK7m7u0uSypcvLzc3N7O29erV05QpUyRJNWvW1KJFixQXF6e2bdtqz549+uabb5SWliZbW1tJ0ty5c7VhwwatXbtWQ4cOlXRzSYT3339fHh4eBdaampqq69evq0uXLqpSpYokKSAgwDg+ZcoUzZs3T126dJEkVa1aVcePH9c777yjZ555xmgXERFhtJGkPn36qF+/frp69aocHByUnp6u2NhYrV+/vsA63nrrrSKfr+LWkdfEiRP14osvGp/T09MJbgEAAAAAAO4TQtt7IDk5WVlZWQoODjb2lS5dWo0bN1ZSUpLOnTun5s2bG4FaXmlpafrll1/UunXrP11H06ZNjb/d3d3l5+enpKQkSVJ2drZmzpypNWvW6Oeff9a1a9eUmZlZ4MzNoiQlJalTp05m+4KDg7VgwQJlZ2fLyspK0s3QNJfJZJKnp6fS0tLudmh3LO/1JalixYrG9Q8dOqSMjAyVLVvWrM1///tfsyUFqlSpYgS2u3fvNgJ5SXrnnXfUs2dPtW7dWgEBAQoNDdXjjz+up59+WmXKlNGVK1eUnJysQYMGaciQIcZ5169fz/dSt4YNG5p97tChg0qXLq2NGzeqZ8+eWrdunVxcXNSmTZsCx3rw4MFCn687qSMvW1tbI9AGAAAAAADA/UVoex/Y29vf1TFJKlXq5goWuT+5l4r3sqpbzZkzRwsXLtSCBQsUEBAgR0dHRURE/GUv2Lo1QDSZTMrJybnteb6+vrp8+bJ++eUXVapUyezYtWvXlJycbKxle7fXz8jIUMWKFY01gfPKO2PX0dHR+Lthw4ZmSyRUqFBBVlZW2rFjh7766itt375db775pl5++WXt27fPCMOXLl2qRx55xOwaucF2QdeRbs4ofvrpp7Vq1Sr17NlTq1atUo8ePQp98VhRz1BGRkax6wAAAAAAAIBlYE3be6B69eqysbFRQkKCsS8rK0uJiYmqXbu26tWrp927dxcYtjo7O8vHx0dxcXEF9p070zM1NdXYV9D6qpL09ddfG39fvHhRJ0+elL+/vyQpISFBnTp1Ut++fVW/fn1jmYG8bGxslJ2dXeRY/f39zcaZ27evr+89CQG7du2q0qVL53u5mSS9/fbbunLlinr16mXUK+m2Nd8qMDBQ586dk7W1tWrUqGG2lStXrsBz7O3tzdo5OztLuhkGBwcHa+rUqfruu+9kY2Oj9evXq0KFCqpUqZJ++OGHfNeoWrXqbWvs06ePtm7dqmPHjumLL75Qnz59Cm1b1PP1Z+sAAAAAAADA/cdM23vA0dFRzz33nMaNGyd3d3dVrlxZs2fP1tWrVzVo0CDl5OTozTffVM+ePTVx4kS5urrq66+/VuPGjeXn56fIyEgNGzZM5cuXV/v27fXHH38oISFBzz//vOzt7dWkSRNFRUWpatWqSktL06RJkwqsY9q0aSpbtqwqVKigl19+WeXKlVPnzp0l3VzXde3atfrqq69UpkwZzZ8/X7/++qtq165tnO/j46N9+/YpJSVFTk5OxpqxeY0ZM0aNGjXS9OnT1aNHD+3du1eLFi3S4sWL78m9zL13Y8aMkZ2dnfr166fSpUvr008/1b/+9S+NGTPGmDFapUoVmUwmbdq0SR06dJC9vb2cnJxue402bdqoadOm6ty5s2bPni1fX1/98ssvio2N1VNPPZVvuYLC7Nu3T3FxcXr88cdVvnx57du3T7/99psRlE+dOlWjRo2Sq6ur2rVrp8zMTO3fv18XL140Wy+2II899pg8PT3Vp08fVa1aNd8s2bxGjhxZ5PP1Z+oAAAAAAADA/cdM23skKipKXbt2Vb9+/RQYGKjTp09r27ZtKlOmjMqWLasvvvhCGRkZatGihYKCgrR06VLjJ/zPPPOMFixYoMWLF6tOnTrq2LGjTp06ZfS9fPlyXb9+XUFBQYqIiNCMGTMKrWH06NEKCgrSuXPn9NlnnxmzUSdNmqTAwECFhoYqJCREnp6eRqCba+zYsbKyslLt2rXl4eGhs2fP5rtGYGCg1qxZo9WrV6tu3bp65ZVXNG3aNLOXkP1ZERERWr9+vXbv3q2GDRuqbt26WrVqlZYsWaK5c+ca7by8/q+9O4+v6dr/P/4+IYlEBlTMIQkSMYWarqFoucZSVJO2rqHmhrpVMd0W0SmosWqqtoKrjaBm1ZJKaiztpVUzFUGVUhKEIGf//vDL+TpNkJBh09fz8TiPm7P32mt/1j7Zdc/bsnZpjR07ViNGjFDx4sU1cODATPVvsVi0bt06NW7cWK+88or8/f314osv6sSJEypevHim6/Tw8NB3332nNm3ayN/fX2+99ZYmTZpkW/u2d+/e+uSTTzRv3jxVq1ZNTZo0UWRkZKZmuFosFr300kv66aef7jnLVtJ9f78epg4AAAAAAADkPotx52KpeCTFxsbq6aef1sWLF+3WZAWyS1JSkjw9PeX9erQcnLP28Dr8n/hxbfO6BAAAAAAAkIfSMpbExER5eHjctR0zbQEAAAAAAADARAhtkavef/99ubm5ZfhKW1YAAAAAAAAA+DvjQWSPgaZNm+pRWeWif//+Cg4OznCfi4tLLlcDAAAAAAAAmA+hLXJVkSJFVKRIkbwuAwAAAAAAADAtlkcAAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAE8mf1wUAeHT8MralPDw88roMAAAAAACAxxozbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARPLndQEAHh1Vx3wtB2fXvC4DDyh+XNu8LgEAAAAAAGQCM20BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtgSzo0aOHOnTokCv9+Pj4aOrUqQ99LgAAAAAAADxa8ud1AcCjZNq0aTIMw/a+adOmqlGjBuEqAAAAAAAAsg2hLZAFnp6eeV0CAAAAAAAAHnMsj4DHitVq1YQJE1ShQgU5OzurbNmyeu+99yRJw4cPl7+/v1xdXeXn56dRo0bp5s2btmPDw8NVo0YNzZkzR97e3nJ1dVVwcLASExNtbe5c1qBHjx6Ki4vTtGnTZLFYZLFYFB8fr9TUVPXq1Uu+vr5ycXFRQECApk2b9tBjS0hI0HPPPSc3Nzd5eHgoODhYZ8+ete3/6aef9PTTT8vd3V0eHh6qVauWfvjhB0nSiRMn1K5dOxUuXFgFCxZUlSpVtG7duoeuCQAAAAAAANmPmbZ4rIwcOVJz587VlClT1KhRI505c0YHDx6UJLm7uysyMlKlSpXS3r171adPH7m7u2vYsGG2448eParo6GitXr1aSUlJ6tWrl0JDQ7Vo0aJ055o2bZoOHz6sqlWr6u2335YkeXl5yWq1qkyZMlqyZImeeOIJbdu2TX379lXJkiUVHBz8QOOyWq22wDYuLk63bt3SgAEDFBISotjYWElSly5dVLNmTc2aNUv58uXTnj175OjoKEkaMGCAbty4oe+++04FCxbU/v375ebmdtfzpaSkKCUlxfY+KSnpgeoGAAAAAABA1hHa4rFx+fJlTZs2TR999JG6d+8uSSpfvrwaNWokSXrrrbdsbX18fBQWFqaoqCi70Pb69etasGCBSpcuLUmaPn262rZtq0mTJqlEiRJ25/P09JSTk5NcXV3t9uXLl09jx461vff19dX27dsVHR39wKFtTEyM9u7dq+PHj8vb21uStGDBAlWpUkW7du1SnTp1lJCQoKFDh6pSpUqSpIoVK9qOT0hI0PPPP69q1apJkvz8/O55voiICLsxAAAAAAAAIPewPAIeGwcOHFBKSoqaNWuW4f7FixerYcOGKlGihNzc3PTWW28pISHBrk3ZsmVtga0k1a9fX1arVYcOHcpSLTNmzFCtWrXk5eUlNzc3ffzxx+nOlWbRokVyc3OzvTZv3pzh2Ly9vW2BrSRVrlxZhQoV0oEDByRJb7zxhnr37q3mzZtr3LhxOnbsmK3toEGD9O6776phw4YaM2aMfv7553vWP3LkSCUmJtpeJ0+ezNL4AQAAAAAA8OAIbfHYcHFxueu+7du3q0uXLmrTpo3WrFmj3bt3680339SNGzeyvY6oqCiFhYWpV69e+uabb7Rnzx698sordz1X+/bttWfPHturdu3aD3Te8PBw7du3T23bttW3336rypUra/ny5ZKk3r1769dff1XXrl21d+9e1a5dW9OnT79rX87OzvLw8LB7AQAAAAAAIHcQ2uKxUbFiRbm4uCgmJibdvm3btqlcuXJ68803Vbt2bVWsWFEnTpxI1y4hIUG//fab7f2OHTvk4OCggICADM/p5OSk1NRUu21bt25VgwYNFBoaqpo1a6pChQp2s17/yt3dXRUqVLC9MgqfAwMDdfLkSbsZr/v379elS5dUuXJl2zZ/f38NHjxY33zzjTp16qR58+bZ9nl7e6t///768ssvNWTIEM2dO/euNQEAAAAAACDvsKYtHhsFChTQ8OHDNWzYMDk5Oalhw4b6448/tG/fPlWsWFEJCQmKiopSnTp1tHbtWtss1L/20b17d02cOFFJSUkaNGiQgoOD061nm8bHx0fff/+94uPj5ebmpiJFiqhixYpasGCBvv76a/n6+mrhwoXatWuXfH19H3hszZs3V7Vq1dSlSxdNnTpVt27dUmhoqJo0aaLatWvr2rVrGjp0qDp37ixfX1+dOnVKu3bt0vPPPy9Jev3119W6dWv5+/vr4sWL2rRpkwIDAx+4HgAAAAAAAOQcZtrisTJq1CgNGTJEo0ePVmBgoEJCQnTu3Dm1b99egwcP1sCBA1WjRg1t27ZNo0aNSnd8hQoV1KlTJ7Vp00YtWrRQ9erVNXPmzLueLywsTPny5VPlypXl5eWlhIQE9evXT506dVJISIjq1aunCxcuKDQ09KHGZbFYtHLlShUuXFiNGzdW8+bN5efnp8WLF0u6/fCzCxcuqFu3bvL391dwcLBat25te5hYamqqBgwYoMDAQLVq1Ur+/v73HBcAAAAAAADyjsUwDCOviwDMIDw8XCtWrNCePXvyuhTTSUpKkqenp7xfj5aDs2tel4MHFD+ubV6XAAAAAADA31paxpKYmHjPZwgx0xYAAAAAAAAATITQFgAAAAAAAABMhNAW+P/Cw8NZGgEAAAAAAAB5jtAWAAAAAAAAAEyE0BYAAAAAAAAATITQFgAAAAAAAABMhNAWAAAAAAAAAEyE0BYAAAAAAAAATITQFgAAAAAAAABMJH9eFwDg0fHL2Jby8PDI6zIAAAAAAAAea8y0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATyZ/XBQB4dFQd87UcnF3zugzggcSPa5vXJQAAAAAAkCnMtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbSFKcXGxspisejSpUt5XYp8fHw0derUvC4DAAAAAAAAfxOEtsD/FxkZqUKFCqXbvmvXLvXt2zf3CwIAAAAAAMDfUv68LgAwOy8vr7wuAQAAAAAAAH8jzLRFrrBarYqIiJCvr69cXFwUFBSkpUuX2vavW7dO/v7+cnFx0dNPP634+Hi748PDw1WjRg27bVOnTpWPj4/dts8++0xVqlSRs7OzSpYsqYEDB9r2TZ48WdWqVVPBggXl7e2t0NBQXblyRdLt5RheeeUVJSYmymKxyGKxKDw8XFL65RESEhL03HPPyc3NTR4eHgoODtbZs2fT1bpw4UL5+PjI09NTL774oi5fvnzPa+Tj46P3339fPXv2lLu7u8qWLauPP/7Ytj+jJSP27Nkji8Viu15ps4XXrFmjgIAAubq6qnPnzkpOTtb8+fPl4+OjwoULa9CgQUpNTb1nPQAAAAAAAMgbhLbIFREREVqwYIFmz56tffv2afDgwfrXv/6luLg4nTx5Up06dVK7du20Z88e9e7dWyNGjMjyOWbNmqUBAwaob9++2rt3r1atWqUKFSrY9js4OOjDDz/Uvn37NH/+fH377bcaNmyYJKlBgwaaOnWqPDw8dObMGZ05c0ZhYWHpzmG1WvXcc8/pzz//VFxcnDZs2KBff/1VISEhdu2OHTumFStWaM2aNVqzZo3i4uI0bty4+45h0qRJql27tnbv3q3Q0FC9+uqrOnToUJauQ3Jysj788ENFRUVp/fr1io2NVceOHbVu3TqtW7dOCxcu1Jw5c+xC879KSUlRUlKS3QsAAAAAAAC5g+URkONSUlL0/vvva+PGjapfv74kyc/PT1u2bNGcOXPk4+Oj8uXLa9KkSZKkgIAA7d27V+PHj8/Sed59910NGTJE//73v23b6tSpY/v59ddft/3s4+Ojd999V/3799fMmTPl5OQkT09PWSwWlShR4q7niImJ0d69e3X8+HF5e3tLkhYsWKAqVapo165dtvNZrVZFRkbK3d1dktS1a1fFxMTovffeu+cY2rRpo9DQUEnS8OHDNWXKFG3atEkBAQGZvg43b97UrFmzVL58eUlS586dtXDhQp09e1Zubm6qXLmynn76aW3atCld2JwmIiJCY8eOzfQ5AQAAAAAAkH2YaYscd/ToUSUnJ+uf//yn3NzcbK8FCxbo2LFjOnDggOrVq2d3TFq4m1nnzp3Tb7/9pmbNmt21zcaNG9WsWTOVLl1a7u7u6tq1qy5cuKDk5ORMn+fAgQPy9va2BbaSVLlyZRUqVEgHDhywbfPx8bEFtpJUsmRJnTt3TpK0aNEiu+uwefNmW7vq1avbfk4LkNOOyyxXV1dbYCtJxYsXl4+Pj9zc3Oy23avfkSNHKjEx0fY6efJklmoAAAAAAADAg2OmLXJc2rqxa9euVenSpe32OTs7a9CgQfftw8HBQYZh2G27efOm7WcXF5d7Hh8fH69nn31Wr776qt577z0VKVJEW7ZsUa9evXTjxg25urpmdjiZ4ujoaPfeYrHIarVKktq3b28XUt95Te51nIPD7b9jufM63HkN7tXHvfrNiLOzs5ydne+6HwAAAAAAADmH0BY5rnLlynJ2dlZCQoKaNGmSbn9gYKBWrVplt23Hjh127728vPT777/LMAxZLBZJtx/Clcbd3V0+Pj6KiYnR008/ne4cP/74o6xWqyZNmmQLP6Ojo+3aODk53ffhXIGBgTp58qROnjxpm227f/9+Xbp0SZUrV77nsXfWeucs3Mzy8vKSJJ05c0aFCxeWZH8NAAAAAAAA8HggtEWOc3d3V1hYmAYPHiyr1apGjRopMTFRW7dulYeHh/r3769JkyZp6NCh6t27t3788UdFRkba9dG0aVP98ccfmjBhgjp37qz169frq6++koeHh61NeHi4+vfvr2LFiql169a6fPmytm7dqtdee00VKlTQzZs3NX36dLVr105bt27V7Nmz7c7h4+OjK1euKCYmRkFBQXJ1dU03A7d58+aqVq2aunTpoqlTp+rWrVsKDQ1VkyZNVHXbK9QAADAvSURBVLt27Ry7hpJUoUIFeXt7Kzw8XO+9954OHz5sWwcYAAAAAAAAjw/WtEWueOeddzRq1ChFREQoMDBQrVq10tq1a+Xr66uyZctq2bJlWrFihYKCgjR79my9//77dscHBgZq5syZmjFjhoKCgrRz506FhYXZtenevbumTp2qmTNnqkqVKnr22Wd15MgRSVJQUJAmT56s8ePHq2rVqlq0aJEiIiLsjm/QoIH69++vkJAQeXl5acKECenGYbFYtHLlShUuXFiNGzdW8+bN5efnp8WLF2fzFUvP0dFRX3zxhQ4ePKjq1atr/Pjxevfdd3P8vAAAAAAAAMhdFuOvC4UCwF8kJSXJ09NT3q9Hy8E5e9f/BXJL/Li2eV0CAAAAAOBvLi1jSUxMtPsX5H/FTFsAAAAAAAAAMBFCWwAAAAAAAAAwEUJbAAAAAAAAADARQlsAAAAAAAAAMBFCWwAAAAAAAAAwEUJbAAAAAAAAADARQlsAAAAAAAAAMBFCWwAAAAAAAAAwEUJbAAAAAAAAADCR/HldAIBHxy9jW8rDwyOvywAAAAAAAHisMdMWAAAAAAAAAEyE0BYAAAAAAAAATITQFgAAAAAAAABMhNAWAAAAAAAAAEyE0BYAAAAAAAAATITQFgAAAAAAAABMhNAWAAAAAAAAAEyE0BYAAAAAAAAATCR/XhcA4NFRdczXcnB2zesyAAD3ET+ubV6XAAAAAOAhMNMWAAAAAAAAAEyE0BYAAAAAAAAATITQFgAAAAAAAABMhNAWAAAAAAAAAEyE0BYAAAAAAAAATITQFgAAAAAAAABMhNAWAAAAAAAAAEyE0BYAAAAAAAAATITQFgAAAAAAAABMhNAWAAAAAAAAAEyE0BYAAAAAAAAATITQFriPHj16qEOHDqbp534iIyNVqFChHD8PAAAAAAAAckb+vC4AMLtp06bJMAzb+6ZNm6pGjRqaOnVq3hV1DyEhIWrTpk1elwEAAAAAAIAHRGgL3Ienp2del5AlLi4ucnFxyesyAAAAAAAA8IBYHgGPPKvVqgkTJqhChQpydnZW2bJl9d5770mShg8fLn9/f7m6usrPz0+jRo3SzZs3bceGh4erRo0amjNnjry9veXq6qrg4GAlJiba2ty5rEGPHj0UFxenadOmyWKxyGKxKD4+XqmpqerVq5d8fX3l4uKigIAATZs2LctjOXPmjNq2bSsXFxf5+vrq888/l4+Pj92s3smTJ6tatWoqWLCgvL29FRoaqitXrtj2/3V5hLQxLly4UD4+PvL09NSLL76oy5cv37WOlJQUJSUl2b0AAAAAAACQOwht8cgbOXKkxo0bp1GjRmn//v36/PPPVbx4cUmSu7u7IiMjtX//fk2bNk1z587VlClT7I4/evSooqOjtXr1aq1fv167d+9WaGhohueaNm2a6tevrz59+ujMmTM6c+aMvL29ZbVaVaZMGS1ZskT79+/X6NGj9Z///EfR0dFZGku3bt3022+/KTY2VsuWLdPHH3+sc+fO2bVxcHDQhx9+qH379mn+/Pn69ttvNWzYsHv2e+zYMa1YsUJr1qzRmjVrFBcXp3Hjxt21fUREhDw9PW0vb2/vLI0DAAAAAAAAD47lEfBIu3z5sqZNm6aPPvpI3bt3lySVL19ejRo1kiS99dZbtrY+Pj4KCwtTVFSUXch5/fp1LViwQKVLl5YkTZ8+XW3bttWkSZNUokQJu/N5enrKyclJrq6udvvy5cunsWPH2t77+vpq+/btio6OVnBwcKbGcvDgQW3cuFG7du1S7dq1JUmffPKJKlasaNfu9ddftxvTu+++q/79+2vmzJl37dtqtSoyMlLu7u6SpK5duyomJsY2I/mvRo4cqTfeeMP2PikpieAWAAAAAAAglxDa4pF24MABpaSkqFmzZhnuX7x4sT788EMdO3ZMV65c0a1bt+Th4WHXpmzZsrbAVpLq168vq9WqQ4cOpQtt72XGjBn67LPPlJCQoGvXrunGjRuqUaNGhm0XLVqkfv362d5/9dVX+vPPP5U/f349+eSTtu0VKlRQ4cKF7Y7duHGjIiIidPDgQSUlJenWrVu6fv26kpOT5erqmuH5fHx8bIGtJJUsWTLdDN47OTs7y9nZOTPDBgAAAAAAQDZjeQQ80u71wK3t27erS5cuatOmjdasWaPdu3frzTff1I0bN7K9jqioKIWFhalXr1765ptvtGfPHr3yyit3PVf79u21Z88e2yttZu39xMfH69lnn1X16tW1bNky/fjjj5oxY4Yk3XNcjo6Odu8tFousVmsmRwcAAAAAAIDcxExbPNIqVqwoFxcXxcTEqHfv3nb7tm3bpnLlyunNN9+0bTtx4kS6PhISEvTbb7+pVKlSkqQdO3bIwcFBAQEBGZ7TyclJqampdtu2bt2qBg0a2K2Fe+zYsbvW7e7ubjfzVZICAgJ069Yt7d69W7Vq1ZJ0e73dixcv2tr8+OOPslqtmjRpkhwcbv+dS1bXzQUAAAAAAIC5EdrikVagQAENHz5cw4YNk5OTkxo2bKg//vhD+/btU8WKFZWQkKCoqCjVqVNHa9eu1fLlyzPso3v37po4caKSkpI0aNAgBQcH33VpBB8fH33//feKj4+Xm5ubihQpoooVK2rBggX6+uuv5evrq4ULF2rXrl3y9fXN9FgqVaqk5s2bq2/fvpo1a5YcHR01ZMgQubi4yGKxSLq9XMLNmzc1ffp0tWvXTlu3btXs2bMf7OIBAAAAAADAlFgeAY+8UaNGaciQIRo9erQCAwMVEhKic+fOqX379ho8eLAGDhyoGjVqaNu2bRo1alS64ytUqKBOnTqpTZs2atGihapXr37Ph3qFhYUpX758qly5sry8vJSQkKB+/fqpU6dOCgkJUb169XThwgW7WbeZtWDBAhUvXlyNGzdWx44d1adPH7m7u6tAgQKSpKCgIE2ePFnjx49X1apVtWjRIkVERGT5PAAAAAAAADAvi2EYRl4XAeSV8PBwrVixQnv27MnrUjJ06tQpeXt7a+PGjXd92FpuSEpKkqenp7xfj5aDc8YPOwMAmEf8uLZ5XQIAAACADKRlLImJifLw8LhrO5ZHAEzk22+/1ZUrV1StWjWdOXNGw4YNk4+Pjxo3bpzXpQEAAAAAACCXENoCJnLz5k395z//0a+//ip3d3c1aNBAixYtkqOjY16XBgAAAAAAgFzC8ggA7ovlEQDg0cLyCAAAAIA5ZXZ5BB5EBgAAAAAAAAAmQmgLAAAAAAAAACZCaAsAAAAAAAAAJkJoCwAAAAAAAAAmQmgLAAAAAAAAACZCaAsAAAAAAAAAJpI/rwsA8Oj4ZWxLeXh45HUZAAAAAAAAjzVm2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAiRDaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAieTP6wIAPDqqjvlaDs6ueV0GAAAAAAD4m4gf1zavS8gTzLQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAE3lsQlsfHx9NnTrVNP3g3nr06KEOHTo8VB+xsbGyWCy6dOnSA/fB5w0AAAAAAACzeWxC2127dqlv37629xaLRStWrMj1Oh70vLkdHkZGRspisSgwMDDdviVLlshiscjHxyfHzj9t2jRFRkbmWP+Z9dffGwAAAAAAACCvPfKh7Y0bNyRJXl5ecnV1zeNqHi0FCxbUuXPntH37drvtn376qcqWLfvQ/ad9NndKTU2V1WqVp6enChUq9NDneFj83gAAAAAAAMBscjS0bdq0qV577TW9/vrrKly4sIoXL665c+fq6tWreuWVV+Tu7q4KFSroq6++knQ70OvVq5d8fX3l4uKigIAATZs2za7PtH9W/95776lUqVIKCAiQZD9TNW2GaMeOHe1mjB47dkzPPfecihcvLjc3N9WpU0cbN27M0phu3LihgQMHqmTJkipQoIDKlSuniIiIhzpv06ZNdeLECQ0ePFgWi0UWi0WSFB4erho1atidf+rUqXYzYGNjY1W3bl0VLFhQhQoVUsOGDXXixIlMjSV//vx6+eWX9dlnn9m2nTp1SrGxsXr55Zft2mbm2vn4+Oidd95Rt27d5OHhob59+yoyMlKFChXSqlWrVLlyZTk7OyshISHd8ghWq1URERG2zz4oKEhLly6163/dunXy9/eXi4uLnn76acXHx2dqnKtXr1adOnVUoEABFS1aVB07drSrOe335uWXX1ZISIjdsTdv3lTRokW1YMGCDPu+ePGiunTpIi8vL7m4uKhixYqaN2+eJCk+Pl4Wi0VRUVFq0KCBChQooKpVqyouLs6uj7i4ONWtW1fOzs4qWbKkRowYoVu3bmVYY5oaNWooPDxckmQYhsLDw1W2bFk5OzurVKlSGjRokK1tSkqKwsLCVLp0aRUsWFD16tVTbGzsPa9ZSkqKkpKS7F4AAAAAAADIHTk+03b+/PkqWrSodu7cqddee02vvvqqXnjhBTVo0ED/+9//1KJFC3Xt2lXJycmyWq0qU6aMlixZov3792v06NH6z3/+o+joaLs+Y2JidOjQIW3YsEFr1qxJd85du3ZJkubNm6czZ87Y3l+5ckVt2rRRTEyMdu/erVatWqldu3ZKSEjI9Hg+/PBDrVq1StHR0Tp06JAWLVpkC1Ef9LxffvmlypQpo7fffltnzpzRmTNnMlXLrVu31KFDBzVp0kQ///yztm/frr59+9pC38zo2bOnoqOjlZycLOn2sgmtWrVS8eLF7dpl9tpNnDhRQUFB2r17t0aNGiVJSk5O1vjx4/XJJ59o3759KlasWLo6IiIitGDBAs2ePVv79u3T4MGD9a9//csWcJ48eVKdOnVSu3bttGfPHvXu3VsjRoy47/jWrl2rjh07qk2bNtq9e7diYmJUt27dDNt26dJFq1ev1pUrV2zbvv76ayUnJ9sFvXcaNWqU9u/fr6+++koHDhzQrFmzVLRoUbs2Q4cO1ZAhQ7R7927Vr19f7dq104ULFyRJp0+fVps2bVSnTh399NNPmjVrlj799FO9++679x1bmmXLlmnKlCmaM2eOjhw5ohUrVqhatWq2/QMHDtT27dsVFRWln3/+WS+88IJatWqlI0eO3LXPiIgIeXp62l7e3t6ZrgcAAAAAAAAPJ39OnyAoKEhvvfWWJGnkyJEaN26cihYtqj59+kiSRo8erVmzZunnn3/WP/7xD40dO9Z2rK+vr7Zv367o6GgFBwfbthcsWFCffPKJnJycMjynl5eXJKlQoUIqUaKEXS1BQUG29++8846WL1+uVatWaeDAgZkaT0JCgipWrKhGjRrJYrGoXLlyD33eIkWKKF++fHJ3d7c77n6SkpKUmJioZ599VuXLl5ekDNeovZeaNWvKz89PS5cuVdeuXRUZGanJkyfr119/tWuX2Wv3zDPPaMiQIbb3mzdv1s2bNzVz5ky74++UkpKi999/Xxs3blT9+vUlSX5+ftqyZYvmzJmjJk2aaNasWSpfvrwmTZokSQoICNDevXs1fvz4e47vvffe04svvmj3e3W3Olq2bKmCBQtq+fLl6tq1qyTp888/V/v27eXu7p7hMQkJCapZs6Zq164tSRmuAzxw4EA9//zzkqRZs2Zp/fr1+vTTTzVs2DDNnDlT3t7e+uijj2SxWFSpUiX99ttvGj58uEaPHi0Hh/v/vUpCQoJKlCih5s2by9HRUWXLlrUF0wkJCZo3b54SEhJUqlQpSVJYWJjWr1+vefPm6f3338+wz5EjR+qNN96wvU9KSiK4BQAAAAAAyCU5PtO2evXqtp/z5cunJ554wm4WYNqMznPnzkmSZsyYoVq1asnLy0tubm76+OOP083mrFat2l0D23u5cuWKwsLCFBgYqEKFCsnNzU0HDhy460zb/v37y83NzfaSbi/PsGfPHgUEBGjQoEH65ptvsv28mVWkSBH16NFDLVu2VLt27TRt2rRMz9K9U8+ePTVv3jzFxcXp6tWratOmzQOPIS28vJOTk5Pd78FfHT16VMnJyfrnP/9pd70XLFigY8eOSZIOHDigevXq2R2XFvCmufPY/v37S5L27NmjZs2aZeo65M+fX8HBwVq0aJEk6erVq1q5cqW6dOkiSWrdurWt/ypVqkiSXn31VUVFRalGjRoaNmyYtm3blq7fO+vMnz+/ateurQMHDtjGVb9+fbvZ0Q0bNtSVK1d06tSpTNX9wgsv6Nq1a/Lz81OfPn20fPly2/IKe/fuVWpqqvz9/e2uT1xcnO3aZsTZ2VkeHh52LwAAAAAAAOSOHJ9p6+joaPfeYrHYbUsLq6xWq6KiohQWFqZJkyapfv36cnd31wcffKDvv//ero+CBQs+UC1hYWHasGGDJk6cqAoVKsjFxUWdO3fO8IFZkvT2228rLCzMbtuTTz6p48eP66uvvtLGjRsVHBys5s2bp1t/9WHOm8bBwUGGYdhtu3nzpt37efPmadCgQVq/fr0WL16st956Sxs2bNA//vGPe/Z9py5dumjYsGEKDw9X165dlT9/+l+LzI4ho8/GxcXlnks2pC1HsHbtWpUuXdpun7Ozc6bHsWfPHtvPaSGji4tLpo+Xbl+LJk2a6Ny5c9qwYYNcXFzUqlUrSdInn3yia9euSfq/3+vWrVvrxIkTWrdunTZs2KBmzZppwIABmjhxYpbOey/3+z3w9vbWoUOHtHHjRm3YsEGhoaH64IMPFBcXpytXrihfvnz68ccflS9fPrs+0v4iAgAAAAAAAOaS46FtVmzdulUNGjRQaGiobdu9ZgPei6Ojo1JTU9P136NHD9v6pFeuXLnnw6yKFSuW4fqrHh4eCgkJUUhIiDp37qxWrVrpzz//VJEiRR74vE5OTumO8/Ly0u+//y7DMGyh553BZJqaNWuqZs2aGjlypOrXr6/PP/88S6FtkSJF1L59e0VHR2v27NkZtsnqtcuKOx9Q1qRJkwzbBAYGatWqVXbbduzYYfe+QoUK6Y6rXr26YmJi9Morr2SqlgYNGsjb21uLFy/WV199pRdeeMEW0P41UE7j5eWl7t27q3v37nrqqac0dOhQu9B2x44daty4saTb6xD/+OOPtiUlAgMDtWzZMrvPeOvWrXJ3d1eZMmVs/d85gzopKUnHjx+3q8HFxUXt2rVTu3btNGDAAFWqVEl79+5VzZo1lZqaqnPnzumpp57K1DUAAAAAAABA3srx5RGyomLFivrhhx/09ddf6/Dhwxo1apTtYV5Z5ePjo5iYGP3++++6ePGirf8vv/xSe/bs0U8//aSXX35ZVqs1S/1OnjxZX3zxhQ4ePKjDhw9ryZIlKlGihAoVKvRQ5/Xx8dF3332n06dP6/z585Kkpk2b6o8//tCECRN07NgxzZgxQ1999ZXtmOPHj2vkyJHavn27Tpw4oW+++UZHjhzJ8rq20u0HkJ0/f16VKlXKcH92XLu7cXd3V1hYmAYPHqz58+fr2LFj+t///qfp06dr/vz5km4vVXHkyBENHTpUhw4d0ueff67IyMj79j1mzBh98cUXGjNmjA4cOJCpdXBffvllzZ49Wxs2bLAtjXA3o0eP1sqVK3X06FHt27dPa9asSXf9Z8yYoeXLl+vgwYMaMGCALl68qJ49e0qSQkNDdfLkSb322ms6ePCgVq5cqTFjxuiNN96wrWf7zDPPaOHChdq8ebP27t2r7t27282ajYyM1KeffqpffvlFv/76q/773//KxcVF5cqVk7+/v7p06aJu3brpyy+/1PHjx7Vz505FRERo7dq1971+AAAAAAAAyH2mCm379eunTp06KSQkRPXq1dOFCxfsZt1mxaRJk7RhwwZ5e3urZs2akm4HroULF1aDBg3Url07tWzZUk8++WSW+nV3d9eECRNUu3Zt1alTR/Hx8Vq3bp0tYHvQ87799tuKj49X+fLlbQ80CwwM1MyZMzVjxgwFBQVp586ddss1uLq66uDBg3r++efl7++vvn37asCAAerXr1+Wr5eLi4ueeOKJu+7Pjmt3L++8845GjRqliIgIBQYGqlWrVlq7dq18fX0lSWXLltWyZcu0YsUKBQUFafbs2Xd9iNadmjZtqiVLlmjVqlWqUaOGnnnmGe3cufOex3Tp0kX79+9X6dKl1bBhw3u2dXJy0siRI1W9enU1btxY+fLlU1RUlF2bcePGady4cQoKCtKWLVu0atUqFS1aVNLt2bvr1q3Tzp07FRQUpP79+6tXr162h/dJtx8K1qRJEz377LNq27atOnToYHvwnHT7wXdz585Vw4YNVb16dW3cuFGrV6+2fZ7z5s1Tt27dNGTIEAUEBKhDhw7atWuXypYte9/rBwAAAAAAgNxnMf66WCaAbBEfHy9fX1/t3r1bNWrUyOtyHkpSUpI8PT3l/Xq0HJxd87ocAAAAAADwNxE/rm1el5Ct0jKWxMTEez743VQzbQEAAAAAAADg747Q9jFVpUoVubm5ZfhatGhRXpcHAAAAAAAA4C7y53UByBnr1q3TzZs3M9xXvHjxXK7m78nHx0esPgIAAAAAAICsIrR9TJUrVy6vSwAAAAAAAADwAFgeAQAAAAAAAABMhNAWAAAAAAAAAEyE0BYAAAAAAAAATITQFgAAAAAAAABMhNAWAAAAAAAAAEwkf14XAODR8cvYlvLw8MjrMgAAAAAAAB5rzLQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATIbQFAAAAAAAAABMhtAUAAAAAAAAAEyG0BQAAAAAAAAATyZ/XBQAwP8MwJElJSUl5XAkAAAAAAMCjKy1bScta7obQFsB9XbhwQZLk7e2dx5UAAAAAAAA8+i5fvixPT8+77ie0BXBfRYoUkSQlJCTc8z8oAP5PUlKSvL29dfLkSXl4eOR1OcAjgfsGyDruG+DBcO8AWcd9kz0Mw9Dly5dVqlSpe7YjtAVwXw4Ot5e/9vT05D/MQBZ5eHhw3wBZxH0DZB33DfBguHeArOO+eXiZmRDHg8gAAAAAAAAAwEQIbQEAAAAAAADARAhtAdyXs7OzxowZI2dn57wuBXhkcN8AWcd9A2Qd9w3wYLh3gKzjvsldFsMwjLwuAgAAAAAAAABwGzNtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG2Bv6EZM2bIx8dHBQoUUL169bRz5857tl+yZIkqVaqkAgUKqFq1alq3bp3dfsMwNHr0aJUsWVIuLi5q3ry5jhw5kpNDAHJddt83PXr0kMVisXu1atUqJ4cA5Ims3Dv79u3T888/Lx8fH1ksFk2dOvWh+wQeRdl934SHh6f7M6dSpUo5OAIg92Xlvpk7d66eeuopFS5cWIULF1bz5s3Ttec7Dv4Osvu+4TtO9iK0Bf5mFi9erDfeeENjxozR//73PwUFBally5Y6d+5chu23bduml156Sb169dLu3bvVoUMHdejQQb/88outzYQJE/Thhx9q9uzZ+v7771WwYEG1bNlS169fz61hATkqJ+4bSWrVqpXOnDlje33xxRe5MRwg12T13klOTpafn5/GjRunEiVKZEufwKMmJ+4bSapSpYrdnzlbtmzJqSEAuS6r901sbKxeeuklbdq0Sdu3b5e3t7datGih06dP29rwHQePu5y4byS+42QrA8DfSt26dY0BAwbY3qemphqlSpUyIiIiMmwfHBxstG3b1m5bvXr1jH79+hmGYRhWq9UoUaKE8cEHH9j2X7p0yXB2dja++OKLHBgBkPuy+74xDMPo3r278dxzz+VIvYBZZPXeuVO5cuWMKVOmZGufwKMgJ+6bMWPGGEFBQdlYJWAuD/tnw61btwx3d3dj/vz5hmHwHQd/D9l93xgG33GyGzNtgb+RGzdu6Mcff1Tz5s1t2xwcHNS8eXNt3749w2O2b99u116SWrZsaWt//Phx/f7773ZtPD09Va9evbv2CTxKcuK+SRMbG6tixYopICBAr776qi5cuJD9AwDyyIPcO3nRJ2AmOfk7fuTIEZUqVUp+fn7q0qWLEhISHrZcwBSy475JTk7WzZs3VaRIEUl8x8HjLyfumzR8x8k+hLbA38j58+eVmpqq4sWL220vXry4fv/99wyP+f333+/ZPu1/s9In8CjJiftGuv3PhhYsWKCYmBiNHz9ecXFxat26tVJTU7N/EEAeeJB7Jy/6BMwkp37H69Wrp8jISK1fv16zZs3S8ePH9dRTT+ny5csPWzKQ57Ljvhk+fLhKlSplC7D4joPHXU7cNxLfcbJb/rwuAACAv6MXX3zR9nO1atVUvXp1lS9fXrGxsWrWrFkeVgYAeNy0bt3a9nP16tVVr149lStXTtHR0erVq1ceVgbkvXHjxikqKkqxsbEqUKBAXpcDPBLudt/wHSd7MdMW+BspWrSo8uXLp7Nnz9ptP3v27F0fXFGiRIl7tk/736z0CTxKcuK+yYifn5+KFi2qo0ePPnzRgAk8yL2TF30CZpJbv+OFChWSv78/f+bgsfAw983EiRM1btw4ffPNN6pevbptO99x8LjLifsmI3zHeTiEtsDfiJOTk2rVqqWYmBjbNqvVqpiYGNWvXz/DY+rXr2/XXpI2bNhga+/r66sSJUrYtUlKStL3339/1z6BR0lO3DcZOXXqlC5cuKCSJUtmT+FAHnuQeycv+gTMJLd+x69cuaJjx47xZw4eCw9630yYMEHvvPOO1q9fr9q1a9vt4zsOHnc5cd9khO84Dymvn4QGIHdFRUUZzs7ORmRkpLF//36jb9++RqFChYzff//dMAzD6Nq1qzFixAhb+61btxr58+c3Jk6caBw4cMAYM2aM4ejoaOzdu9fWZty4cUahQoWMlStXGj///LPx3HPPGb6+vsa1a9dyfXxATsju++by5ctGWFiYsX37duP48ePGxo0bjSeffNKoWLGicf369TwZI5ATsnrvpKSkGLt37zZ2795tlCxZ0ggLCzN2795tHDlyJNN9Ao+6nLhvhgwZYsTGxhrHjx83tm7dajRv3twoWrSoce7cuVwfH5ATsnrfjBs3znBycjKWLl1qnDlzxva6fPmyXRu+4+Bxlt33Dd9xsh+hLfA3NH36dKNs2bKGk5OTUbduXWPHjh22fU2aNDG6d+9u1z46Otrw9/c3nJycjCpVqhhr166122+1Wo1Ro0YZxYsXN5ydnY1mzZoZhw4dyo2hALkmO++b5ORko0WLFoaXl5fh6OholCtXzujTpw+hEx5LWbl3jh8/bkhK92rSpEmm+wQeB9l934SEhBglS5Y0nJycjNKlSxshISHG0aNHc3FEQM7Lyn1Trly5DO+bMWPG2NrwHQd/B9l53/AdJ/tZDMMwcnduLwAAAAAAAADgbljTFgAAAAAAAABMhNAWAAAAAAAAAEyE0BYAAAAAAAAATITQFgAAAAAAAABMhNAWAAAAAAAAAEyE0BYAAAAAAAAATITQFgAAAAAAAABMhNAWAAAAAAAAAEyE0BYAAAB4DMXGxspisSg2NjZb+7VYLAoPD8/WPgEAAGCP0BYAAADIY5GRkbJYLLZX/vz5Vbp0afXo0UOnT5/O9XrWrVtnumDWYrFo4MCBeV3GA9u2bZvCw8N16dKlvC4FAAA8AvLndQEAAAAAbnv77bfl6+ur69eva8eOHYqMjNSWLVv0yy+/qECBArlWx7p16zRjxowMg9tr164pf36+RmTVtm3bNHbsWPXo0UOFChXK63IAAIDJ8f+2AAAAAJNo3bq1ateuLUnq3bu3ihYtqvHjx2vVqlUKDg7O4+puy83w+HFw9epVFSxYMK/LAAAAjxiWRwAAAABM6qmnnpIkHTt2zG77wYMH1blzZxUpUkQFChRQ7dq1tWrVqvv2t3nzZr3wwgsqW7asnJ2d5e3trcGDB+vatWu2Nj169NCMGTMkyW7JhjR3rmm7dOlSWSwWxcXFpTvXnDlzZLFY9Msvvzx03RlJW7M3OjpaY8eOVenSpeXu7q7OnTsrMTFRKSkpev3111WsWDG5ubnplVdeUUpKil0faUsuLFq0SAEBASpQoIBq1aql7777Lt35du/erdatW8vDw0Nubm5q1qyZduzYYdcmbZmLuLg4hYaGqlixYipTpozCw8M1dOhQSZKvr6/tmsbHx0uS5s2bp2eeeUbFihWTs7OzKleurFmzZqWrwcfHR88++6y2bNmiunXrqkCBAvLz89OCBQvStb106ZIGDx4sHx8fOTs7q0yZMurWrZvOnz9va5OSkqIxY8aoQoUKtt+HYcOGpbtOAAAg9zHTFgAAADCptFCvcOHCtm379u1Tw4YNVbp0aY0YMUIFCxZUdHS0OnTooGXLlqljx4537W/JkiVKTk7Wq6++qieeeEI7d+7U9OnTderUKS1ZskSS1K9fP/3222/asGGDFi5ceM/62rZtKzc3N0VHR6tJkyZ2+xYvXqwqVaqoatWqD133vURERMjFxUUjRozQ0aNHNX36dDk6OsrBwUEXL15UeHi4bakJX19fjR492u74uLg4LV68WIMGDZKzs7NmzpypVq1aaefOnXa1P/XUU/Lw8NCwYcPk6OioOXPmqGnTpoqLi1O9evXs+gwNDZWXl5dGjx6tq1evqnXr1jp8+LC++OILTZkyRUWLFpUkeXl5SZJmzZqlKlWqqH379sqfP79Wr16t0NBQWa1WDRgwwK7vo0ePqnPnzurVq5e6d++uzz77TD169FCtWrVUpUoVSdKVK1f01FNP6cCBA+rZs6eefPJJnT9/XqtWrdKpU6dUtGhRWa1WtW/fXlu2bFHfvn0VGBiovXv3asqUKTp8+LBWrFjxQJ8HAADIJgYAAACAPDVv3jxDkrFx40bjjz/+ME6ePGksXbrU8PLyMpydnY2TJ0/a2jZr1syoVq2acf36dds2q9VqNGjQwKhYsaJt26ZNmwxJxqZNm2zbkpOT0507IiLCsFgsxokTJ2zbBgwYYNztq4IkY8yYMbb3L730klGsWDHj1q1btm1nzpwxHBwcjLfffjvLdd+NJGPAgAHpxle1alXjxo0bdvVYLBajdevWdsfXr1/fKFeuXLo+JRk//PCDbduJEyeMAgUKGB07drRt69Chg+Hk5GQcO3bMtu23334z3N3djcaNG9u2pX2OjRo1srsehmEYH3zwgSHJOH78eLqxZfS5tGzZ0vDz87PbVq5cOUOS8d1339m2nTt3znB2djaGDBli2zZ69GhDkvHll1+m69dqtRqGYRgLFy40HBwcjM2bN9vtnz17tiHJ2Lp1a7pjAQBA7mF5BAAAAMAkmjdvLi8vL3l7e6tz584qWLCgVq1apTJlykiS/vzzT3377bcKDg7W5cuXdf78eZ0/f14XLlxQy5YtdeTIEZ0+ffqu/bu4uNh+vnr1qs6fP68GDRrIMAzt3r37gWoOCQnRuXPnFBsba9u2dOlSWa1WhYSEZEvd99KtWzc5Ojra3terV0+GYahnz5527erVq6eTJ0/q1q1bdtvr16+vWrVq2d6XLVtWzz33nL7++mulpqYqNTVV33zzjTp06CA/Pz9bu5IlS+rll1/Wli1blJSUZNdnnz59lC9fvkyP4c7PJTExUefPn1eTJk3066+/KjEx0a5t5cqVbctmSLdn6wYEBOjXX3+1bVu2bJmCgoIynL2cttTFkiVLFBgYqEqVKtk+j/Pnz+uZZ56RJG3atCnT9QMAgOzH8ggAAACAScyYMUP+/v5KTEzUZ599pu+++07Ozs62/UePHpVhGBo1apRGjRqVYR/nzp1T6dKlM9yXkJCg0aNHa9WqVbp48aLdvr+Gg5nVqlUreXp6avHixWrWrJmk20sj1KhRQ/7+/tlS972ULVvW7r2np6ckydvbO912q9WqxMREPfHEE7btFStWTNenv7+/kpOT9ccff0iSkpOTFRAQkK5dYGCgrFarTp48aVuaQLq9bm1WbN26VWPGjNH27duVnJxsty8xMdE2Jin9eKXby2fc+XkeO3ZMzz///D3PeeTIER04cMC2RMNfnTt3LitDAAAA2YzQFgAAADCJunXrqnbt2pKkDh06qFGjRnr55Zd16NAhubm5yWq1SpLCwsLUsmXLDPuoUKFChttTU1P1z3/+U3/++aeGDx+uSpUqqWDBgjp9+rR69Ohh6zurnJ2d1aFDBy1fvlwzZ87U2bNntXXrVr3//vu2Ng9T9/3cbUbr3bYbhvFA58mKO2fO3s+xY8fUrFkzVapUSZMnT5a3t7ecnJy0bt06TZkyJd3nkl3jslqtqlatmiZPnpzh/r+G3gAAIHcR2gIAAAAmlC9fPkVEROjpp5/WRx99pBEjRtj+eb6jo6OaN2+epf727t2rw4cPa/78+erWrZtt+4YNG9K1Tfsn9JkVEhKi+fPnKyYmRgcOHJBhGLalESQ9VN057ciRI+m2HT58WK6urrZZqK6urjp06FC6dgcPHpSDg0OmAs67XdPVq1crJSVFq1atsptF+zDLE5QvX16//PLLfdv89NNPatasWZY/bwAAkPNY0xYAAAAwqaZNm6pu3bqaOnWqrl+/rmLFiqlp06aaM2eOzpw5k6592j/nz0jaDM07Z2QahqFp06ala1uwYEFJ0qVLlzJVZ/PmzVWkSBEtXrxYixcvVt26de2WCHiYunPa9u3b9b///c/2/uTJk1q5cqVatGihfPnyKV++fGrRooVWrlyp+Ph4W7uzZ8/q888/V6NGjeTh4XHf89ztmmb0uSQmJmrevHkPPKbnn39eP/30k5YvX55uX9p5goODdfr0ac2dOzddm2vXrunq1asPfH4AAPDwmGkLAAAAmNjQoUP1wgsvKDIyUv3799eMGTPUqFEjVatWTX369JGfn5/Onj2r7du369SpU/rpp58y7KdSpUoqX768wsLCdPr0aXl4eGjZsmXp1raVZHsw16BBg9SyZUvly5dPL7744l1rdHR0VKdOnRQVFaWrV69q4sSJ6do8aN05rWrVqmrZsqUGDRokZ2dnzZw5U5I0duxYW5t3331XGzZsUKNGjRQaGqr8+fNrzpw5SklJ0YQJEzJ1nrRr+uabb+rFF1+Uo6Oj2rVrpxYtWsjJyUnt2rVTv379dOXKFc2dO1fFihXLMODOjKFDh2rp0qV64YUX1LNnT9WqVUt//vmnVq1apdmzZysoKEhdu3ZVdHS0+vfvr02bNqlhw4ZKTU3VwYMHFR0dra+//tq2VAcAAMh9hLYAAACAiXXq1Enly5fXxIkT1adPH1WuXFk//PCDxo4dq8jISF24cEHFihVTzZo1NXr06Lv24+joqNWrV2vQoEGKiIhQgQIF1LFjRw0cOFBBQUHpzvnaa68pKipK//3vf2UYxj1DW+n2EgmffPKJLBaLgoOD0+1/0LpzWpMmTVS/fn2NHTtWCQkJqly5siIjI1W9enVbmypVqmjz5s0aOXKkIiIiZLVaVa9ePf33v/9VvXr1MnWeOnXq6J133tHs2bO1fv16Wa1WHT9+XAEBAVq6dKneeusthYWFqUSJEnr11Vfl5eWlnj17PtCY3NzctHnzZo0ZM0bLly/X/PnzVaxYMTVr1kxlypSRJDk4OGjFihWaMmWKFixYoOXLl8vV1VV+fn7697//bXuIHAAAyBsWIzdW4gcAAAAAk7FYLBowYIA++uijvC4FAADADmvaAgAAAAAAAICJENoCAAAAAAAAgIkQ2gIAAAAAAACAifAgMgAAAAB/SzzeAwAAmBUzbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBECG0BAAAAAAAAwEQIbQEAAAAAAADARAhtAQAAAAAAAMBE/h8VzEzAYnL2jQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1400x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try to understand feature Importance\n",
    "plt.figure(figsize=(14, 10))\n",
    "feature_importance = best_model.feature_importances_\n",
    "indices = np.argsort(feature_importance)[::-1]\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# top 20 features\n",
    "n_features = min(20, len(feature_names))\n",
    "plt.barh(range(n_features), feature_importance[indices[:n_features]], align='center')\n",
    "plt.yticks(range(n_features), [feature_names[i] for i in indices[:n_features]])\n",
    "plt.title('XGBoost Feature Importance', fontsize=15)\n",
    "plt.xlabel('Relative Importance', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f383928",
   "metadata": {},
   "source": [
    "Top 2-6 make a lot of sense, capital gain, education, capital loss and occupation were the expected results, but also interesting to see that the top 1 feature by a large margin is being married to a civilian spouse, this could be related to having a stable income and household, but also due to the fact that being married to an AF (armed forces) spouse is also a feature, which may influence the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf46025",
   "metadata": {},
   "source": [
    "# Use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733a097b",
   "metadata": {},
   "source": [
    "## Governmental policy making\n",
    "\n",
    "Policymakers can use insights from income predictions to design more targeted interventions aimed at reducing income inequality. For instance, understanding how education or housing factors contribute to higher income levels can inform decisions about funding educational programs, for example helping women in rural areas, which are often at a disadvantage in terms of opportunities compared to their urban counterparts, get access to better education.\n",
    "\n",
    "For this problem we need to focus on two metrics:\n",
    "1. Recall - we need to identify as many eligible individuals as possible to ensure no one is left behind, even if that means some false positives.\n",
    "2. F1 Score - we want a balance between identifying eligible individuals and minimizing false positives, ensuring that resources are allocated efficiently.\n",
    "\n",
    "For this reason we'll use the **Random Forest Classifier** with the hyperparameters tuned for recall, using **undersampling**, as it provides a good balance between identifying eligible individuals and minimizing false positives.\n",
    "We got the following metrics when testing:\n",
    "- Accuracy: 0.7905\n",
    "- Precision: 0.5378\n",
    "- **Recall**: **0.8898**\n",
    "- **F1 Score**: **0.6704**\n",
    "- ROC AUC: 0.9092"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcadf37",
   "metadata": {},
   "source": [
    "## Bank loan approval\n",
    "Financial institutions can use income predictions for credit risk analysis. By understanding an individual's potential income level, they can more accurately predict their ability to repay loans, which can help in determining interest rates and loan amounts.\n",
    "\n",
    "Here we'll focus on:\n",
    "1. Precision - we want to ensure that the individuals we approve for loans are likely to repay them, minimizing the risk of defaults.\n",
    "2. Accuracy - we want to ensure that our model is making correct predictions, balancing both true positives and true negatives, leading to an overall positive porfolio.\n",
    "\n",
    "For this use case we'll use the **XGBoost Classifier** with the hyperparameters tuned for precision, using **raw data**, as it performed best especially in terms of precision. We got the following metrics when testing: \n",
    "- **Accuracy**: **0.8158**\n",
    "- **Precision**: **0.9846**\n",
    "- Recall: 0.234\n",
    "- F1 Score: 0.3781\n",
    "- ROC AUC: 0.8955"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
